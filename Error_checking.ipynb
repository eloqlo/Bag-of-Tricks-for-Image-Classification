{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argparse 문제X  \n",
    "tqdm을 epochs에 걸었었다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/anaconda3/envs/test_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_archive.ResNet import ResNet, Config\n",
    "\n",
    "import argparse\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    model='resnet50',\n",
    "    batch_size=64,\n",
    "    lr=5e-5,\n",
    "    epochs=100,\n",
    "    root_path='/home/jh/Desktop/VSC/CNN_work/archive/CUB_200_2011/',\n",
    "    scheduler='no',\n",
    "    pretrained='no',\n",
    "\n",
    "    cosLRdecay_lin_end=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image    \n",
    "\n",
    "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device, scheduler=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for step, (x, y) in enumerate(iterator):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler=='yes':\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<< Configurations >>\n",
      "[*] Model       - resnet50\n",
      "[*] Batch_size  - 64\n",
      "[*] LR          - 5e-05\n",
      "[*] Epochs      - 100\n",
      "[*] train newly initialized model!\n",
      "[*] Parameters  - 23,917,832\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--model\", type=str, default='resnet34')     # resnet18, 34, 50, 101, 152.\n",
    "    # parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    # parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    # parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "    # parser.add_argument(\"--root_path\", type=str, default='/home/jh/Desktop/VSC/CNN_work/archive/CUB_200_2011/')\n",
    "    # parser.add_argument(\"--scheduler\", type=str, default='no')      # yes / no\n",
    "    # parser.add_argument(\"--pretrained\", type=str, default='no')     # yes / no\n",
    "    # # parser.add_argument(\"--half\", type=str, default='no')           # yes / no\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    print()\n",
    "    print('<< Configurations >>')\n",
    "    print(f'[*] Model       - {args.model}')\n",
    "    print(f'[*] Batch_size  - {args.batch_size}')\n",
    "    print(f'[*] LR          - {args.lr}')\n",
    "    print(f'[*] Epochs      - {args.epochs}')\n",
    "\n",
    "    # Dataset\n",
    "    pretrained_size = 224\n",
    "    pretrained_means = [0.485, 0.456, 0.406]\n",
    "    pretrained_stds= [0.229, 0.224, 0.225]\n",
    "    train_transforms = transforms.Compose([\n",
    "                            transforms.Resize(pretrained_size),\n",
    "                            transforms.RandomRotation(5),\n",
    "                            transforms.RandomHorizontalFlip(0.5),\n",
    "                            transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean = pretrained_means, \n",
    "                                                    std = pretrained_stds)\n",
    "                        ])\n",
    "    test_transforms = transforms.Compose([\n",
    "                            transforms.Resize(pretrained_size),\n",
    "                            transforms.CenterCrop(pretrained_size),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean = pretrained_means, \n",
    "                                                    std = pretrained_stds)\n",
    "                        ])\n",
    "    ROOT = args.root_path\n",
    "    data_dir = os.path.join(ROOT, 'CUB_200_2011')\n",
    "    images_dir = os.path.join(data_dir, 'images')\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "    train_data = datasets.ImageFolder(root = train_dir,\n",
    "                                  transform = train_transforms)\n",
    "    test_data = datasets.ImageFolder(root = test_dir,\n",
    "                                    transform = test_transforms)\n",
    "    \n",
    "    VALID_RATIO = 0.8\n",
    "    n_train_examples = int(len(train_data)*VALID_RATIO)\n",
    "    n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "    train_data, valid_data = data.random_split(train_data,\n",
    "                                            [n_train_examples, n_valid_examples])\n",
    "    valid_data = copy.deepcopy(valid_data)\n",
    "    valid_data.dataset.transform = test_transforms\n",
    "\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    train_iterator = data.DataLoader(train_data, \n",
    "                                    shuffle = True, \n",
    "                                    batch_size = BATCH_SIZE)\n",
    "    valid_iterator = data.DataLoader(valid_data, \n",
    "                                    batch_size = BATCH_SIZE)\n",
    "    test_iterator = data.DataLoader(test_data, \n",
    "                                    batch_size = BATCH_SIZE)\n",
    "\n",
    "    # Model Zoo\n",
    "    if args.model=='resnet18':\n",
    "        if args.pretrained=='yes':\n",
    "            downloaded_model = models.resnet18(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "        else:\n",
    "            downloaded_model = models.resnet18(pretrained = False)\n",
    "            print('[*] train newly initialized model!')\n",
    "    elif args.model=='resnet34':\n",
    "        if args.pretrained=='yes':\n",
    "            downloaded_model = models.resnet34(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "        else:\n",
    "            downloaded_model = models.resnet34(pretrained = False)\n",
    "            print('[*] train newly initialized model!')\n",
    "    elif args.model=='resnet50':\n",
    "        if args.pretrained=='yes':\n",
    "            downloaded_model = models.resnet50(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "        else:\n",
    "            downloaded_model = models.resnet50(pretrained = False)\n",
    "            print('[*] train newly initialized model!')\n",
    "    elif args.model=='resnet101':\n",
    "        if args.pretrained=='yes':\n",
    "            downloaded_model = models.resnet101(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "        else:\n",
    "            downloaded_model = models.resnet101(pretrained = False)\n",
    "            print('[*] train newly initialized model!')\n",
    "    elif args.model=='resnet152':\n",
    "        if args.pretrained=='yes':\n",
    "            downloaded_model = models.resnet152(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "        else:\n",
    "            downloaded_model = models.resnet152(pretrained = False)\n",
    "            print('[*] train newly initialized model!')\n",
    "    config = Config()\n",
    "    resnet_config = config.get_resnet_config(model_name = args.model)\n",
    "\n",
    "\n",
    "    # Change FC layer in model for transfer learning.\n",
    "    IN_FEATURES = downloaded_model.fc.in_features \n",
    "    OUTPUT_DIM = len(test_data.classes)\n",
    "    downloaded_model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "    START_LR = args.lr\n",
    "    model = ResNet(resnet_config, OUTPUT_DIM)\n",
    "    print(f'[*] Parameters  - {count_parameters(model):,}')\n",
    "    # if args.half=='yes':\n",
    "    #     model = model.half()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if args.scheduler == 'yes':\n",
    "        # cosine scheduler\n",
    "        '''\n",
    "        - 기존 lr overfitting지점인, 30-40 에 다다르기 전에 decay주는게 적합해보여.\n",
    "        - 한번 그렇게 ``lr==0`` 까지 탐색하는것보단, hard_reset하면서 그 optima에서 빠져나와서 \n",
    "          주변 다른 optima 들어가보는것도 좋지 않을까?\n",
    "        - 지금 실험상황은 best 모델 찾는거고, epoch 100 가면서 어차피 튀는 경향성 보이니, 좋은 시도같은데?\n",
    "        '''\n",
    "        ITERATIONS = args.epochs * len(train_iterator)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=ITERATIONS, eta_min=1e-8)\n",
    "    else:\n",
    "        scheduler=None\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # writer = SummaryWriter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifing Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear warmup있는 cosine LR decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDecayWithLinearWarmup_demo(MAX_EPOCH, lin_end, epoch, train_loader, step):\n",
    "    import math\n",
    "    '''\n",
    "    input   :   max_epoch  : max_epoch of whole training stage.\n",
    "                lin_end  : end epoch of linear warmup stage.\n",
    "                epoch(current step's / must starts from 0)  \n",
    "                train_loader (for len(train_loader)...)  \n",
    "                current step_num (might should use enumerate)  \n",
    "    output  :   lr_계수 that will be multiplied with lr for current step before optimizer.step().  \n",
    "    '''\n",
    "    \n",
    "    lin_end_steps = lin_end*len(train_loader) # lin_warmup이 끝나는 지점\n",
    "    iter_per_epoch = len(train_loader)\n",
    "    whole_steps = iter_per_epoch*MAX_EPOCH - lin_end_steps  # 'whole_steps' is whole iteration steps.\n",
    "    whole_steps_cos = whole_steps - lin_end_steps   # pure cosine #steps.\n",
    "\n",
    "    if epoch < lin_end:\n",
    "        lr_const = (step + epoch*iter_per_epoch)/lin_end_steps  # 선형 증가 비율계산\n",
    "        return lr_const\n",
    "    else:\n",
    "        T = (MAX_EPOCH-lin_end)*iter_per_epoch\n",
    "        t = (epoch - lin_end)*iter_per_epoch + step\n",
    "        lr_const = 0.5*(1+math.cos(t/T*math.pi))\n",
    "        return lr_const\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만든 함수에 맞게, 바꿔줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cosLRdecay(model, iterator, optimizer, criterion, device, MAX_EPOCH, lin_end, epoch, lr, scheduler='no'):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for step, (x, y) in enumerate(iterator):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        ##################################\n",
    "        # MAX_EPOCH, lin_end, epoch, train_loader, step\n",
    "        for g in optimizer.param_groups:\n",
    "            lr_const = cosineDecayWithLinearWarmup_demo(MAX_EPOCH, lin_end, epoch, iterator, step)\n",
    "            print(lr, lr_const)\n",
    "            g['lr'] = lr * lr_const\n",
    "        ##################################\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler=='yes':\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5, lr_const"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW : 학습 돌리기 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Start Training !\n",
      "\n",
      "5e-05 0.0\n",
      "5e-05 0.001694915254237288\n",
      "5e-05 0.003389830508474576\n",
      "5e-05 0.005084745762711864\n",
      "5e-05 0.006779661016949152\n",
      "5e-05 0.00847457627118644\n",
      "5e-05 0.010169491525423728\n",
      "5e-05 0.011864406779661017\n",
      "5e-05 0.013559322033898305\n",
      "5e-05 0.015254237288135594\n",
      "5e-05 0.01694915254237288\n",
      "5e-05 0.01864406779661017\n",
      "5e-05 0.020338983050847456\n",
      "5e-05 0.022033898305084745\n",
      "5e-05 0.023728813559322035\n",
      "5e-05 0.025423728813559324\n",
      "5e-05 0.02711864406779661\n",
      "5e-05 0.0288135593220339\n",
      "5e-05 0.030508474576271188\n",
      "5e-05 0.03220338983050847\n",
      "5e-05 0.03389830508474576\n",
      "5e-05 0.03559322033898305\n",
      "5e-05 0.03728813559322034\n",
      "5e-05 0.03898305084745763\n",
      "5e-05 0.04067796610169491\n",
      "5e-05 0.0423728813559322\n",
      "5e-05 0.04406779661016949\n",
      "5e-05 0.04576271186440678\n",
      "5e-05 0.04745762711864407\n",
      "5e-05 0.04915254237288136\n",
      "5e-05 0.05084745762711865\n",
      "5e-05 0.05254237288135593\n",
      "5e-05 0.05423728813559322\n",
      "5e-05 0.05593220338983051\n",
      "5e-05 0.0576271186440678\n",
      "5e-05 0.059322033898305086\n",
      "5e-05 0.061016949152542375\n",
      "5e-05 0.06271186440677966\n",
      "5e-05 0.06440677966101695\n",
      "5e-05 0.06610169491525424\n",
      "5e-05 0.06779661016949153\n",
      "5e-05 0.06949152542372881\n",
      "5e-05 0.0711864406779661\n",
      "5e-05 0.07288135593220339\n",
      "5e-05 0.07457627118644068\n",
      "5e-05 0.07627118644067797\n",
      "5e-05 0.07796610169491526\n",
      "5e-05 0.07966101694915254\n",
      "5e-05 0.08135593220338982\n",
      "5e-05 0.08305084745762711\n",
      "5e-05 0.0847457627118644\n",
      "5e-05 0.08644067796610169\n",
      "5e-05 0.08813559322033898\n",
      "5e-05 0.08983050847457627\n",
      "5e-05 0.09152542372881356\n",
      "5e-05 0.09322033898305085\n",
      "5e-05 0.09491525423728814\n",
      "5e-05 0.09661016949152543\n",
      "5e-05 0.09830508474576272\n",
      "5e-05 0.1\n",
      "5e-05 0.1016949152542373\n",
      "5e-05 0.10338983050847457\n",
      "5e-05 0.10508474576271186\n",
      "5e-05 0.10677966101694915\n",
      "5e-05 0.10847457627118644\n",
      "5e-05 0.11016949152542373\n",
      "5e-05 0.11186440677966102\n",
      "5e-05 0.1135593220338983\n",
      "5e-05 0.1152542372881356\n",
      "5e-05 0.11694915254237288\n",
      "5e-05 0.11864406779661017\n",
      "5e-05 0.12033898305084746\n",
      "5e-05 0.12203389830508475\n",
      "5e-05 0.12372881355932204\n",
      "5e-05 0.12542372881355932\n",
      "5e-05 0.1271186440677966\n",
      "5e-05 0.1288135593220339\n",
      "5e-05 0.13050847457627118\n",
      "5e-05 0.13220338983050847\n",
      "5e-05 0.13389830508474576\n",
      "5e-05 0.13559322033898305\n",
      "5e-05 0.13728813559322034\n",
      "5e-05 0.13898305084745763\n",
      "5e-05 0.14067796610169492\n",
      "5e-05 0.1423728813559322\n",
      "5e-05 0.1440677966101695\n",
      "5e-05 0.14576271186440679\n",
      "5e-05 0.14745762711864407\n",
      "5e-05 0.14915254237288136\n",
      "5e-05 0.15084745762711865\n",
      "5e-05 0.15254237288135594\n",
      "5e-05 0.15423728813559323\n",
      "5e-05 0.15593220338983052\n",
      "5e-05 0.1576271186440678\n",
      "5e-05 0.15932203389830507\n",
      "5e-05 0.16101694915254236\n",
      "5e-05 0.16271186440677965\n",
      "5e-05 0.16440677966101694\n",
      "5e-05 0.16610169491525423\n",
      "5e-05 0.16779661016949152\n",
      "5e-05 0.1694915254237288\n",
      "5e-05 0.1711864406779661\n",
      "5e-05 0.17288135593220338\n",
      "5e-05 0.17457627118644067\n",
      "5e-05 0.17627118644067796\n",
      "5e-05 0.17796610169491525\n",
      "5e-05 0.17966101694915254\n",
      "5e-05 0.18135593220338983\n",
      "5e-05 0.18305084745762712\n",
      "5e-05 0.1847457627118644\n",
      "5e-05 0.1864406779661017\n",
      "5e-05 0.188135593220339\n",
      "5e-05 0.18983050847457628\n",
      "5e-05 0.19152542372881357\n",
      "5e-05 0.19322033898305085\n",
      "5e-05 0.19491525423728814\n",
      "5e-05 0.19661016949152543\n",
      "5e-05 0.19830508474576272\n",
      "Epoch: 01 | Epoch Time: 1m 40s\n",
      "\tTrain Loss: 5.400 | Train Acc @1:   0.52% | Train Acc @5:   2.48%\n",
      "\tValid Loss: 5.320 | Valid Acc @1:   0.75% | Valid Acc @5:   2.94%\n",
      "5e-05 0.2\n",
      "5e-05 0.2016949152542373\n",
      "5e-05 0.2033898305084746\n",
      "5e-05 0.20508474576271185\n",
      "5e-05 0.20677966101694914\n",
      "5e-05 0.20847457627118643\n",
      "5e-05 0.21016949152542372\n",
      "5e-05 0.211864406779661\n",
      "5e-05 0.2135593220338983\n",
      "5e-05 0.21525423728813559\n",
      "5e-05 0.21694915254237288\n",
      "5e-05 0.21864406779661016\n",
      "5e-05 0.22033898305084745\n",
      "5e-05 0.22203389830508474\n",
      "5e-05 0.22372881355932203\n",
      "5e-05 0.22542372881355932\n",
      "5e-05 0.2271186440677966\n",
      "5e-05 0.2288135593220339\n",
      "5e-05 0.2305084745762712\n",
      "5e-05 0.23220338983050848\n",
      "5e-05 0.23389830508474577\n",
      "5e-05 0.23559322033898306\n",
      "5e-05 0.23728813559322035\n",
      "5e-05 0.23898305084745763\n",
      "5e-05 0.24067796610169492\n",
      "5e-05 0.2423728813559322\n",
      "5e-05 0.2440677966101695\n",
      "5e-05 0.2457627118644068\n",
      "5e-05 0.24745762711864408\n",
      "5e-05 0.24915254237288137\n",
      "5e-05 0.25084745762711863\n",
      "5e-05 0.25254237288135595\n",
      "5e-05 0.2542372881355932\n",
      "5e-05 0.2559322033898305\n",
      "5e-05 0.2576271186440678\n",
      "5e-05 0.2593220338983051\n",
      "5e-05 0.26101694915254237\n",
      "5e-05 0.2627118644067797\n",
      "5e-05 0.26440677966101694\n",
      "5e-05 0.26610169491525426\n",
      "5e-05 0.2677966101694915\n",
      "5e-05 0.26949152542372884\n",
      "5e-05 0.2711864406779661\n",
      "5e-05 0.27288135593220336\n",
      "5e-05 0.2745762711864407\n",
      "5e-05 0.27627118644067794\n",
      "5e-05 0.27796610169491526\n",
      "5e-05 0.2796610169491525\n",
      "5e-05 0.28135593220338984\n",
      "5e-05 0.2830508474576271\n",
      "5e-05 0.2847457627118644\n",
      "5e-05 0.2864406779661017\n",
      "5e-05 0.288135593220339\n",
      "5e-05 0.28983050847457625\n",
      "5e-05 0.29152542372881357\n",
      "5e-05 0.29322033898305083\n",
      "5e-05 0.29491525423728815\n",
      "5e-05 0.2966101694915254\n",
      "5e-05 0.2983050847457627\n",
      "5e-05 0.3\n",
      "5e-05 0.3016949152542373\n",
      "5e-05 0.30338983050847457\n",
      "5e-05 0.3050847457627119\n",
      "5e-05 0.30677966101694915\n",
      "5e-05 0.30847457627118646\n",
      "5e-05 0.3101694915254237\n",
      "5e-05 0.31186440677966104\n",
      "5e-05 0.3135593220338983\n",
      "5e-05 0.3152542372881356\n",
      "5e-05 0.3169491525423729\n",
      "5e-05 0.31864406779661014\n",
      "5e-05 0.32033898305084746\n",
      "5e-05 0.3220338983050847\n",
      "5e-05 0.32372881355932204\n",
      "5e-05 0.3254237288135593\n",
      "5e-05 0.3271186440677966\n",
      "5e-05 0.3288135593220339\n",
      "5e-05 0.3305084745762712\n",
      "5e-05 0.33220338983050846\n",
      "5e-05 0.3338983050847458\n",
      "5e-05 0.33559322033898303\n",
      "5e-05 0.33728813559322035\n",
      "5e-05 0.3389830508474576\n",
      "5e-05 0.34067796610169493\n",
      "5e-05 0.3423728813559322\n",
      "5e-05 0.3440677966101695\n",
      "5e-05 0.34576271186440677\n",
      "5e-05 0.3474576271186441\n",
      "5e-05 0.34915254237288135\n",
      "5e-05 0.35084745762711866\n",
      "5e-05 0.3525423728813559\n",
      "5e-05 0.35423728813559324\n",
      "5e-05 0.3559322033898305\n",
      "5e-05 0.3576271186440678\n",
      "5e-05 0.3593220338983051\n",
      "5e-05 0.3610169491525424\n",
      "5e-05 0.36271186440677966\n",
      "5e-05 0.3644067796610169\n",
      "5e-05 0.36610169491525424\n",
      "5e-05 0.3677966101694915\n",
      "5e-05 0.3694915254237288\n",
      "5e-05 0.3711864406779661\n",
      "5e-05 0.3728813559322034\n",
      "5e-05 0.37457627118644066\n",
      "5e-05 0.376271186440678\n",
      "5e-05 0.37796610169491524\n",
      "5e-05 0.37966101694915255\n",
      "5e-05 0.3813559322033898\n",
      "5e-05 0.38305084745762713\n",
      "5e-05 0.3847457627118644\n",
      "5e-05 0.3864406779661017\n",
      "5e-05 0.38813559322033897\n",
      "5e-05 0.3898305084745763\n",
      "5e-05 0.39152542372881355\n",
      "5e-05 0.39322033898305087\n",
      "5e-05 0.3949152542372881\n",
      "5e-05 0.39661016949152544\n",
      "5e-05 0.3983050847457627\n",
      "Epoch: 02 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 5.286 | Train Acc @1:   0.90% | Train Acc @5:   3.45%\n",
      "\tValid Loss: 5.276 | Valid Acc @1:   0.73% | Valid Acc @5:   3.82%\n",
      "5e-05 0.4\n",
      "5e-05 0.4016949152542373\n",
      "5e-05 0.4033898305084746\n",
      "5e-05 0.40508474576271186\n",
      "5e-05 0.4067796610169492\n",
      "5e-05 0.40847457627118644\n",
      "5e-05 0.4101694915254237\n",
      "5e-05 0.411864406779661\n",
      "5e-05 0.4135593220338983\n",
      "5e-05 0.4152542372881356\n",
      "5e-05 0.41694915254237286\n",
      "5e-05 0.4186440677966102\n",
      "5e-05 0.42033898305084744\n",
      "5e-05 0.42203389830508475\n",
      "5e-05 0.423728813559322\n",
      "5e-05 0.42542372881355933\n",
      "5e-05 0.4271186440677966\n",
      "5e-05 0.4288135593220339\n",
      "5e-05 0.43050847457627117\n",
      "5e-05 0.4322033898305085\n",
      "5e-05 0.43389830508474575\n",
      "5e-05 0.43559322033898307\n",
      "5e-05 0.43728813559322033\n",
      "5e-05 0.43898305084745765\n",
      "5e-05 0.4406779661016949\n",
      "5e-05 0.4423728813559322\n",
      "5e-05 0.4440677966101695\n",
      "5e-05 0.4457627118644068\n",
      "5e-05 0.44745762711864406\n",
      "5e-05 0.4491525423728814\n",
      "5e-05 0.45084745762711864\n",
      "5e-05 0.45254237288135596\n",
      "5e-05 0.4542372881355932\n",
      "5e-05 0.4559322033898305\n",
      "5e-05 0.4576271186440678\n",
      "5e-05 0.45932203389830506\n",
      "5e-05 0.4610169491525424\n",
      "5e-05 0.46271186440677964\n",
      "5e-05 0.46440677966101696\n",
      "5e-05 0.4661016949152542\n",
      "5e-05 0.46779661016949153\n",
      "5e-05 0.4694915254237288\n",
      "5e-05 0.4711864406779661\n",
      "5e-05 0.4728813559322034\n",
      "5e-05 0.4745762711864407\n",
      "5e-05 0.47627118644067795\n",
      "5e-05 0.47796610169491527\n",
      "5e-05 0.47966101694915253\n",
      "5e-05 0.48135593220338985\n",
      "5e-05 0.4830508474576271\n",
      "5e-05 0.4847457627118644\n",
      "5e-05 0.4864406779661017\n",
      "5e-05 0.488135593220339\n",
      "5e-05 0.48983050847457626\n",
      "5e-05 0.4915254237288136\n",
      "5e-05 0.49322033898305084\n",
      "5e-05 0.49491525423728816\n",
      "5e-05 0.4966101694915254\n",
      "5e-05 0.49830508474576274\n",
      "5e-05 0.5\n",
      "5e-05 0.5016949152542373\n",
      "5e-05 0.5033898305084745\n",
      "5e-05 0.5050847457627119\n",
      "5e-05 0.5067796610169492\n",
      "5e-05 0.5084745762711864\n",
      "5e-05 0.5101694915254237\n",
      "5e-05 0.511864406779661\n",
      "5e-05 0.5135593220338983\n",
      "5e-05 0.5152542372881356\n",
      "5e-05 0.5169491525423728\n",
      "5e-05 0.5186440677966102\n",
      "5e-05 0.5203389830508475\n",
      "5e-05 0.5220338983050847\n",
      "5e-05 0.523728813559322\n",
      "5e-05 0.5254237288135594\n",
      "5e-05 0.5271186440677966\n",
      "5e-05 0.5288135593220339\n",
      "5e-05 0.5305084745762711\n",
      "5e-05 0.5322033898305085\n",
      "5e-05 0.5338983050847458\n",
      "5e-05 0.535593220338983\n",
      "5e-05 0.5372881355932203\n",
      "5e-05 0.5389830508474577\n",
      "5e-05 0.5406779661016949\n",
      "5e-05 0.5423728813559322\n",
      "5e-05 0.5440677966101695\n",
      "5e-05 0.5457627118644067\n",
      "5e-05 0.5474576271186441\n",
      "5e-05 0.5491525423728814\n",
      "5e-05 0.5508474576271186\n",
      "5e-05 0.5525423728813559\n",
      "5e-05 0.5542372881355933\n",
      "5e-05 0.5559322033898305\n",
      "5e-05 0.5576271186440678\n",
      "5e-05 0.559322033898305\n",
      "5e-05 0.5610169491525424\n",
      "5e-05 0.5627118644067797\n",
      "5e-05 0.5644067796610169\n",
      "5e-05 0.5661016949152542\n",
      "5e-05 0.5677966101694916\n",
      "5e-05 0.5694915254237288\n",
      "5e-05 0.5711864406779661\n",
      "5e-05 0.5728813559322034\n",
      "5e-05 0.5745762711864407\n",
      "5e-05 0.576271186440678\n",
      "5e-05 0.5779661016949152\n",
      "5e-05 0.5796610169491525\n",
      "5e-05 0.5813559322033899\n",
      "5e-05 0.5830508474576271\n",
      "5e-05 0.5847457627118644\n",
      "5e-05 0.5864406779661017\n",
      "5e-05 0.588135593220339\n",
      "5e-05 0.5898305084745763\n",
      "5e-05 0.5915254237288136\n",
      "5e-05 0.5932203389830508\n",
      "5e-05 0.5949152542372881\n",
      "5e-05 0.5966101694915255\n",
      "5e-05 0.5983050847457627\n",
      "Epoch: 03 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 5.226 | Train Acc @1:   1.23% | Train Acc @5:   5.15%\n",
      "\tValid Loss: 5.182 | Valid Acc @1:   1.61% | Valid Acc @5:   5.73%\n",
      "5e-05 0.6\n",
      "5e-05 0.6016949152542372\n",
      "5e-05 0.6033898305084746\n",
      "5e-05 0.6050847457627119\n",
      "5e-05 0.6067796610169491\n",
      "5e-05 0.6084745762711864\n",
      "5e-05 0.6101694915254238\n",
      "5e-05 0.611864406779661\n",
      "5e-05 0.6135593220338983\n",
      "5e-05 0.6152542372881356\n",
      "5e-05 0.6169491525423729\n",
      "5e-05 0.6186440677966102\n",
      "5e-05 0.6203389830508474\n",
      "5e-05 0.6220338983050847\n",
      "5e-05 0.6237288135593221\n",
      "5e-05 0.6254237288135593\n",
      "5e-05 0.6271186440677966\n",
      "5e-05 0.6288135593220339\n",
      "5e-05 0.6305084745762712\n",
      "5e-05 0.6322033898305085\n",
      "5e-05 0.6338983050847458\n",
      "5e-05 0.635593220338983\n",
      "5e-05 0.6372881355932203\n",
      "5e-05 0.6389830508474577\n",
      "5e-05 0.6406779661016949\n",
      "5e-05 0.6423728813559322\n",
      "5e-05 0.6440677966101694\n",
      "5e-05 0.6457627118644068\n",
      "5e-05 0.6474576271186441\n",
      "5e-05 0.6491525423728813\n",
      "5e-05 0.6508474576271186\n",
      "5e-05 0.652542372881356\n",
      "5e-05 0.6542372881355932\n",
      "5e-05 0.6559322033898305\n",
      "5e-05 0.6576271186440678\n",
      "5e-05 0.6593220338983051\n",
      "5e-05 0.6610169491525424\n",
      "5e-05 0.6627118644067796\n",
      "5e-05 0.6644067796610169\n",
      "5e-05 0.6661016949152543\n",
      "5e-05 0.6677966101694915\n",
      "5e-05 0.6694915254237288\n",
      "5e-05 0.6711864406779661\n",
      "5e-05 0.6728813559322034\n",
      "5e-05 0.6745762711864407\n",
      "5e-05 0.676271186440678\n",
      "5e-05 0.6779661016949152\n",
      "5e-05 0.6796610169491526\n",
      "5e-05 0.6813559322033899\n",
      "5e-05 0.6830508474576271\n",
      "5e-05 0.6847457627118644\n",
      "5e-05 0.6864406779661016\n",
      "5e-05 0.688135593220339\n",
      "5e-05 0.6898305084745763\n",
      "5e-05 0.6915254237288135\n",
      "5e-05 0.6932203389830508\n",
      "5e-05 0.6949152542372882\n",
      "5e-05 0.6966101694915254\n",
      "5e-05 0.6983050847457627\n",
      "5e-05 0.7\n",
      "5e-05 0.7016949152542373\n",
      "5e-05 0.7033898305084746\n",
      "5e-05 0.7050847457627119\n",
      "5e-05 0.7067796610169491\n",
      "5e-05 0.7084745762711865\n",
      "5e-05 0.7101694915254237\n",
      "5e-05 0.711864406779661\n",
      "5e-05 0.7135593220338983\n",
      "5e-05 0.7152542372881356\n",
      "5e-05 0.7169491525423729\n",
      "5e-05 0.7186440677966102\n",
      "5e-05 0.7203389830508474\n",
      "5e-05 0.7220338983050848\n",
      "5e-05 0.7237288135593221\n",
      "5e-05 0.7254237288135593\n",
      "5e-05 0.7271186440677966\n",
      "5e-05 0.7288135593220338\n",
      "5e-05 0.7305084745762712\n",
      "5e-05 0.7322033898305085\n",
      "5e-05 0.7338983050847457\n",
      "5e-05 0.735593220338983\n",
      "5e-05 0.7372881355932204\n",
      "5e-05 0.7389830508474576\n",
      "5e-05 0.7406779661016949\n",
      "5e-05 0.7423728813559322\n",
      "5e-05 0.7440677966101695\n",
      "5e-05 0.7457627118644068\n",
      "5e-05 0.747457627118644\n",
      "5e-05 0.7491525423728813\n",
      "5e-05 0.7508474576271187\n",
      "5e-05 0.752542372881356\n",
      "5e-05 0.7542372881355932\n",
      "5e-05 0.7559322033898305\n",
      "5e-05 0.7576271186440678\n",
      "5e-05 0.7593220338983051\n",
      "5e-05 0.7610169491525424\n",
      "5e-05 0.7627118644067796\n",
      "5e-05 0.764406779661017\n",
      "5e-05 0.7661016949152543\n",
      "5e-05 0.7677966101694915\n",
      "5e-05 0.7694915254237288\n",
      "5e-05 0.7711864406779662\n",
      "5e-05 0.7728813559322034\n",
      "5e-05 0.7745762711864407\n",
      "5e-05 0.7762711864406779\n",
      "5e-05 0.7779661016949152\n",
      "5e-05 0.7796610169491526\n",
      "5e-05 0.7813559322033898\n",
      "5e-05 0.7830508474576271\n",
      "5e-05 0.7847457627118644\n",
      "5e-05 0.7864406779661017\n",
      "5e-05 0.788135593220339\n",
      "5e-05 0.7898305084745763\n",
      "5e-05 0.7915254237288135\n",
      "5e-05 0.7932203389830509\n",
      "5e-05 0.7949152542372881\n",
      "5e-05 0.7966101694915254\n",
      "5e-05 0.7983050847457627\n",
      "Epoch: 04 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 5.062 | Train Acc @1:   1.60% | Train Acc @5:   7.15%\n",
      "\tValid Loss: 5.003 | Valid Acc @1:   2.08% | Valid Acc @5:   8.07%\n",
      "5e-05 0.8\n",
      "5e-05 0.8016949152542373\n",
      "5e-05 0.8033898305084746\n",
      "5e-05 0.8050847457627118\n",
      "5e-05 0.8067796610169492\n",
      "5e-05 0.8084745762711865\n",
      "5e-05 0.8101694915254237\n",
      "5e-05 0.811864406779661\n",
      "5e-05 0.8135593220338984\n",
      "5e-05 0.8152542372881356\n",
      "5e-05 0.8169491525423729\n",
      "5e-05 0.8186440677966101\n",
      "5e-05 0.8203389830508474\n",
      "5e-05 0.8220338983050848\n",
      "5e-05 0.823728813559322\n",
      "5e-05 0.8254237288135593\n",
      "5e-05 0.8271186440677966\n",
      "5e-05 0.8288135593220339\n",
      "5e-05 0.8305084745762712\n",
      "5e-05 0.8322033898305085\n",
      "5e-05 0.8338983050847457\n",
      "5e-05 0.8355932203389831\n",
      "5e-05 0.8372881355932204\n",
      "5e-05 0.8389830508474576\n",
      "5e-05 0.8406779661016949\n",
      "5e-05 0.8423728813559322\n",
      "5e-05 0.8440677966101695\n",
      "5e-05 0.8457627118644068\n",
      "5e-05 0.847457627118644\n",
      "5e-05 0.8491525423728814\n",
      "5e-05 0.8508474576271187\n",
      "5e-05 0.8525423728813559\n",
      "5e-05 0.8542372881355932\n",
      "5e-05 0.8559322033898306\n",
      "5e-05 0.8576271186440678\n",
      "5e-05 0.8593220338983051\n",
      "5e-05 0.8610169491525423\n",
      "5e-05 0.8627118644067797\n",
      "5e-05 0.864406779661017\n",
      "5e-05 0.8661016949152542\n",
      "5e-05 0.8677966101694915\n",
      "5e-05 0.8694915254237288\n",
      "5e-05 0.8711864406779661\n",
      "5e-05 0.8728813559322034\n",
      "5e-05 0.8745762711864407\n",
      "5e-05 0.8762711864406779\n",
      "5e-05 0.8779661016949153\n",
      "5e-05 0.8796610169491526\n",
      "5e-05 0.8813559322033898\n",
      "5e-05 0.8830508474576271\n",
      "5e-05 0.8847457627118644\n",
      "5e-05 0.8864406779661017\n",
      "5e-05 0.888135593220339\n",
      "5e-05 0.8898305084745762\n",
      "5e-05 0.8915254237288136\n",
      "5e-05 0.8932203389830509\n",
      "5e-05 0.8949152542372881\n",
      "5e-05 0.8966101694915254\n",
      "5e-05 0.8983050847457628\n",
      "5e-05 0.9\n",
      "5e-05 0.9016949152542373\n",
      "5e-05 0.9033898305084745\n",
      "5e-05 0.9050847457627119\n",
      "5e-05 0.9067796610169492\n",
      "5e-05 0.9084745762711864\n",
      "5e-05 0.9101694915254237\n",
      "5e-05 0.911864406779661\n",
      "5e-05 0.9135593220338983\n",
      "5e-05 0.9152542372881356\n",
      "5e-05 0.9169491525423729\n",
      "5e-05 0.9186440677966101\n",
      "5e-05 0.9203389830508475\n",
      "5e-05 0.9220338983050848\n",
      "5e-05 0.923728813559322\n",
      "5e-05 0.9254237288135593\n",
      "5e-05 0.9271186440677966\n",
      "5e-05 0.9288135593220339\n",
      "5e-05 0.9305084745762712\n",
      "5e-05 0.9322033898305084\n",
      "5e-05 0.9338983050847458\n",
      "5e-05 0.9355932203389831\n",
      "5e-05 0.9372881355932203\n",
      "5e-05 0.9389830508474576\n",
      "5e-05 0.940677966101695\n",
      "5e-05 0.9423728813559322\n",
      "5e-05 0.9440677966101695\n",
      "5e-05 0.9457627118644067\n",
      "5e-05 0.9474576271186441\n",
      "5e-05 0.9491525423728814\n",
      "5e-05 0.9508474576271186\n",
      "5e-05 0.9525423728813559\n",
      "5e-05 0.9542372881355933\n",
      "5e-05 0.9559322033898305\n",
      "5e-05 0.9576271186440678\n",
      "5e-05 0.9593220338983051\n",
      "5e-05 0.9610169491525423\n",
      "5e-05 0.9627118644067797\n",
      "5e-05 0.964406779661017\n",
      "5e-05 0.9661016949152542\n",
      "5e-05 0.9677966101694915\n",
      "5e-05 0.9694915254237289\n",
      "5e-05 0.9711864406779661\n",
      "5e-05 0.9728813559322034\n",
      "5e-05 0.9745762711864406\n",
      "5e-05 0.976271186440678\n",
      "5e-05 0.9779661016949153\n",
      "5e-05 0.9796610169491525\n",
      "5e-05 0.9813559322033898\n",
      "5e-05 0.9830508474576272\n",
      "5e-05 0.9847457627118644\n",
      "5e-05 0.9864406779661017\n",
      "5e-05 0.988135593220339\n",
      "5e-05 0.9898305084745763\n",
      "5e-05 0.9915254237288136\n",
      "5e-05 0.9932203389830508\n",
      "5e-05 0.9949152542372881\n",
      "5e-05 0.9966101694915255\n",
      "5e-05 0.9983050847457627\n",
      "Epoch: 05 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 4.889 | Train Acc @1:   2.66% | Train Acc @5:  10.64%\n",
      "\tValid Loss: 4.921 | Valid Acc @1:   2.19% | Valid Acc @5:  11.26%\n",
      "5e-05 1.0\n",
      "5e-05 0.9999999803651076\n",
      "5e-05 0.9999999214604318\n",
      "5e-05 0.9999998232859775\n",
      "5e-05 0.9999996858417521\n",
      "5e-05 0.9999995091277667\n",
      "5e-05 0.9999992931440349\n",
      "5e-05 0.9999990378905739\n",
      "5e-05 0.9999987433674035\n",
      "5e-05 0.999998409574547\n",
      "5e-05 0.9999980365120306\n",
      "5e-05 0.9999976241798836\n",
      "5e-05 0.9999971725781382\n",
      "5e-05 0.9999966817068302\n",
      "5e-05 0.999996151565998\n",
      "5e-05 0.9999955821556832\n",
      "5e-05 0.9999949734759305\n",
      "5e-05 0.9999943255267878\n",
      "5e-05 0.9999936383083059\n",
      "5e-05 0.9999929118205387\n",
      "5e-05 0.9999921460635435\n",
      "5e-05 0.9999913410373803\n",
      "5e-05 0.9999904967421123\n",
      "5e-05 0.9999896131778059\n",
      "5e-05 0.9999886903445304\n",
      "5e-05 0.9999877282423584\n",
      "5e-05 0.9999867268713653\n",
      "5e-05 0.9999856862316299\n",
      "5e-05 0.9999846063232338\n",
      "5e-05 0.9999834871462618\n",
      "5e-05 0.9999823287008021\n",
      "5e-05 0.9999811309869453\n",
      "5e-05 0.9999798940047857\n",
      "5e-05 0.9999786177544203\n",
      "5e-05 0.9999773022359495\n",
      "5e-05 0.9999759474494765\n",
      "5e-05 0.9999745533951078\n",
      "5e-05 0.9999731200729527\n",
      "5e-05 0.9999716474831241\n",
      "5e-05 0.9999701356257373\n",
      "5e-05 0.9999685845009112\n",
      "5e-05 0.9999669941087678\n",
      "5e-05 0.9999653644494317\n",
      "5e-05 0.9999636955230311\n",
      "5e-05 0.9999619873296969\n",
      "5e-05 0.9999602398695634\n",
      "5e-05 0.9999584531427679\n",
      "5e-05 0.9999566271494504\n",
      "5e-05 0.9999547618897549\n",
      "5e-05 0.9999528573638273\n",
      "5e-05 0.9999509135718175\n",
      "5e-05 0.9999489305138781\n",
      "5e-05 0.9999469081901649\n",
      "5e-05 0.9999448466008365\n",
      "5e-05 0.9999427457460551\n",
      "5e-05 0.9999406056259856\n",
      "5e-05 0.9999384262407961\n",
      "5e-05 0.9999362075906577\n",
      "5e-05 0.9999339496757447\n",
      "5e-05 0.9999316524962345\n",
      "5e-05 0.9999293160523074\n",
      "5e-05 0.9999269403441469\n",
      "5e-05 0.9999245253719398\n",
      "5e-05 0.9999220711358754\n",
      "5e-05 0.9999195776361467\n",
      "5e-05 0.9999170448729496\n",
      "5e-05 0.9999144728464829\n",
      "5e-05 0.9999118615569487\n",
      "5e-05 0.9999092110045519\n",
      "5e-05 0.9999065211895009\n",
      "5e-05 0.9999037921120068\n",
      "5e-05 0.9999010237722838\n",
      "5e-05 0.9998982161705499\n",
      "5e-05 0.9998953693070249\n",
      "5e-05 0.9998924831819329\n",
      "5e-05 0.9998895577955004\n",
      "5e-05 0.999886593147957\n",
      "5e-05 0.9998835892395359\n",
      "5e-05 0.9998805460704726\n",
      "5e-05 0.9998774636410064\n",
      "5e-05 0.9998743419513794\n",
      "5e-05 0.9998711810018366\n",
      "5e-05 0.9998679807926265\n",
      "5e-05 0.9998647413240002\n",
      "5e-05 0.9998614625962121\n",
      "5e-05 0.99985814460952\n",
      "5e-05 0.9998547873641843\n",
      "5e-05 0.9998513908604687\n",
      "5e-05 0.9998479550986399\n",
      "5e-05 0.9998444800789679\n",
      "5e-05 0.9998409658017255\n",
      "5e-05 0.9998374122671887\n",
      "5e-05 0.9998338194756368\n",
      "5e-05 0.9998301874273516\n",
      "5e-05 0.9998265161226187\n",
      "5e-05 0.9998228055617263\n",
      "5e-05 0.9998190557449658\n",
      "5e-05 0.9998152666726318\n",
      "5e-05 0.9998114383450218\n",
      "5e-05 0.9998075707624365\n",
      "5e-05 0.9998036639251797\n",
      "5e-05 0.9997997178335583\n",
      "5e-05 0.9997957324878821\n",
      "5e-05 0.9997917078884642\n",
      "5e-05 0.9997876440356204\n",
      "5e-05 0.9997835409296703\n",
      "5e-05 0.999779398570936\n",
      "5e-05 0.9997752169597427\n",
      "5e-05 0.999770996096419\n",
      "5e-05 0.9997667359812963\n",
      "5e-05 0.9997624366147093\n",
      "5e-05 0.9997580979969956\n",
      "5e-05 0.9997537201284958\n",
      "5e-05 0.9997493030095539\n",
      "5e-05 0.9997448466405169\n",
      "5e-05 0.9997403510217346\n",
      "5e-05 0.9997358161535603\n",
      "5e-05 0.99973124203635\n",
      "Epoch: 06 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 4.723 | Train Acc @1:   3.60% | Train Acc @5:  13.47%\n",
      "\tValid Loss: 4.712 | Valid Acc @1:   3.51% | Valid Acc @5:  13.79%\n",
      "5e-05 0.999726628670463\n",
      "5e-05 0.9997219760562617\n",
      "5e-05 0.9997172841941113\n",
      "5e-05 0.9997125530843806\n",
      "5e-05 0.999707782727441\n",
      "5e-05 0.9997029731236671\n",
      "5e-05 0.9996981242734367\n",
      "5e-05 0.9996932361771307\n",
      "5e-05 0.999688308835133\n",
      "5e-05 0.9996833422478306\n",
      "5e-05 0.9996783364156134\n",
      "5e-05 0.9996732913388748\n",
      "5e-05 0.999668207018011\n",
      "5e-05 0.999663083453421\n",
      "5e-05 0.9996579206455076\n",
      "5e-05 0.9996527185946762\n",
      "5e-05 0.9996474773013352\n",
      "5e-05 0.9996421967658964\n",
      "5e-05 0.9996368769887743\n",
      "5e-05 0.9996315179703871\n",
      "5e-05 0.9996261197111553\n",
      "5e-05 0.9996206822115032\n",
      "5e-05 0.9996152054718578\n",
      "5e-05 0.9996096894926491\n",
      "5e-05 0.9996041342743103\n",
      "5e-05 0.9995985398172779\n",
      "5e-05 0.999592906121991\n",
      "5e-05 0.9995872331888924\n",
      "5e-05 0.9995815210184276\n",
      "5e-05 0.9995757696110449\n",
      "5e-05 0.9995699789671963\n",
      "5e-05 0.9995641490873366\n",
      "5e-05 0.9995582799719236\n",
      "5e-05 0.9995523716214182\n",
      "5e-05 0.9995464240362846\n",
      "5e-05 0.9995404372169897\n",
      "5e-05 0.9995344111640039\n",
      "5e-05 0.9995283458778004\n",
      "5e-05 0.9995222413588556\n",
      "5e-05 0.9995160976076489\n",
      "5e-05 0.9995099146246629\n",
      "5e-05 0.9995036924103832\n",
      "5e-05 0.9994974309652984\n",
      "5e-05 0.9994911302899003\n",
      "5e-05 0.9994847903846837\n",
      "5e-05 0.9994784112501467\n",
      "5e-05 0.9994719928867903\n",
      "5e-05 0.9994655352951184\n",
      "5e-05 0.9994590384756383\n",
      "5e-05 0.9994525024288603\n",
      "5e-05 0.9994459271552977\n",
      "5e-05 0.9994393126554668\n",
      "5e-05 0.9994326589298874\n",
      "5e-05 0.9994259659790817\n",
      "5e-05 0.9994192338035757\n",
      "5e-05 0.9994124624038978\n",
      "5e-05 0.9994056517805803\n",
      "5e-05 0.9993988019341575\n",
      "5e-05 0.999391912865168\n",
      "5e-05 0.9993849845741524\n",
      "5e-05 0.9993780170616551\n",
      "5e-05 0.9993710103282232\n",
      "5e-05 0.999363964374407\n",
      "5e-05 0.9993568792007599\n",
      "5e-05 0.9993497548078385\n",
      "5e-05 0.9993425911962022\n",
      "5e-05 0.9993353883664137\n",
      "5e-05 0.9993281463190387\n",
      "5e-05 0.9993208650546459\n",
      "5e-05 0.9993135445738073\n",
      "5e-05 0.9993061848770977\n",
      "5e-05 0.9992987859650952\n",
      "5e-05 0.9992913478383809\n",
      "5e-05 0.9992838704975391\n",
      "5e-05 0.999276353943157\n",
      "5e-05 0.9992687981758248\n",
      "5e-05 0.9992612031961361\n",
      "5e-05 0.9992535690046873\n",
      "5e-05 0.9992458956020782\n",
      "5e-05 0.9992381829889112\n",
      "5e-05 0.999230431165792\n",
      "5e-05 0.9992226401333297\n",
      "5e-05 0.9992148098921361\n",
      "5e-05 0.9992069404428261\n",
      "5e-05 0.999199031786018\n",
      "5e-05 0.9991910839223326\n",
      "5e-05 0.9991830968523943\n",
      "5e-05 0.9991750705768303\n",
      "5e-05 0.9991670050962713\n",
      "5e-05 0.9991589004113504\n",
      "5e-05 0.9991507565227042\n",
      "5e-05 0.9991425734309725\n",
      "5e-05 0.9991343511367978\n",
      "5e-05 0.999126089640826\n",
      "5e-05 0.999117788943706\n",
      "5e-05 0.9991094490460894\n",
      "5e-05 0.9991010699486316\n",
      "5e-05 0.9990926516519906\n",
      "5e-05 0.9990841941568274\n",
      "5e-05 0.9990756974638064\n",
      "5e-05 0.9990671615735949\n",
      "5e-05 0.9990585864868633\n",
      "5e-05 0.9990499722042852\n",
      "5e-05 0.9990413187265369\n",
      "5e-05 0.9990326260542981\n",
      "5e-05 0.9990238941882518\n",
      "5e-05 0.9990151231290836\n",
      "5e-05 0.9990063128774822\n",
      "5e-05 0.9989974634341399\n",
      "5e-05 0.9989885747997513\n",
      "5e-05 0.998979646975015\n",
      "5e-05 0.9989706799606319\n",
      "5e-05 0.9989616737573063\n",
      "5e-05 0.9989526283657455\n",
      "5e-05 0.9989435437866601\n",
      "5e-05 0.9989344200207635\n",
      "5e-05 0.9989252570687721\n",
      "5e-05 0.9989160549314058\n",
      "Epoch: 07 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 4.539 | Train Acc @1:   5.35% | Train Acc @5:  17.66%\n",
      "\tValid Loss: 4.584 | Valid Acc @1:   4.65% | Valid Acc @5:  17.62%\n",
      "5e-05 0.9989068136093873\n",
      "5e-05 0.9988975331034423\n",
      "5e-05 0.9988882134142998\n",
      "5e-05 0.9988788545426917\n",
      "5e-05 0.998869456489353\n",
      "5e-05 0.9988600192550218\n",
      "5e-05 0.9988505428404395\n",
      "5e-05 0.9988410272463502\n",
      "5e-05 0.9988314724735012\n",
      "5e-05 0.998821878522643\n",
      "5e-05 0.9988122453945293\n",
      "5e-05 0.9988025730899164\n",
      "5e-05 0.998792861609564\n",
      "5e-05 0.998783110954235\n",
      "5e-05 0.9987733211246951\n",
      "5e-05 0.9987634921217131\n",
      "5e-05 0.9987536239460612\n",
      "5e-05 0.9987437165985142\n",
      "5e-05 0.9987337700798504\n",
      "5e-05 0.9987237843908509\n",
      "5e-05 0.9987137595322999\n",
      "5e-05 0.998703695504985\n",
      "5e-05 0.9986935923096963\n",
      "5e-05 0.9986834499472276\n",
      "5e-05 0.9986732684183752\n",
      "5e-05 0.9986630477239391\n",
      "5e-05 0.9986527878647217\n",
      "5e-05 0.9986424888415288\n",
      "5e-05 0.9986321506551696\n",
      "5e-05 0.9986217733064557\n",
      "5e-05 0.9986113567962025\n",
      "5e-05 0.9986009011252278\n",
      "5e-05 0.9985904062943529\n",
      "5e-05 0.9985798723044021\n",
      "5e-05 0.9985692991562026\n",
      "5e-05 0.9985586868505849\n",
      "5e-05 0.9985480353883825\n",
      "5e-05 0.998537344770432\n",
      "5e-05 0.9985266149975729\n",
      "5e-05 0.998515846070648\n",
      "5e-05 0.9985050379905032\n",
      "5e-05 0.9984941907579872\n",
      "5e-05 0.9984833043739518\n",
      "5e-05 0.9984723788392524\n",
      "5e-05 0.9984614141547468\n",
      "5e-05 0.9984504103212961\n",
      "5e-05 0.9984393673397649\n",
      "5e-05 0.9984282852110202\n",
      "5e-05 0.9984171639359324\n",
      "5e-05 0.998406003515375\n",
      "5e-05 0.9983948039502247\n",
      "5e-05 0.998383565241361\n",
      "5e-05 0.9983722873896664\n",
      "5e-05 0.9983609703960269\n",
      "5e-05 0.9983496142613313\n",
      "5e-05 0.9983382189864713\n",
      "5e-05 0.9983267845723421\n",
      "5e-05 0.9983153110198417\n",
      "5e-05 0.9983037983298713\n",
      "5e-05 0.9982922465033349\n",
      "5e-05 0.99828065554114\n",
      "5e-05 0.9982690254441967\n",
      "5e-05 0.9982573562134187\n",
      "5e-05 0.9982456478497223\n",
      "5e-05 0.998233900354027\n",
      "5e-05 0.9982221137272558\n",
      "5e-05 0.9982102879703341\n",
      "5e-05 0.9981984230841907\n",
      "5e-05 0.9981865190697576\n",
      "5e-05 0.9981745759279697\n",
      "5e-05 0.998162593659765\n",
      "5e-05 0.9981505722660846\n",
      "5e-05 0.9981385117478725\n",
      "5e-05 0.9981264121060762\n",
      "5e-05 0.9981142733416457\n",
      "5e-05 0.9981020954555346\n",
      "5e-05 0.9980898784486993\n",
      "5e-05 0.9980776223220993\n",
      "5e-05 0.9980653270766972\n",
      "5e-05 0.9980529927134585\n",
      "5e-05 0.9980406192333522\n",
      "5e-05 0.99802820663735\n",
      "5e-05 0.9980157549264268\n",
      "5e-05 0.9980032641015604\n",
      "5e-05 0.997990734163732\n",
      "5e-05 0.9979781651139257\n",
      "5e-05 0.9979655569531285\n",
      "5e-05 0.9979529096823307\n",
      "5e-05 0.9979402233025259\n",
      "5e-05 0.9979274978147101\n",
      "5e-05 0.9979147332198829\n",
      "5e-05 0.9979019295190468\n",
      "5e-05 0.9978890867132074\n",
      "5e-05 0.9978762048033735\n",
      "5e-05 0.9978632837905566\n",
      "5e-05 0.9978503236757716\n",
      "5e-05 0.9978373244600367\n",
      "5e-05 0.9978242861443724\n",
      "5e-05 0.9978112087298028\n",
      "5e-05 0.9977980922173553\n",
      "5e-05 0.9977849366080596\n",
      "5e-05 0.9977717419029494\n",
      "5e-05 0.9977585081030607\n",
      "5e-05 0.9977452352094329\n",
      "5e-05 0.9977319232231088\n",
      "5e-05 0.9977185721451334\n",
      "5e-05 0.9977051819765557\n",
      "5e-05 0.997691752718427\n",
      "5e-05 0.9976782843718023\n",
      "5e-05 0.9976647769377393\n",
      "5e-05 0.9976512304172989\n",
      "5e-05 0.9976376448115449\n",
      "5e-05 0.9976240201215446\n",
      "5e-05 0.9976103563483678\n",
      "5e-05 0.9975966534930878\n",
      "5e-05 0.9975829115567808\n",
      "5e-05 0.9975691305405261\n",
      "5e-05 0.9975553104454058\n",
      "Epoch: 08 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 4.327 | Train Acc @1:   7.27% | Train Acc @5:  24.03%\n",
      "\tValid Loss: 4.504 | Valid Acc @1:   6.55% | Valid Acc @5:  20.67%\n",
      "5e-05 0.9975414512725057\n",
      "5e-05 0.9975275530229141\n",
      "5e-05 0.9975136156977226\n",
      "5e-05 0.9974996392980258\n",
      "5e-05 0.9974856238249213\n",
      "5e-05 0.9974715692795102\n",
      "5e-05 0.997457475662896\n",
      "5e-05 0.9974433429761858\n",
      "5e-05 0.9974291712204895\n",
      "5e-05 0.99741496039692\n",
      "5e-05 0.9974007105065937\n",
      "5e-05 0.9973864215506296\n",
      "5e-05 0.9973720935301501\n",
      "5e-05 0.9973577264462803\n",
      "5e-05 0.9973433203001487\n",
      "5e-05 0.9973288750928868\n",
      "5e-05 0.997314390825629\n",
      "5e-05 0.997299867499513\n",
      "5e-05 0.9972853051156795\n",
      "5e-05 0.997270703675272\n",
      "5e-05 0.9972560631794375\n",
      "5e-05 0.9972413836293258\n",
      "5e-05 0.9972266650260897\n",
      "5e-05 0.9972119073708854\n",
      "5e-05 0.9971971106648718\n",
      "5e-05 0.9971822749092112\n",
      "5e-05 0.9971674001050685\n",
      "5e-05 0.9971524862536123\n",
      "5e-05 0.9971375333560137\n",
      "5e-05 0.9971225414134472\n",
      "5e-05 0.9971075104270902\n",
      "5e-05 0.9970924403981233\n",
      "5e-05 0.99707733132773\n",
      "5e-05 0.9970621832170969\n",
      "5e-05 0.9970469960674141\n",
      "5e-05 0.997031769879874\n",
      "5e-05 0.9970165046556725\n",
      "5e-05 0.9970012003960087\n",
      "5e-05 0.9969858571020844\n",
      "5e-05 0.9969704747751049\n",
      "5e-05 0.9969550534162781\n",
      "5e-05 0.9969395930268152\n",
      "5e-05 0.9969240936079306\n",
      "5e-05 0.9969085551608414\n",
      "5e-05 0.9968929776867683\n",
      "5e-05 0.9968773611869344\n",
      "5e-05 0.9968617056625665\n",
      "5e-05 0.996846011114894\n",
      "5e-05 0.9968302775451496\n",
      "5e-05 0.9968145049545689\n",
      "5e-05 0.996798693344391\n",
      "5e-05 0.9967828427158574\n",
      "5e-05 0.996766953070213\n",
      "5e-05 0.9967510244087061\n",
      "5e-05 0.9967350567325873\n",
      "5e-05 0.9967190500431111\n",
      "5e-05 0.9967030043415344\n",
      "5e-05 0.9966869196291174\n",
      "5e-05 0.9966707959071235\n",
      "5e-05 0.9966546331768191\n",
      "5e-05 0.9966384314394735\n",
      "5e-05 0.9966221906963593\n",
      "5e-05 0.9966059109487517\n",
      "5e-05 0.9965895921979298\n",
      "5e-05 0.996573234445175\n",
      "5e-05 0.996556837691772\n",
      "5e-05 0.9965404019390086\n",
      "5e-05 0.9965239271881758\n",
      "5e-05 0.9965074134405674\n",
      "5e-05 0.9964908606974805\n",
      "5e-05 0.9964742689602148\n",
      "5e-05 0.9964576382300739\n",
      "5e-05 0.9964409685083637\n",
      "5e-05 0.9964242597963935\n",
      "5e-05 0.9964075120954754\n",
      "5e-05 0.9963907254069251\n",
      "5e-05 0.9963738997320608\n",
      "5e-05 0.996357035072204\n",
      "5e-05 0.9963401314286793\n",
      "5e-05 0.9963231888028141\n",
      "5e-05 0.9963062071959394\n",
      "5e-05 0.9962891866093888\n",
      "5e-05 0.996272127044499\n",
      "5e-05 0.9962550285026097\n",
      "5e-05 0.9962378909850643\n",
      "5e-05 0.9962207144932084\n",
      "5e-05 0.9962034990283911\n",
      "5e-05 0.9961862445919645\n",
      "5e-05 0.9961689511852838\n",
      "5e-05 0.9961516188097073\n",
      "5e-05 0.996134247466596\n",
      "5e-05 0.9961168371573146\n",
      "5e-05 0.99609938788323\n",
      "5e-05 0.9960818996457133\n",
      "5e-05 0.9960643724461375\n",
      "5e-05 0.9960468062858794\n",
      "5e-05 0.9960292011663185\n",
      "5e-05 0.9960115570888377\n",
      "5e-05 0.9959938740548226\n",
      "5e-05 0.9959761520656623\n",
      "5e-05 0.9959583911227482\n",
      "5e-05 0.9959405912274756\n",
      "5e-05 0.9959227523812423\n",
      "5e-05 0.9959048745854495\n",
      "5e-05 0.9958869578415013\n",
      "5e-05 0.9958690021508048\n",
      "5e-05 0.9958510075147702\n",
      "5e-05 0.9958329739348109\n",
      "5e-05 0.9958149014123432\n",
      "5e-05 0.9957967899487864\n",
      "5e-05 0.9957786395455632\n",
      "5e-05 0.9957604502040989\n",
      "5e-05 0.9957422219258223\n",
      "5e-05 0.9957239547121648\n",
      "5e-05 0.9957056485645613\n",
      "5e-05 0.9956873034844496\n",
      "5e-05 0.9956689194732702\n",
      "5e-05 0.9956504965324673\n",
      "Epoch: 09 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 4.129 | Train Acc @1:   9.47% | Train Acc @5:  29.00%\n",
      "\tValid Loss: 4.163 | Valid Acc @1:  10.01% | Valid Acc @5:  29.98%\n",
      "5e-05 0.9956320346634876\n",
      "5e-05 0.9956135338677812\n",
      "5e-05 0.9955949941468012\n",
      "5e-05 0.9955764155020036\n",
      "5e-05 0.9955577979348476\n",
      "5e-05 0.9955391414467953\n",
      "5e-05 0.9955204460393122\n",
      "5e-05 0.9955017117138665\n",
      "5e-05 0.9954829384719295\n",
      "5e-05 0.9954641263149758\n",
      "5e-05 0.9954452752444829\n",
      "5e-05 0.9954263852619312\n",
      "5e-05 0.9954074563688045\n",
      "5e-05 0.9953884885665891\n",
      "5e-05 0.9953694818567753\n",
      "5e-05 0.9953504362408554\n",
      "5e-05 0.9953313517203255\n",
      "5e-05 0.9953122282966843\n",
      "5e-05 0.9952930659714339\n",
      "5e-05 0.9952738647460793\n",
      "5e-05 0.9952546246221283\n",
      "5e-05 0.9952353456010923\n",
      "5e-05 0.9952160276844855\n",
      "5e-05 0.9951966708738249\n",
      "5e-05 0.9951772751706308\n",
      "5e-05 0.9951578405764266\n",
      "5e-05 0.9951383670927387\n",
      "5e-05 0.9951188547210967\n",
      "5e-05 0.9950993034630328\n",
      "5e-05 0.9950797133200826\n",
      "5e-05 0.9950600842937849\n",
      "5e-05 0.995040416385681\n",
      "5e-05 0.995020709597316\n",
      "5e-05 0.9950009639302375\n",
      "5e-05 0.9949811793859962\n",
      "5e-05 0.9949613559661462\n",
      "5e-05 0.9949414936722443\n",
      "5e-05 0.9949215925058503\n",
      "5e-05 0.9949016524685276\n",
      "5e-05 0.994881673561842\n",
      "5e-05 0.9948616557873627\n",
      "5e-05 0.9948415991466619\n",
      "5e-05 0.994821503641315\n",
      "5e-05 0.9948013692729001\n",
      "5e-05 0.9947811960429984\n",
      "5e-05 0.9947609839531947\n",
      "5e-05 0.9947407330050761\n",
      "5e-05 0.9947204432002332\n",
      "5e-05 0.9947001145402597\n",
      "5e-05 0.9946797470267521\n",
      "5e-05 0.99465934066131\n",
      "5e-05 0.9946388954455362\n",
      "5e-05 0.9946184113810363\n",
      "5e-05 0.9945978884694193\n",
      "5e-05 0.994577326712297\n",
      "5e-05 0.9945567261112842\n",
      "5e-05 0.9945360866679991\n",
      "5e-05 0.9945154083840624\n",
      "5e-05 0.9944946912610985\n",
      "5e-05 0.9944739353007342\n",
      "5e-05 0.9944531405046\n",
      "5e-05 0.9944323068743287\n",
      "5e-05 0.9944114344115569\n",
      "5e-05 0.9943905231179238\n",
      "5e-05 0.9943695729950717\n",
      "5e-05 0.9943485840446462\n",
      "5e-05 0.9943275562682956\n",
      "5e-05 0.9943064896676714\n",
      "5e-05 0.9942853842444282\n",
      "5e-05 0.9942642400002237\n",
      "5e-05 0.9942430569367185\n",
      "5e-05 0.9942218350555763\n",
      "5e-05 0.9942005743584639\n",
      "5e-05 0.9941792748470509\n",
      "5e-05 0.9941579365230104\n",
      "5e-05 0.9941365593880183\n",
      "5e-05 0.9941151434437534\n",
      "5e-05 0.9940936886918977\n",
      "5e-05 0.9940721951341365\n",
      "5e-05 0.9940506627721575\n",
      "5e-05 0.9940290916076522\n",
      "5e-05 0.9940074816423146\n",
      "5e-05 0.9939858328778419\n",
      "5e-05 0.9939641453159345\n",
      "5e-05 0.9939424189582957\n",
      "5e-05 0.9939206538066319\n",
      "5e-05 0.9938988498626525\n",
      "5e-05 0.99387700712807\n",
      "5e-05 0.9938551256045999\n",
      "5e-05 0.9938332052939607\n",
      "5e-05 0.9938112461978741\n",
      "5e-05 0.9937892483180647\n",
      "5e-05 0.9937672116562603\n",
      "5e-05 0.9937451362141915\n",
      "5e-05 0.9937230219935922\n",
      "5e-05 0.9937008689961992\n",
      "5e-05 0.9936786772237525\n",
      "5e-05 0.9936564466779948\n",
      "5e-05 0.9936341773606723\n",
      "5e-05 0.9936118692735338\n",
      "5e-05 0.9935895224183318\n",
      "5e-05 0.9935671367968208\n",
      "5e-05 0.9935447124107595\n",
      "5e-05 0.9935222492619088\n",
      "5e-05 0.9934997473520331\n",
      "5e-05 0.9934772066828994\n",
      "5e-05 0.9934546272562784\n",
      "5e-05 0.9934320090739432\n",
      "5e-05 0.9934093521376706\n",
      "5e-05 0.9933866564492396\n",
      "5e-05 0.993363922010433\n",
      "5e-05 0.9933411488230364\n",
      "5e-05 0.9933183368888381\n",
      "5e-05 0.9932954862096299\n",
      "5e-05 0.9932725967872065\n",
      "5e-05 0.9932496686233656\n",
      "5e-05 0.9932267017199081\n",
      "5e-05 0.9932036960786377\n",
      "Epoch: 10 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 3.919 | Train Acc @1:  11.41% | Train Acc @5:  34.55%\n",
      "\tValid Loss: 4.002 | Valid Acc @1:  10.42% | Valid Acc @5:  32.87%\n",
      "5e-05 0.9931806517013612\n",
      "5e-05 0.9931575685898886\n",
      "5e-05 0.9931344467460327\n",
      "5e-05 0.9931112861716096\n",
      "5e-05 0.9930880868684382\n",
      "5e-05 0.9930648488383408\n",
      "5e-05 0.9930415720831423\n",
      "5e-05 0.9930182566046709\n",
      "5e-05 0.9929949024047577\n",
      "5e-05 0.9929715094852372\n",
      "5e-05 0.9929480778479464\n",
      "5e-05 0.9929246074947257\n",
      "5e-05 0.9929010984274184\n",
      "5e-05 0.992877550647871\n",
      "5e-05 0.9928539641579328\n",
      "5e-05 0.9928303389594564\n",
      "5e-05 0.9928066750542972\n",
      "5e-05 0.9927829724443139\n",
      "5e-05 0.992759231131368\n",
      "5e-05 0.9927354511173241\n",
      "5e-05 0.9927116324040499\n",
      "5e-05 0.9926877749934162\n",
      "5e-05 0.9926638788872966\n",
      "5e-05 0.992639944087568\n",
      "5e-05 0.9926159705961102\n",
      "5e-05 0.992591958414806\n",
      "5e-05 0.9925679075455414\n",
      "5e-05 0.9925438179902053\n",
      "5e-05 0.9925196897506896\n",
      "5e-05 0.9924955228288896\n",
      "5e-05 0.992471317226703\n",
      "5e-05 0.9924470729460313\n",
      "5e-05 0.9924227899887782\n",
      "5e-05 0.9923984683568512\n",
      "5e-05 0.9923741080521602\n",
      "5e-05 0.9923497090766189\n",
      "5e-05 0.9923252714321431\n",
      "5e-05 0.9923007951206525\n",
      "5e-05 0.9922762801440692\n",
      "5e-05 0.9922517265043188\n",
      "5e-05 0.9922271342033295\n",
      "5e-05 0.992202503243033\n",
      "5e-05 0.9921778336253637\n",
      "5e-05 0.9921531253522592\n",
      "5e-05 0.9921283784256599\n",
      "5e-05 0.9921035928475097\n",
      "5e-05 0.992078768619755\n",
      "5e-05 0.9920539057443455\n",
      "5e-05 0.992029004223234\n",
      "5e-05 0.9920040640583763\n",
      "5e-05 0.9919790852517312\n",
      "5e-05 0.9919540678052603\n",
      "5e-05 0.9919290117209287\n",
      "5e-05 0.9919039170007042\n",
      "5e-05 0.9918787836465579\n",
      "5e-05 0.9918536116604635\n",
      "5e-05 0.9918284010443981\n",
      "5e-05 0.9918031518003416\n",
      "5e-05 0.9917778639302772\n",
      "5e-05 0.9917525374361912\n",
      "5e-05 0.9917271723200725\n",
      "5e-05 0.9917017685839131\n",
      "5e-05 0.9916763262297086\n",
      "5e-05 0.9916508452594568\n",
      "5e-05 0.9916253256751594\n",
      "5e-05 0.9915997674788204\n",
      "5e-05 0.9915741706724472\n",
      "5e-05 0.9915485352580502\n",
      "5e-05 0.9915228612376428\n",
      "5e-05 0.9914971486132413\n",
      "5e-05 0.9914713973868653\n",
      "5e-05 0.9914456075605372\n",
      "5e-05 0.9914197791362827\n",
      "5e-05 0.9913939121161301\n",
      "5e-05 0.9913680065021112\n",
      "5e-05 0.9913420622962605\n",
      "5e-05 0.9913160795006156\n",
      "5e-05 0.9912900581172173\n",
      "5e-05 0.9912639981481093\n",
      "5e-05 0.9912378995953381\n",
      "5e-05 0.9912117624609539\n",
      "5e-05 0.9911855867470092\n",
      "5e-05 0.9911593724555599\n",
      "5e-05 0.9911331195886647\n",
      "5e-05 0.9911068281483857\n",
      "5e-05 0.9910804981367878\n",
      "5e-05 0.991054129555939\n",
      "5e-05 0.99102772240791\n",
      "5e-05 0.9910012766947751\n",
      "5e-05 0.9909747924186112\n",
      "5e-05 0.9909482695814984\n",
      "5e-05 0.9909217081855197\n",
      "5e-05 0.9908951082327614\n",
      "5e-05 0.9908684697253125\n",
      "5e-05 0.9908417926652653\n",
      "5e-05 0.9908150770547148\n",
      "5e-05 0.9907883228957595\n",
      "5e-05 0.9907615301905004\n",
      "5e-05 0.9907346989410419\n",
      "5e-05 0.9907078291494914\n",
      "5e-05 0.9906809208179592\n",
      "5e-05 0.9906539739485585\n",
      "5e-05 0.990626988543406\n",
      "5e-05 0.9905999646046209\n",
      "5e-05 0.9905729021343256\n",
      "5e-05 0.9905458011346457\n",
      "5e-05 0.9905186616077097\n",
      "5e-05 0.9904914835556492\n",
      "5e-05 0.9904642669805985\n",
      "5e-05 0.9904370118846955\n",
      "5e-05 0.9904097182700806\n",
      "5e-05 0.9903823861388974\n",
      "5e-05 0.9903550154932926\n",
      "5e-05 0.990327606335416\n",
      "5e-05 0.99030015866742\n",
      "5e-05 0.9902726724914608\n",
      "5e-05 0.9902451478096967\n",
      "5e-05 0.9902175846242898\n",
      "Epoch: 11 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 3.720 | Train Acc @1:  14.25% | Train Acc @5:  39.76%\n",
      "\tValid Loss: 3.964 | Valid Acc @1:  11.52% | Valid Acc @5:  33.75%\n",
      "5e-05 0.9901899829374047\n",
      "5e-05 0.9901623427512092\n",
      "5e-05 0.9901346640678743\n",
      "5e-05 0.9901069468895738\n",
      "5e-05 0.9900791912184846\n",
      "5e-05 0.9900513970567867\n",
      "5e-05 0.9900235644066628\n",
      "5e-05 0.9899956932702991\n",
      "5e-05 0.9899677836498846\n",
      "5e-05 0.9899398355476112\n",
      "5e-05 0.9899118489656739\n",
      "5e-05 0.9898838239062708\n",
      "5e-05 0.9898557603716029\n",
      "5e-05 0.9898276583638745\n",
      "5e-05 0.9897995178852926\n",
      "5e-05 0.9897713389380673\n",
      "5e-05 0.9897431215244119\n",
      "5e-05 0.9897148656465424\n",
      "5e-05 0.989686571306678\n",
      "5e-05 0.9896582385070412\n",
      "5e-05 0.989629867249857\n",
      "5e-05 0.9896014575373537\n",
      "5e-05 0.9895730093717627\n",
      "5e-05 0.9895445227553181\n",
      "5e-05 0.9895159976902574\n",
      "5e-05 0.9894874341788209\n",
      "5e-05 0.989458832223252\n",
      "5e-05 0.9894301918257971\n",
      "5e-05 0.9894015129887054\n",
      "5e-05 0.9893727957142295\n",
      "5e-05 0.989344040004625\n",
      "5e-05 0.9893152458621499\n",
      "5e-05 0.9892864132890662\n",
      "5e-05 0.989257542287638\n",
      "5e-05 0.989228632860133\n",
      "5e-05 0.9891996850088218\n",
      "5e-05 0.9891706987359778\n",
      "5e-05 0.9891416740438777\n",
      "5e-05 0.9891126109348009\n",
      "5e-05 0.9890835094110302\n",
      "5e-05 0.989054369474851\n",
      "5e-05 0.9890251911285521\n",
      "5e-05 0.9889959743744252\n",
      "5e-05 0.988966719214765\n",
      "5e-05 0.988937425651869\n",
      "5e-05 0.988908093688038\n",
      "5e-05 0.9888787233255758\n",
      "5e-05 0.9888493145667889\n",
      "5e-05 0.9888198674139872\n",
      "5e-05 0.9887903818694836\n",
      "5e-05 0.9887608579355938\n",
      "5e-05 0.9887312956146364\n",
      "5e-05 0.9887016949089333\n",
      "5e-05 0.9886720558208095\n",
      "5e-05 0.9886423783525927\n",
      "5e-05 0.9886126625066138\n",
      "5e-05 0.9885829082852067\n",
      "5e-05 0.9885531156907081\n",
      "5e-05 0.9885232847254581\n",
      "5e-05 0.9884934153917997\n",
      "5e-05 0.9884635076920785\n",
      "5e-05 0.9884335616286436\n",
      "5e-05 0.9884035772038471\n",
      "5e-05 0.9883735544200436\n",
      "5e-05 0.9883434932795915\n",
      "5e-05 0.9883133937848515\n",
      "5e-05 0.9882832559381878\n",
      "5e-05 0.9882530797419671\n",
      "5e-05 0.9882228651985597\n",
      "5e-05 0.9881926123103386\n",
      "5e-05 0.9881623210796799\n",
      "5e-05 0.9881319915089625\n",
      "5e-05 0.9881016236005685\n",
      "5e-05 0.9880712173568831\n",
      "5e-05 0.9880407727802942\n",
      "5e-05 0.9880102898731932\n",
      "5e-05 0.9879797686379739\n",
      "5e-05 0.9879492090770337\n",
      "5e-05 0.9879186111927725\n",
      "5e-05 0.9878879749875935\n",
      "5e-05 0.9878573004639031\n",
      "5e-05 0.9878265876241101\n",
      "5e-05 0.9877958364706267\n",
      "5e-05 0.9877650470058685\n",
      "5e-05 0.9877342192322534\n",
      "5e-05 0.9877033531522024\n",
      "5e-05 0.9876724487681401\n",
      "5e-05 0.9876415060824935\n",
      "5e-05 0.9876105250976928\n",
      "5e-05 0.9875795058161712\n",
      "5e-05 0.9875484482403651\n",
      "5e-05 0.9875173523727139\n",
      "5e-05 0.9874862182156594\n",
      "5e-05 0.9874550457716471\n",
      "5e-05 0.9874238350431255\n",
      "5e-05 0.9873925860325454\n",
      "5e-05 0.9873612987423614\n",
      "5e-05 0.9873299731750308\n",
      "5e-05 0.9872986093330138\n",
      "5e-05 0.9872672072187737\n",
      "5e-05 0.9872357668347769\n",
      "5e-05 0.9872042881834925\n",
      "5e-05 0.987172771267393\n",
      "5e-05 0.9871412160889539\n",
      "5e-05 0.987109622650653\n",
      "5e-05 0.9870779909549722\n",
      "5e-05 0.9870463210043955\n",
      "5e-05 0.9870146128014103\n",
      "5e-05 0.9869828663485072\n",
      "5e-05 0.9869510816481791\n",
      "5e-05 0.9869192587029227\n",
      "5e-05 0.9868873975152372\n",
      "5e-05 0.9868554980876252\n",
      "5e-05 0.9868235604225917\n",
      "5e-05 0.9867915845226454\n",
      "5e-05 0.9867595703902974\n",
      "5e-05 0.9867275180280622\n",
      "5e-05 0.9866954274384573\n",
      "Epoch: 12 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 3.552 | Train Acc @1:  16.35% | Train Acc @5:  42.56%\n",
      "\tValid Loss: 3.842 | Valid Acc @1:  13.88% | Valid Acc @5:  37.19%\n",
      "5e-05 0.9866632986240029\n",
      "5e-05 0.9866311315872225\n",
      "5e-05 0.9865989263306424\n",
      "5e-05 0.986566682856792\n",
      "5e-05 0.9865344011682038\n",
      "5e-05 0.986502081267413\n",
      "5e-05 0.9864697231569582\n",
      "5e-05 0.9864373268393807\n",
      "5e-05 0.9864048923172248\n",
      "5e-05 0.986372419593038\n",
      "5e-05 0.9863399086693707\n",
      "5e-05 0.9863073595487762\n",
      "5e-05 0.986274772233811\n",
      "5e-05 0.9862421467270345\n",
      "5e-05 0.9862094830310089\n",
      "5e-05 0.9861767811482999\n",
      "5e-05 0.9861440410814756\n",
      "5e-05 0.9861112628331076\n",
      "5e-05 0.9860784464057701\n",
      "5e-05 0.9860455918020408\n",
      "5e-05 0.9860126990244996\n",
      "5e-05 0.9859797680757303\n",
      "5e-05 0.9859467989583193\n",
      "5e-05 0.9859137916748556\n",
      "5e-05 0.9858807462279319\n",
      "5e-05 0.9858476626201435\n",
      "5e-05 0.9858145408540887\n",
      "5e-05 0.985781380932369\n",
      "5e-05 0.9857481828575886\n",
      "5e-05 0.9857149466323549\n",
      "5e-05 0.9856816722592785\n",
      "5e-05 0.9856483597409724\n",
      "5e-05 0.9856150090800533\n",
      "5e-05 0.9855816202791402\n",
      "5e-05 0.9855481933408556\n",
      "5e-05 0.9855147282678249\n",
      "5e-05 0.9854812250626764\n",
      "5e-05 0.9854476837280415\n",
      "5e-05 0.9854141042665543\n",
      "5e-05 0.9853804866808522\n",
      "5e-05 0.9853468309735756\n",
      "5e-05 0.9853131371473678\n",
      "5e-05 0.985279405204875\n",
      "5e-05 0.9852456351487465\n",
      "5e-05 0.9852118269816347\n",
      "5e-05 0.9851779807061948\n",
      "5e-05 0.985144096325085\n",
      "5e-05 0.9851101738409669\n",
      "5e-05 0.9850762132565043\n",
      "5e-05 0.9850422145743647\n",
      "5e-05 0.9850081777972182\n",
      "5e-05 0.9849741029277382\n",
      "5e-05 0.9849399899686009\n",
      "5e-05 0.9849058389224855\n",
      "5e-05 0.9848716497920742\n",
      "5e-05 0.984837422580052\n",
      "5e-05 0.9848031572891074\n",
      "5e-05 0.9847688539219315\n",
      "5e-05 0.9847345124812183\n",
      "5e-05 0.9847001329696652\n",
      "5e-05 0.9846657153899723\n",
      "5e-05 0.9846312597448426\n",
      "5e-05 0.9845967660369821\n",
      "5e-05 0.9845622342691004\n",
      "5e-05 0.9845276644439093\n",
      "5e-05 0.9844930565641239\n",
      "5e-05 0.9844584106324623\n",
      "5e-05 0.9844237266516457\n",
      "5e-05 0.9843890046243979\n",
      "5e-05 0.9843542445534463\n",
      "5e-05 0.9843194464415208\n",
      "5e-05 0.9842846102913543\n",
      "5e-05 0.9842497361056829\n",
      "5e-05 0.9842148238872457\n",
      "5e-05 0.9841798736387846\n",
      "5e-05 0.9841448853630443\n",
      "5e-05 0.9841098590627734\n",
      "5e-05 0.9840747947407223\n",
      "5e-05 0.9840396923996453\n",
      "5e-05 0.9840045520422991\n",
      "5e-05 0.9839693736714435\n",
      "5e-05 0.9839341572898417\n",
      "5e-05 0.9838989029002595\n",
      "5e-05 0.9838636105054657\n",
      "5e-05 0.9838282801082321\n",
      "5e-05 0.9837929117113335\n",
      "5e-05 0.9837575053175478\n",
      "5e-05 0.983722060929656\n",
      "5e-05 0.9836865785504416\n",
      "5e-05 0.9836510581826914\n",
      "5e-05 0.9836154998291953\n",
      "5e-05 0.9835799034927459\n",
      "5e-05 0.9835442691761391\n",
      "5e-05 0.9835085968821733\n",
      "5e-05 0.9834728866136505\n",
      "5e-05 0.9834371383733753\n",
      "5e-05 0.9834013521641551\n",
      "5e-05 0.983365527988801\n",
      "5e-05 0.983329665850126\n",
      "5e-05 0.9832937657509473\n",
      "5e-05 0.9832578276940841\n",
      "5e-05 0.9832218516823591\n",
      "5e-05 0.9831858377185978\n",
      "5e-05 0.9831497858056288\n",
      "5e-05 0.9831136959462834\n",
      "5e-05 0.9830775681433963\n",
      "5e-05 0.983041402399805\n",
      "5e-05 0.9830051987183497\n",
      "5e-05 0.9829689571018739\n",
      "5e-05 0.9829326775532241\n",
      "5e-05 0.9828963600752496\n",
      "5e-05 0.9828600046708029\n",
      "5e-05 0.9828236113427391\n",
      "5e-05 0.9827871800939167\n",
      "5e-05 0.9827507109271969\n",
      "5e-05 0.9827142038454442\n",
      "5e-05 0.9826776588515254\n",
      "5e-05 0.9826410759483111\n",
      "Epoch: 13 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 3.391 | Train Acc @1:  19.38% | Train Acc @5:  47.64%\n",
      "\tValid Loss: 3.683 | Valid Acc @1:  16.24% | Valid Acc @5:  40.16%\n",
      "5e-05 0.9826044551386743\n",
      "5e-05 0.9825677964254913\n",
      "5e-05 0.9825310998116414\n",
      "5e-05 0.9824943653000064\n",
      "5e-05 0.9824575928934716\n",
      "5e-05 0.9824207825949252\n",
      "5e-05 0.982383934407258\n",
      "5e-05 0.9823470483333642\n",
      "5e-05 0.9823101243761407\n",
      "5e-05 0.9822731625384877\n",
      "5e-05 0.9822361628233082\n",
      "5e-05 0.9821991252335078\n",
      "5e-05 0.9821620497719956\n",
      "5e-05 0.9821249364416835\n",
      "5e-05 0.9820877852454866\n",
      "5e-05 0.9820505961863222\n",
      "5e-05 0.9820133692671116\n",
      "5e-05 0.9819761044907783\n",
      "5e-05 0.9819388018602493\n",
      "5e-05 0.981901461378454\n",
      "5e-05 0.9818640830483255\n",
      "5e-05 0.9818266668727992\n",
      "5e-05 0.9817892128548138\n",
      "5e-05 0.981751720997311\n",
      "5e-05 0.9817141913032352\n",
      "5e-05 0.9816766237755343\n",
      "5e-05 0.9816390184171586\n",
      "5e-05 0.9816013752310617\n",
      "5e-05 0.9815636942202\n",
      "5e-05 0.981525975387533\n",
      "5e-05 0.981488218736023\n",
      "5e-05 0.9814504242686356\n",
      "5e-05 0.981412591988339\n",
      "5e-05 0.9813747218981046\n",
      "5e-05 0.9813368140009068\n",
      "5e-05 0.9812988682997227\n",
      "5e-05 0.9812608847975326\n",
      "5e-05 0.9812228634973197\n",
      "5e-05 0.9811848044020701\n",
      "5e-05 0.9811467075147733\n",
      "5e-05 0.9811085728384209\n",
      "5e-05 0.9810704003760082\n",
      "5e-05 0.9810321901305334\n",
      "5e-05 0.9809939421049975\n",
      "5e-05 0.9809556563024042\n",
      "5e-05 0.9809173327257606\n",
      "5e-05 0.9808789713780768\n",
      "5e-05 0.9808405722623654\n",
      "5e-05 0.9808021353816425\n",
      "5e-05 0.9807636607389266\n",
      "5e-05 0.9807251483372399\n",
      "5e-05 0.9806865981796067\n",
      "5e-05 0.9806480102690551\n",
      "5e-05 0.9806093846086155\n",
      "5e-05 0.9805707212013217\n",
      "5e-05 0.9805320200502103\n",
      "5e-05 0.9804932811583208\n",
      "5e-05 0.9804545045286958\n",
      "5e-05 0.9804156901643808\n",
      "5e-05 0.9803768380684241\n",
      "5e-05 0.9803379482438773\n",
      "5e-05 0.9802990206937948\n",
      "5e-05 0.980260055421234\n",
      "5e-05 0.980221052429255\n",
      "5e-05 0.9801820117209211\n",
      "5e-05 0.9801429332992988\n",
      "5e-05 0.980103817167457\n",
      "5e-05 0.9800646633284682\n",
      "5e-05 0.9800254717854071\n",
      "5e-05 0.9799862425413521\n",
      "5e-05 0.9799469755993844\n",
      "5e-05 0.9799076709625875\n",
      "5e-05 0.9798683286340487\n",
      "5e-05 0.9798289486168579\n",
      "5e-05 0.979789530914108\n",
      "5e-05 0.9797500755288947\n",
      "5e-05 0.9797105824643171\n",
      "5e-05 0.9796710517234766\n",
      "5e-05 0.9796314833094781\n",
      "5e-05 0.9795918772254295\n",
      "5e-05 0.9795522334744411\n",
      "5e-05 0.9795125520596267\n",
      "5e-05 0.9794728329841028\n",
      "5e-05 0.979433076250989\n",
      "5e-05 0.9793932818634076\n",
      "5e-05 0.9793534498244842\n",
      "5e-05 0.9793135801373472\n",
      "5e-05 0.9792736728051277\n",
      "5e-05 0.9792337278309603\n",
      "5e-05 0.9791937452179822\n",
      "5e-05 0.9791537249693334\n",
      "5e-05 0.9791136670881573\n",
      "5e-05 0.9790735715776\n",
      "5e-05 0.9790334384408106\n",
      "5e-05 0.978993267680941\n",
      "5e-05 0.9789530593011464\n",
      "5e-05 0.9789128133045846\n",
      "5e-05 0.9788725296944164\n",
      "5e-05 0.9788322084738059\n",
      "5e-05 0.9787918496459198\n",
      "5e-05 0.9787514532139279\n",
      "5e-05 0.9787110191810027\n",
      "5e-05 0.9786705475503202\n",
      "5e-05 0.9786300383250589\n",
      "5e-05 0.9785894915084004\n",
      "5e-05 0.9785489071035292\n",
      "5e-05 0.9785082851136326\n",
      "5e-05 0.9784676255419014\n",
      "5e-05 0.9784269283915286\n",
      "5e-05 0.9783861936657108\n",
      "5e-05 0.9783454213676472\n",
      "5e-05 0.9783046115005403\n",
      "5e-05 0.9782637640675947\n",
      "5e-05 0.9782228790720191\n",
      "5e-05 0.9781819565170242\n",
      "5e-05 0.9781409964058243\n",
      "5e-05 0.9780999987416363\n",
      "5e-05 0.9780589635276802\n",
      "Epoch: 14 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 3.210 | Train Acc @1:  22.80% | Train Acc @5:  52.15%\n",
      "\tValid Loss: 3.536 | Valid Acc @1:  17.94% | Valid Acc @5:  43.34%\n",
      "5e-05 0.9780178907671788\n",
      "5e-05 0.9779767804633579\n",
      "5e-05 0.9779356326194465\n",
      "5e-05 0.9778944472386761\n",
      "5e-05 0.9778532243242815\n",
      "5e-05 0.9778119638795002\n",
      "5e-05 0.9777706659075729\n",
      "5e-05 0.9777293304117431\n",
      "5e-05 0.9776879573952573\n",
      "5e-05 0.9776465468613649\n",
      "5e-05 0.9776050988133183\n",
      "5e-05 0.9775636132543727\n",
      "5e-05 0.9775220901877865\n",
      "5e-05 0.9774805296168207\n",
      "5e-05 0.9774389315447397\n",
      "5e-05 0.9773972959748104\n",
      "5e-05 0.977355622910303\n",
      "5e-05 0.9773139123544903\n",
      "5e-05 0.9772721643106483\n",
      "5e-05 0.977230378782056\n",
      "5e-05 0.9771885557719951\n",
      "5e-05 0.9771466952837504\n",
      "5e-05 0.9771047973206096\n",
      "5e-05 0.9770628618858632\n",
      "5e-05 0.9770208889828051\n",
      "5e-05 0.9769788786147315\n",
      "5e-05 0.9769368307849422\n",
      "5e-05 0.9768947454967394\n",
      "5e-05 0.9768526227534284\n",
      "5e-05 0.9768104625583177\n",
      "5e-05 0.9767682649147185\n",
      "5e-05 0.9767260298259448\n",
      "5e-05 0.976683757295314\n",
      "5e-05 0.976641447326146\n",
      "5e-05 0.9765990999217637\n",
      "5e-05 0.9765567150854935\n",
      "5e-05 0.9765142928206637\n",
      "5e-05 0.9764718331306066\n",
      "5e-05 0.9764293360186567\n",
      "5e-05 0.9763868014881516\n",
      "5e-05 0.9763442295424323\n",
      "5e-05 0.9763016201848422\n",
      "5e-05 0.9762589734187277\n",
      "5e-05 0.9762162892474384\n",
      "5e-05 0.9761735676743268\n",
      "5e-05 0.976130808702748\n",
      "5e-05 0.9760880123360605\n",
      "5e-05 0.9760451785776252\n",
      "5e-05 0.9760023074308066\n",
      "5e-05 0.9759593988989715\n",
      "5e-05 0.9759164529854901\n",
      "5e-05 0.9758734696937352\n",
      "5e-05 0.9758304490270829\n",
      "5e-05 0.9757873909889119\n",
      "5e-05 0.9757442955826039\n",
      "5e-05 0.9757011628115436\n",
      "5e-05 0.9756579926791188\n",
      "5e-05 0.9756147851887198\n",
      "5e-05 0.9755715403437404\n",
      "5e-05 0.9755282581475768\n",
      "5e-05 0.9754849386036284\n",
      "5e-05 0.9754415817152976\n",
      "5e-05 0.9753981874859896\n",
      "5e-05 0.9753547559191125\n",
      "5e-05 0.9753112870180773\n",
      "5e-05 0.9752677807862984\n",
      "5e-05 0.9752242372271924\n",
      "5e-05 0.9751806563441793\n",
      "5e-05 0.9751370381406819\n",
      "5e-05 0.975093382620126\n",
      "5e-05 0.9750496897859404\n",
      "5e-05 0.9750059596415566\n",
      "5e-05 0.974962192190409\n",
      "5e-05 0.9749183874359353\n",
      "5e-05 0.9748745453815757\n",
      "5e-05 0.9748306660307737\n",
      "5e-05 0.9747867493869757\n",
      "5e-05 0.9747427954536305\n",
      "5e-05 0.9746988042341906\n",
      "5e-05 0.9746547757321109\n",
      "5e-05 0.9746107099508493\n",
      "5e-05 0.9745666068938668\n",
      "5e-05 0.9745224665646273\n",
      "5e-05 0.9744782889665973\n",
      "5e-05 0.9744340741032468\n",
      "5e-05 0.9743898219780482\n",
      "5e-05 0.9743455325944772\n",
      "5e-05 0.9743012059560121\n",
      "5e-05 0.9742568420661346\n",
      "5e-05 0.9742124409283286\n",
      "5e-05 0.9741680025460817\n",
      "5e-05 0.9741235269228838\n",
      "5e-05 0.9740790140622282\n",
      "5e-05 0.9740344639676108\n",
      "5e-05 0.9739898766425307\n",
      "5e-05 0.9739452520904897\n",
      "5e-05 0.9739005903149923\n",
      "5e-05 0.9738558913195466\n",
      "5e-05 0.9738111551076631\n",
      "5e-05 0.9737663816828555\n",
      "5e-05 0.97372157104864\n",
      "5e-05 0.9736767232085364\n",
      "5e-05 0.9736318381660666\n",
      "5e-05 0.9735869159247561\n",
      "5e-05 0.9735419564881329\n",
      "5e-05 0.9734969598597284\n",
      "5e-05 0.9734519260430763\n",
      "5e-05 0.9734068550417138\n",
      "5e-05 0.9733617468591805\n",
      "5e-05 0.9733166014990193\n",
      "5e-05 0.9732714189647761\n",
      "5e-05 0.9732261992599991\n",
      "5e-05 0.9731809423882403\n",
      "5e-05 0.9731356483530537\n",
      "5e-05 0.973090317157997\n",
      "5e-05 0.9730449488066302\n",
      "5e-05 0.9729995433025168\n",
      "5e-05 0.9729541006492228\n",
      "Epoch: 15 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 3.072 | Train Acc @1:  25.30% | Train Acc @5:  55.89%\n",
      "\tValid Loss: 3.609 | Valid Acc @1:  18.01% | Valid Acc @5:  43.68%\n",
      "5e-05 0.9729086208503173\n",
      "5e-05 0.9728631039093723\n",
      "5e-05 0.9728175498299625\n",
      "5e-05 0.9727719586156658\n",
      "5e-05 0.9727263302700629\n",
      "5e-05 0.9726806647967375\n",
      "5e-05 0.9726349621992761\n",
      "5e-05 0.9725892224812682\n",
      "5e-05 0.972543445646306\n",
      "5e-05 0.9724976316979851\n",
      "5e-05 0.9724517806399035\n",
      "5e-05 0.9724058924756622\n",
      "5e-05 0.9723599672088656\n",
      "5e-05 0.9723140048431204\n",
      "5e-05 0.9722680053820365\n",
      "5e-05 0.9722219688292266\n",
      "5e-05 0.9721758951883066\n",
      "5e-05 0.9721297844628949\n",
      "5e-05 0.9720836366566131\n",
      "5e-05 0.9720374517730856\n",
      "5e-05 0.9719912298159399\n",
      "5e-05 0.9719449707888062\n",
      "5e-05 0.9718986746953173\n",
      "5e-05 0.9718523415391098\n",
      "5e-05 0.9718059713238223\n",
      "5e-05 0.9717595640530969\n",
      "5e-05 0.9717131197305784\n",
      "5e-05 0.9716666383599144\n",
      "5e-05 0.9716201199447556\n",
      "5e-05 0.9715735644887555\n",
      "5e-05 0.9715269719955708\n",
      "5e-05 0.9714803424688605\n",
      "5e-05 0.9714336759122869\n",
      "5e-05 0.9713869723295153\n",
      "5e-05 0.9713402317242139\n",
      "5e-05 0.9712934541000533\n",
      "5e-05 0.9712466394607078\n",
      "5e-05 0.9711997878098539\n",
      "5e-05 0.9711528991511715\n",
      "5e-05 0.9711059734883433\n",
      "5e-05 0.9710590108250545\n",
      "5e-05 0.9710120111649938\n",
      "5e-05 0.9709649745118524\n",
      "5e-05 0.9709179008693245\n",
      "5e-05 0.9708707902411073\n",
      "5e-05 0.970823642630901\n",
      "5e-05 0.9707764580424084\n",
      "5e-05 0.9707292364793354\n",
      "5e-05 0.9706819779453906\n",
      "5e-05 0.970634682444286\n",
      "5e-05 0.9705873499797357\n",
      "5e-05 0.9705399805554576\n",
      "5e-05 0.970492574175172\n",
      "5e-05 0.9704451308426019\n",
      "5e-05 0.9703976505614738\n",
      "5e-05 0.9703501333355167\n",
      "5e-05 0.9703025791684624\n",
      "5e-05 0.970254988064046\n",
      "5e-05 0.9702073600260052\n",
      "5e-05 0.9701596950580806\n",
      "5e-05 0.970111993164016\n",
      "5e-05 0.9700642543475577\n",
      "5e-05 0.9700164786124552\n",
      "5e-05 0.9699686659624607\n",
      "5e-05 0.9699208164013293\n",
      "5e-05 0.9698729299328194\n",
      "5e-05 0.9698250065606917\n",
      "5e-05 0.9697770462887101\n",
      "5e-05 0.9697290491206416\n",
      "5e-05 0.9696810150602556\n",
      "5e-05 0.9696329441113248\n",
      "5e-05 0.9695848362776247\n",
      "5e-05 0.9695366915629337\n",
      "5e-05 0.9694885099710329\n",
      "5e-05 0.9694402915057065\n",
      "5e-05 0.9693920361707418\n",
      "5e-05 0.9693437439699285\n",
      "5e-05 0.9692954149070596\n",
      "5e-05 0.9692470489859306\n",
      "5e-05 0.9691986462103404\n",
      "5e-05 0.9691502065840905\n",
      "5e-05 0.9691017301109852\n",
      "5e-05 0.9690532167948318\n",
      "5e-05 0.9690046666394407\n",
      "5e-05 0.968956079648625\n",
      "5e-05 0.9689074558262004\n",
      "5e-05 0.9688587951759862\n",
      "5e-05 0.9688100977018039\n",
      "5e-05 0.9687613634074783\n",
      "5e-05 0.9687125922968369\n",
      "5e-05 0.9686637843737103\n",
      "5e-05 0.9686149396419316\n",
      "5e-05 0.9685660581053372\n",
      "5e-05 0.9685171397677663\n",
      "5e-05 0.968468184633061\n",
      "5e-05 0.9684191927050659\n",
      "5e-05 0.968370163987629\n",
      "5e-05 0.9683210984846011\n",
      "5e-05 0.9682719961998356\n",
      "5e-05 0.9682228571371889\n",
      "5e-05 0.9681736813005206\n",
      "5e-05 0.968124468693693\n",
      "5e-05 0.9680752193205708\n",
      "5e-05 0.9680259331850225\n",
      "5e-05 0.9679766102909186\n",
      "5e-05 0.9679272506421334\n",
      "5e-05 0.967877854242543\n",
      "5e-05 0.9678284210960275\n",
      "5e-05 0.9677789512064691\n",
      "5e-05 0.9677294445777531\n",
      "5e-05 0.9676799012137678\n",
      "5e-05 0.9676303211184043\n",
      "5e-05 0.9675807042955566\n",
      "5e-05 0.9675310507491217\n",
      "5e-05 0.9674813604829993\n",
      "5e-05 0.967431633501092\n",
      "5e-05 0.9673818698073053\n",
      "5e-05 0.9673320694055476\n",
      "Epoch: 16 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 2.947 | Train Acc @1:  27.31% | Train Acc @5:  58.75%\n",
      "\tValid Loss: 3.604 | Valid Acc @1:  17.79% | Valid Acc @5:  45.51%\n",
      "5e-05 0.9672822322997304\n",
      "5e-05 0.9672323584937678\n",
      "5e-05 0.9671824479915767\n",
      "5e-05 0.9671325007970772\n",
      "5e-05 0.9670825169141921\n",
      "5e-05 0.9670324963468473\n",
      "5e-05 0.966982439098971\n",
      "5e-05 0.966932345174495\n",
      "5e-05 0.9668822145773535\n",
      "5e-05 0.9668320473114838\n",
      "5e-05 0.9667818433808261\n",
      "5e-05 0.9667316027893231\n",
      "5e-05 0.966681325540921\n",
      "5e-05 0.9666310116395684\n",
      "5e-05 0.9665806610892169\n",
      "5e-05 0.9665302738938211\n",
      "5e-05 0.9664798500573384\n",
      "5e-05 0.9664293895837289\n",
      "5e-05 0.966378892476956\n",
      "5e-05 0.9663283587409854\n",
      "5e-05 0.9662777883797864\n",
      "5e-05 0.9662271813973304\n",
      "5e-05 0.9661765377975923\n",
      "5e-05 0.9661258575845495\n",
      "5e-05 0.9660751407621824\n",
      "5e-05 0.9660243873344743\n",
      "5e-05 0.9659735973054114\n",
      "5e-05 0.9659227706789828\n",
      "5e-05 0.9658719074591802\n",
      "5e-05 0.9658210076499985\n",
      "5e-05 0.9657700712554351\n",
      "5e-05 0.965719098279491\n",
      "5e-05 0.9656680887261693\n",
      "5e-05 0.9656170425994761\n",
      "5e-05 0.965565959903421\n",
      "5e-05 0.9655148406420156\n",
      "5e-05 0.965463684819275\n",
      "5e-05 0.9654124924392169\n",
      "5e-05 0.9653612635058619\n",
      "5e-05 0.9653099980232336\n",
      "5e-05 0.9652586959953582\n",
      "5e-05 0.9652073574262652\n",
      "5e-05 0.9651559823199863\n",
      "5e-05 0.9651045706805569\n",
      "5e-05 0.9650531225120146\n",
      "5e-05 0.9650016378184002\n",
      "5e-05 0.9649501166037573\n",
      "5e-05 0.9648985588721323\n",
      "5e-05 0.9648469646275746\n",
      "5e-05 0.9647953338741362\n",
      "5e-05 0.9647436666158724\n",
      "5e-05 0.9646919628568409\n",
      "5e-05 0.9646402226011028\n",
      "5e-05 0.9645884458527214\n",
      "5e-05 0.9645366326157635\n",
      "5e-05 0.9644847828942984\n",
      "5e-05 0.9644328966923982\n",
      "5e-05 0.9643809740141382\n",
      "5e-05 0.9643290148635963\n",
      "5e-05 0.9642770192448535\n",
      "5e-05 0.9642249871619935\n",
      "5e-05 0.9641729186191026\n",
      "5e-05 0.9641208136202704\n",
      "5e-05 0.9640686721695892\n",
      "5e-05 0.9640164942711544\n",
      "5e-05 0.9639642799290637\n",
      "5e-05 0.9639120291474181\n",
      "5e-05 0.9638597419303214\n",
      "5e-05 0.9638074182818801\n",
      "5e-05 0.9637550582062039\n",
      "5e-05 0.9637026617074049\n",
      "5e-05 0.9636502287895985\n",
      "5e-05 0.9635977594569025\n",
      "5e-05 0.9635452537134381\n",
      "5e-05 0.9634927115633288\n",
      "5e-05 0.9634401330107016\n",
      "5e-05 0.9633875180596856\n",
      "5e-05 0.9633348667144135\n",
      "5e-05 0.9632821789790202\n",
      "5e-05 0.9632294548576441\n",
      "5e-05 0.9631766943544258\n",
      "5e-05 0.9631238974735093\n",
      "5e-05 0.9630710642190412\n",
      "5e-05 0.963018194595171\n",
      "5e-05 0.9629652886060511\n",
      "5e-05 0.9629123462558367\n",
      "5e-05 0.9628593675486856\n",
      "5e-05 0.9628063524887591\n",
      "5e-05 0.9627533010802208\n",
      "5e-05 0.9627002133272374\n",
      "5e-05 0.9626470892339785\n",
      "5e-05 0.9625939288046161\n",
      "5e-05 0.9625407320433257\n",
      "5e-05 0.9624874989542852\n",
      "5e-05 0.9624342295416756\n",
      "5e-05 0.9623809238096805\n",
      "5e-05 0.9623275817624868\n",
      "5e-05 0.9622742034042837\n",
      "5e-05 0.9622207887392635\n",
      "5e-05 0.9621673377716216\n",
      "5e-05 0.9621138505055559\n",
      "5e-05 0.9620603269452671\n",
      "5e-05 0.9620067670949592\n",
      "5e-05 0.9619531709588385\n",
      "5e-05 0.9618995385411147\n",
      "5e-05 0.9618458698459997\n",
      "5e-05 0.961792164877709\n",
      "5e-05 0.9617384236404605\n",
      "5e-05 0.9616846461384747\n",
      "5e-05 0.9616308323759755\n",
      "5e-05 0.9615769823571894\n",
      "5e-05 0.9615230960863458\n",
      "5e-05 0.9614691735676768\n",
      "5e-05 0.9614152148054175\n",
      "5e-05 0.9613612198038057\n",
      "5e-05 0.9613071885670823\n",
      "5e-05 0.9612531210994909\n",
      "5e-05 0.9611990174052778\n",
      "Epoch: 17 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 2.793 | Train Acc @1:  30.09% | Train Acc @5:  62.78%\n",
      "\tValid Loss: 3.427 | Valid Acc @1:  20.81% | Valid Acc @5:  47.06%\n",
      "5e-05 0.9611448774886924\n",
      "5e-05 0.9610907013539867\n",
      "5e-05 0.9610364890054157\n",
      "5e-05 0.9609822404472373\n",
      "5e-05 0.9609279556837121\n",
      "5e-05 0.9608736347191037\n",
      "5e-05 0.9608192775576783\n",
      "5e-05 0.9607648842037051\n",
      "5e-05 0.9607104546614562\n",
      "5e-05 0.9606559889352064\n",
      "5e-05 0.9606014870292336\n",
      "5e-05 0.9605469489478182\n",
      "5e-05 0.9604923746952436\n",
      "5e-05 0.960437764275796\n",
      "5e-05 0.9603831176937645\n",
      "5e-05 0.9603284349534411\n",
      "5e-05 0.9602737160591206\n",
      "5e-05 0.9602189610151004\n",
      "5e-05 0.9601641698256811\n",
      "5e-05 0.9601093424951659\n",
      "5e-05 0.960054479027861\n",
      "5e-05 0.9599995794280752\n",
      "5e-05 0.9599446437001204\n",
      "5e-05 0.9598896718483114\n",
      "5e-05 0.9598346638769653\n",
      "5e-05 0.9597796197904026\n",
      "5e-05 0.9597245395929463\n",
      "5e-05 0.9596694232889227\n",
      "5e-05 0.9596142708826604\n",
      "5e-05 0.959559082378491\n",
      "5e-05 0.959503857780749\n",
      "5e-05 0.9594485970937718\n",
      "5e-05 0.9593933003218995\n",
      "5e-05 0.9593379674694751\n",
      "5e-05 0.9592825985408442\n",
      "5e-05 0.9592271935403558\n",
      "5e-05 0.9591717524723613\n",
      "5e-05 0.9591162753412149\n",
      "5e-05 0.9590607621512739\n",
      "5e-05 0.959005212906898\n",
      "5e-05 0.9589496276124504\n",
      "5e-05 0.9588940062722964\n",
      "5e-05 0.9588383488908048\n",
      "5e-05 0.9587826554723466\n",
      "5e-05 0.958726926021296\n",
      "5e-05 0.9586711605420302\n",
      "5e-05 0.9586153590389288\n",
      "5e-05 0.9585595215163744\n",
      "5e-05 0.9585036479787525\n",
      "5e-05 0.9584477384304515\n",
      "5e-05 0.9583917928758623\n",
      "5e-05 0.958335811319379\n",
      "5e-05 0.9582797937653982\n",
      "5e-05 0.9582237402183198\n",
      "5e-05 0.9581676506825458\n",
      "5e-05 0.9581115251624819\n",
      "5e-05 0.958055363662536\n",
      "5e-05 0.9579991661871188\n",
      "5e-05 0.9579429327406441\n",
      "5e-05 0.9578866633275287\n",
      "5e-05 0.9578303579521918\n",
      "5e-05 0.9577740166190556\n",
      "5e-05 0.9577176393325451\n",
      "5e-05 0.957661226097088\n",
      "5e-05 0.9576047769171154\n",
      "5e-05 0.9575482917970605\n",
      "5e-05 0.9574917707413596\n",
      "5e-05 0.957435213754452\n",
      "5e-05 0.9573786208407794\n",
      "5e-05 0.9573219920047868\n",
      "5e-05 0.9572653272509218\n",
      "5e-05 0.9572086265836348\n",
      "5e-05 0.957151890007379\n",
      "5e-05 0.9570951175266105\n",
      "5e-05 0.957038309145788\n",
      "5e-05 0.9569814648693735\n",
      "5e-05 0.9569245847018315\n",
      "5e-05 0.9568676686476292\n",
      "5e-05 0.9568107167112367\n",
      "5e-05 0.9567537288971272\n",
      "5e-05 0.9566967052097763\n",
      "5e-05 0.9566396456536628\n",
      "5e-05 0.9565825502332679\n",
      "5e-05 0.9565254189530761\n",
      "5e-05 0.9564682518175744\n",
      "5e-05 0.9564110488312525\n",
      "5e-05 0.9563538099986033\n",
      "5e-05 0.9562965353241223\n",
      "5e-05 0.9562392248123077\n",
      "5e-05 0.9561818784676608\n",
      "5e-05 0.9561244962946854\n",
      "5e-05 0.9560670782978884\n",
      "5e-05 0.9560096244817793\n",
      "5e-05 0.9559521348508705\n",
      "5e-05 0.9558946094096773\n",
      "5e-05 0.9558370481627176\n",
      "5e-05 0.9557794511145123\n",
      "5e-05 0.9557218182695851\n",
      "5e-05 0.9556641496324625\n",
      "5e-05 0.9556064452076735\n",
      "5e-05 0.9555487049997504\n",
      "5e-05 0.9554909290132281\n",
      "5e-05 0.9554331172526442\n",
      "5e-05 0.9553752697225393\n",
      "5e-05 0.9553173864274567\n",
      "5e-05 0.9552594673719423\n",
      "5e-05 0.9552015125605455\n",
      "5e-05 0.9551435219978177\n",
      "5e-05 0.9550854956883135\n",
      "5e-05 0.9550274336365904\n",
      "5e-05 0.9549693358472084\n",
      "5e-05 0.9549112023247306\n",
      "5e-05 0.9548530330737226\n",
      "5e-05 0.9547948280987533\n",
      "5e-05 0.9547365874043938\n",
      "5e-05 0.9546783109952185\n",
      "5e-05 0.9546199988758043\n",
      "5e-05 0.954561651050731\n",
      "Epoch: 18 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 2.655 | Train Acc @1:  33.87% | Train Acc @5:  65.49%\n",
      "\tValid Loss: 3.244 | Valid Acc @1:  23.04% | Valid Acc @5:  50.79%\n",
      "5e-05 0.9545032675245813\n",
      "5e-05 0.9544448483019404\n",
      "5e-05 0.9543863933873968\n",
      "5e-05 0.9543279027855414\n",
      "5e-05 0.954269376500968\n",
      "5e-05 0.9542108145382733\n",
      "5e-05 0.9541522169020566\n",
      "5e-05 0.9540935835969203\n",
      "5e-05 0.9540349146274694\n",
      "5e-05 0.9539762099983116\n",
      "5e-05 0.9539174697140576\n",
      "5e-05 0.953858693779321\n",
      "5e-05 0.9537998821987177\n",
      "5e-05 0.9537410349768671\n",
      "5e-05 0.9536821521183909\n",
      "5e-05 0.9536232336279136\n",
      "5e-05 0.9535642795100627\n",
      "5e-05 0.9535052897694687\n",
      "5e-05 0.9534462644107642\n",
      "5e-05 0.9533872034385853\n",
      "5e-05 0.9533281068575705\n",
      "5e-05 0.9532689746723613\n",
      "5e-05 0.9532098068876018\n",
      "5e-05 0.9531506035079391\n",
      "5e-05 0.9530913645380232\n",
      "5e-05 0.9530320899825064\n",
      "5e-05 0.9529727798460442\n",
      "5e-05 0.9529134341332948\n",
      "5e-05 0.9528540528489191\n",
      "5e-05 0.9527946359975812\n",
      "5e-05 0.9527351835839473\n",
      "5e-05 0.9526756956126868\n",
      "5e-05 0.9526161720884722\n",
      "5e-05 0.952556613015978\n",
      "5e-05 0.9524970183998822\n",
      "5e-05 0.9524373882448655\n",
      "5e-05 0.9523777225556108\n",
      "5e-05 0.9523180213368045\n",
      "5e-05 0.9522582845931356\n",
      "5e-05 0.9521985123292955\n",
      "5e-05 0.9521387045499788\n",
      "5e-05 0.952078861259883\n",
      "5e-05 0.9520189824637078\n",
      "5e-05 0.9519590681661563\n",
      "5e-05 0.9518991183719341\n",
      "5e-05 0.9518391330857496\n",
      "5e-05 0.951779112312314\n",
      "5e-05 0.9517190560563413\n",
      "5e-05 0.9516589643225484\n",
      "5e-05 0.9515988371156548\n",
      "5e-05 0.9515386744403829\n",
      "5e-05 0.9514784763014578\n",
      "5e-05 0.9514182427036074\n",
      "5e-05 0.9513579736515625\n",
      "5e-05 0.9512976691500566\n",
      "5e-05 0.9512373292038261\n",
      "5e-05 0.9511769538176098\n",
      "5e-05 0.9511165429961497\n",
      "5e-05 0.9510560967441904\n",
      "5e-05 0.9509956150664796\n",
      "5e-05 0.950935097967767\n",
      "5e-05 0.9508745454528059\n",
      "5e-05 0.9508139575263521\n",
      "5e-05 0.9507533341931641\n",
      "5e-05 0.9506926754580032\n",
      "5e-05 0.9506319813256334\n",
      "5e-05 0.9505712518008219\n",
      "5e-05 0.9505104868883381\n",
      "5e-05 0.9504496865929545\n",
      "5e-05 0.9503888509194464\n",
      "5e-05 0.9503279798725917\n",
      "5e-05 0.9502670734571713\n",
      "5e-05 0.9502061316779686\n",
      "5e-05 0.9501451545397703\n",
      "5e-05 0.9500841420473651\n",
      "5e-05 0.9500230942055451\n",
      "5e-05 0.9499620110191049\n",
      "5e-05 0.949900892492842\n",
      "5e-05 0.9498397386315567\n",
      "5e-05 0.9497785494400519\n",
      "5e-05 0.9497173249231333\n",
      "5e-05 0.9496560650856096\n",
      "5e-05 0.949594769932292\n",
      "5e-05 0.9495334394679947\n",
      "5e-05 0.9494720736975344\n",
      "5e-05 0.949410672625731\n",
      "5e-05 0.9493492362574067\n",
      "5e-05 0.9492877645973867\n",
      "5e-05 0.9492262576504991\n",
      "5e-05 0.9491647154215745\n",
      "5e-05 0.9491031379154465\n",
      "5e-05 0.9490415251369513\n",
      "5e-05 0.9489798770909279\n",
      "5e-05 0.9489181937822182\n",
      "5e-05 0.9488564752156667\n",
      "5e-05 0.9487947213961208\n",
      "5e-05 0.9487329323284306\n",
      "5e-05 0.948671108017449\n",
      "5e-05 0.9486092484680317\n",
      "5e-05 0.9485473536850371\n",
      "5e-05 0.9484854236733264\n",
      "5e-05 0.9484234584377634\n",
      "5e-05 0.948361457983215\n",
      "5e-05 0.9482994223145507\n",
      "5e-05 0.9482373514366427\n",
      "5e-05 0.9481752453543659\n",
      "5e-05 0.9481131040725982\n",
      "5e-05 0.9480509275962201\n",
      "5e-05 0.947988715930115\n",
      "5e-05 0.9479264690791691\n",
      "5e-05 0.9478641870482709\n",
      "5e-05 0.9478018698423122\n",
      "5e-05 0.9477395174661873\n",
      "5e-05 0.9476771299247935\n",
      "5e-05 0.9476147072230305\n",
      "5e-05 0.9475522493658011\n",
      "5e-05 0.9474897563580105\n",
      "5e-05 0.9474272282045672\n",
      "Epoch: 19 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 2.518 | Train Acc @1:  36.44% | Train Acc @5:  68.22%\n",
      "\tValid Loss: 3.288 | Valid Acc @1:  23.03% | Valid Acc @5:  51.87%\n",
      "5e-05 0.9473646649103817\n",
      "5e-05 0.9473020664803681\n",
      "5e-05 0.9472394329194427\n",
      "5e-05 0.9471767642325246\n",
      "5e-05 0.9471140604245358\n",
      "5e-05 0.9470513215004013\n",
      "5e-05 0.9469885474650483\n",
      "5e-05 0.9469257383234071\n",
      "5e-05 0.9468628940804108\n",
      "5e-05 0.9468000147409951\n",
      "5e-05 0.9467371003100984\n",
      "5e-05 0.9466741507926622\n",
      "5e-05 0.9466111661936304\n",
      "5e-05 0.9465481465179497\n",
      "5e-05 0.9464850917705699\n",
      "5e-05 0.9464220019564431\n",
      "5e-05 0.9463588770805242\n",
      "5e-05 0.9462957171477715\n",
      "5e-05 0.9462325221631449\n",
      "5e-05 0.9461692921316083\n",
      "5e-05 0.9461060270581274\n",
      "5e-05 0.946042726947671\n",
      "5e-05 0.9459793918052108\n",
      "5e-05 0.9459160216357212\n",
      "5e-05 0.9458526164441792\n",
      "5e-05 0.9457891762355644\n",
      "5e-05 0.9457257010148596\n",
      "5e-05 0.9456621907870502\n",
      "5e-05 0.9455986455571239\n",
      "5e-05 0.9455350653300718\n",
      "5e-05 0.9454714501108874\n",
      "5e-05 0.945407799904567\n",
      "5e-05 0.9453441147161097\n",
      "5e-05 0.9452803945505173\n",
      "5e-05 0.9452166394127943\n",
      "5e-05 0.945152849307948\n",
      "5e-05 0.9450890242409886\n",
      "5e-05 0.9450251642169286\n",
      "5e-05 0.9449612692407838\n",
      "5e-05 0.9448973393175724\n",
      "5e-05 0.9448333744523154\n",
      "5e-05 0.9447693746500366\n",
      "5e-05 0.9447053399157626\n",
      "5e-05 0.9446412702545225\n",
      "5e-05 0.9445771656713484\n",
      "5e-05 0.944513026171275\n",
      "5e-05 0.9444488517593398\n",
      "5e-05 0.9443846424405831\n",
      "5e-05 0.9443203982200478\n",
      "5e-05 0.9442561191027796\n",
      "5e-05 0.9441918050938269\n",
      "5e-05 0.9441274561982411\n",
      "5e-05 0.944063072421076\n",
      "5e-05 0.9439986537673883\n",
      "5e-05 0.9439342002422373\n",
      "5e-05 0.9438697118506854\n",
      "5e-05 0.9438051885977973\n",
      "5e-05 0.9437406304886407\n",
      "5e-05 0.9436760375282858\n",
      "5e-05 0.9436114097218059\n",
      "5e-05 0.9435467470742769\n",
      "5e-05 0.9434820495907771\n",
      "5e-05 0.943417317276388\n",
      "5e-05 0.9433525501361937\n",
      "5e-05 0.9432877481752808\n",
      "5e-05 0.9432229113987389\n",
      "5e-05 0.9431580398116605\n",
      "5e-05 0.9430931334191401\n",
      "5e-05 0.9430281922262758\n",
      "5e-05 0.9429632162381679\n",
      "5e-05 0.9428982054599198\n",
      "5e-05 0.942833159896637\n",
      "5e-05 0.9427680795534283\n",
      "5e-05 0.9427029644354055\n",
      "5e-05 0.9426378145476821\n",
      "5e-05 0.9425726298953754\n",
      "5e-05 0.9425074104836048\n",
      "5e-05 0.9424421563174925\n",
      "5e-05 0.9423768674021638\n",
      "5e-05 0.9423115437427461\n",
      "5e-05 0.9422461853443702\n",
      "5e-05 0.9421807922121692\n",
      "5e-05 0.942115364351279\n",
      "5e-05 0.9420499017668384\n",
      "5e-05 0.9419844044639889\n",
      "5e-05 0.9419188724478742\n",
      "5e-05 0.9418533057236416\n",
      "5e-05 0.9417877042964404\n",
      "5e-05 0.9417220681714231\n",
      "5e-05 0.9416563973537447\n",
      "5e-05 0.9415906918485628\n",
      "5e-05 0.9415249516610381\n",
      "5e-05 0.9414591767963336\n",
      "5e-05 0.9413933672596155\n",
      "5e-05 0.9413275230560522\n",
      "5e-05 0.941261644190815\n",
      "5e-05 0.9411957306690784\n",
      "5e-05 0.9411297824960188\n",
      "5e-05 0.941063799676816\n",
      "5e-05 0.9409977822166521\n",
      "5e-05 0.9409317301207122\n",
      "5e-05 0.940865643394184\n",
      "5e-05 0.9407995220422578\n",
      "5e-05 0.9407333660701269\n",
      "5e-05 0.9406671754829872\n",
      "5e-05 0.940600950286037\n",
      "5e-05 0.9405346904844778\n",
      "5e-05 0.9404683960835136\n",
      "5e-05 0.9404020670883511\n",
      "5e-05 0.9403357035041998\n",
      "5e-05 0.9402693053362718\n",
      "5e-05 0.9402028725897822\n",
      "5e-05 0.9401364052699481\n",
      "5e-05 0.9400699033819904\n",
      "5e-05 0.9400033669311318\n",
      "5e-05 0.939936795922598\n",
      "5e-05 0.9398701903616178\n",
      "5e-05 0.9398035502534219\n",
      "Epoch: 20 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 2.395 | Train Acc @1:  38.76% | Train Acc @5:  71.28%\n",
      "\tValid Loss: 3.261 | Valid Acc @1:  25.31% | Valid Acc @5:  53.83%\n",
      "5e-05 0.9397368756032445\n",
      "5e-05 0.9396701664163222\n",
      "5e-05 0.9396034226978942\n",
      "5e-05 0.9395366444532025\n",
      "5e-05 0.9394698316874919\n",
      "5e-05 0.9394029844060099\n",
      "5e-05 0.9393361026140066\n",
      "5e-05 0.9392691863167348\n",
      "5e-05 0.9392022355194501\n",
      "5e-05 0.939135250227411\n",
      "5e-05 0.9390682304458782\n",
      "5e-05 0.9390011761801155\n",
      "5e-05 0.9389340874353893\n",
      "5e-05 0.9388669642169689\n",
      "5e-05 0.938799806530126\n",
      "5e-05 0.938732614380135\n",
      "5e-05 0.9386653877722733\n",
      "5e-05 0.9385981267118209\n",
      "5e-05 0.9385308312040603\n",
      "5e-05 0.9384635012542769\n",
      "5e-05 0.9383961368677589\n",
      "5e-05 0.9383287380497969\n",
      "5e-05 0.9382613048056845\n",
      "5e-05 0.9381938371407177\n",
      "5e-05 0.9381263350601956\n",
      "5e-05 0.9380587985694195\n",
      "5e-05 0.9379912276736941\n",
      "5e-05 0.937923622378326\n",
      "5e-05 0.9378559826886252\n",
      "5e-05 0.9377883086099039\n",
      "5e-05 0.9377206001474773\n",
      "5e-05 0.9376528573066629\n",
      "5e-05 0.9375850800927816\n",
      "5e-05 0.9375172685111565\n",
      "5e-05 0.9374494225671133\n",
      "5e-05 0.9373815422659806\n",
      "5e-05 0.93731362761309\n",
      "5e-05 0.9372456786137751\n",
      "5e-05 0.9371776952733728\n",
      "5e-05 0.9371096775972225\n",
      "5e-05 0.9370416255906662\n",
      "5e-05 0.9369735392590487\n",
      "5e-05 0.9369054186077175\n",
      "5e-05 0.9368372636420227\n",
      "5e-05 0.9367690743673172\n",
      "5e-05 0.9367008507889566\n",
      "5e-05 0.9366325929122991\n",
      "5e-05 0.9365643007427056\n",
      "5e-05 0.9364959742855398\n",
      "5e-05 0.936427613546168\n",
      "5e-05 0.9363592185299593\n",
      "5e-05 0.9362907892422854\n",
      "5e-05 0.9362223256885205\n",
      "5e-05 0.936153827874042\n",
      "5e-05 0.9360852958042294\n",
      "5e-05 0.9360167294844655\n",
      "5e-05 0.9359481289201352\n",
      "5e-05 0.9358794941166265\n",
      "5e-05 0.9358108250793299\n",
      "5e-05 0.9357421218136386\n",
      "5e-05 0.9356733843249486\n",
      "5e-05 0.9356046126186586\n",
      "5e-05 0.9355358067001696\n",
      "5e-05 0.9354669665748858\n",
      "5e-05 0.9353980922482139\n",
      "5e-05 0.9353291837255632\n",
      "5e-05 0.9352602410123456\n",
      "5e-05 0.9351912641139761\n",
      "5e-05 0.935122253035872\n",
      "5e-05 0.9350532077834535\n",
      "5e-05 0.9349841283621432\n",
      "5e-05 0.9349150147773666\n",
      "5e-05 0.9348458670345519\n",
      "5e-05 0.9347766851391299\n",
      "5e-05 0.9347074690965342\n",
      "5e-05 0.9346382189122009\n",
      "5e-05 0.9345689345915691\n",
      "5e-05 0.93449961614008\n",
      "5e-05 0.934430263563178\n",
      "5e-05 0.9343608768663102\n",
      "5e-05 0.934291456054926\n",
      "5e-05 0.9342220011344777\n",
      "5e-05 0.9341525121104203\n",
      "5e-05 0.9340829889882114\n",
      "5e-05 0.9340134317733114\n",
      "5e-05 0.9339438404711833\n",
      "5e-05 0.9338742150872925\n",
      "5e-05 0.9338045556271077\n",
      "5e-05 0.9337348620960998\n",
      "5e-05 0.9336651344997424\n",
      "5e-05 0.933595372843512\n",
      "5e-05 0.9335255771328876\n",
      "5e-05 0.933455747373351\n",
      "5e-05 0.9333858835703865\n",
      "5e-05 0.9333159857294812\n",
      "5e-05 0.9332460538561249\n",
      "5e-05 0.9331760879558099\n",
      "5e-05 0.9331060880340313\n",
      "5e-05 0.933036054096287\n",
      "5e-05 0.9329659861480774\n",
      "5e-05 0.9328958841949055\n",
      "5e-05 0.9328257482422772\n",
      "5e-05 0.9327555782957009\n",
      "5e-05 0.9326853743606875\n",
      "5e-05 0.9326151364427513\n",
      "5e-05 0.9325448645474083\n",
      "5e-05 0.9324745586801777\n",
      "5e-05 0.9324042188465815\n",
      "5e-05 0.932333845052144\n",
      "5e-05 0.9322634373023924\n",
      "5e-05 0.9321929956028564\n",
      "5e-05 0.9321225199590685\n",
      "5e-05 0.9320520103765638\n",
      "5e-05 0.9319814668608802\n",
      "5e-05 0.9319108894175581\n",
      "5e-05 0.9318402780521406\n",
      "5e-05 0.9317696327701734\n",
      "5e-05 0.9316989535772052\n",
      "Epoch: 21 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 2.272 | Train Acc @1:  42.12% | Train Acc @5:  73.85%\n",
      "\tValid Loss: 3.055 | Valid Acc @1:  26.77% | Valid Acc @5:  57.15%\n",
      "5e-05 0.931628240478787\n",
      "5e-05 0.9315574934804725\n",
      "5e-05 0.9314867125878179\n",
      "5e-05 0.9314158978063829\n",
      "5e-05 0.9313450491417288\n",
      "5e-05 0.9312741665994202\n",
      "5e-05 0.931203250185024\n",
      "5e-05 0.9311322999041103\n",
      "5e-05 0.9310613157622513\n",
      "5e-05 0.930990297765022\n",
      "5e-05 0.9309192459180001\n",
      "5e-05 0.9308481602267662\n",
      "5e-05 0.930777040696903\n",
      "5e-05 0.9307058873339966\n",
      "5e-05 0.930634700143635\n",
      "5e-05 0.9305634791314095\n",
      "5e-05 0.9304922243029137\n",
      "5e-05 0.9304209356637436\n",
      "5e-05 0.9303496132194986\n",
      "5e-05 0.9302782569757803\n",
      "5e-05 0.9302068669381927\n",
      "5e-05 0.9301354431123429\n",
      "5e-05 0.9300639855038405\n",
      "5e-05 0.9299924941182978\n",
      "5e-05 0.9299209689613297\n",
      "5e-05 0.9298494100385535\n",
      "5e-05 0.9297778173555897\n",
      "5e-05 0.9297061909180613\n",
      "5e-05 0.9296345307315934\n",
      "5e-05 0.9295628368018143\n",
      "5e-05 0.929491109134355\n",
      "5e-05 0.9294193477348486\n",
      "5e-05 0.9293475526089315\n",
      "5e-05 0.9292757237622424\n",
      "5e-05 0.9292038612004228\n",
      "5e-05 0.9291319649291165\n",
      "5e-05 0.9290600349539704\n",
      "5e-05 0.9289880712806338\n",
      "5e-05 0.9289160739147586\n",
      "5e-05 0.9288440428619997\n",
      "5e-05 0.9287719781280142\n",
      "5e-05 0.9286998797184618\n",
      "5e-05 0.9286277476390056\n",
      "5e-05 0.9285555818953104\n",
      "5e-05 0.9284833824930443\n",
      "5e-05 0.9284111494378777\n",
      "5e-05 0.9283388827354838\n",
      "5e-05 0.9282665823915384\n",
      "5e-05 0.9281942484117198\n",
      "5e-05 0.9281218808017093\n",
      "5e-05 0.9280494795671905\n",
      "5e-05 0.9279770447138499\n",
      "5e-05 0.9279045762473762\n",
      "5e-05 0.9278320741734614\n",
      "5e-05 0.9277595384977995\n",
      "5e-05 0.9276869692260874\n",
      "5e-05 0.927614366364025\n",
      "5e-05 0.9275417299173141\n",
      "5e-05 0.9274690598916598\n",
      "5e-05 0.9273963562927695\n",
      "5e-05 0.9273236191263533\n",
      "5e-05 0.9272508483981239\n",
      "5e-05 0.9271780441137968\n",
      "5e-05 0.9271052062790899\n",
      "5e-05 0.9270323348997239\n",
      "5e-05 0.9269594299814221\n",
      "5e-05 0.9268864915299104\n",
      "5e-05 0.9268135195509173\n",
      "5e-05 0.9267405140501741\n",
      "5e-05 0.9266674750334146\n",
      "5e-05 0.9265944025063753\n",
      "5e-05 0.9265212964747951\n",
      "5e-05 0.9264481569444157\n",
      "5e-05 0.9263749839209817\n",
      "5e-05 0.92630177741024\n",
      "5e-05 0.92622853741794\n",
      "5e-05 0.9261552639498343\n",
      "5e-05 0.9260819570116774\n",
      "5e-05 0.926008616609227\n",
      "5e-05 0.9259352427482431\n",
      "5e-05 0.9258618354344886\n",
      "5e-05 0.9257883946737289\n",
      "5e-05 0.9257149204717317\n",
      "5e-05 0.925641412834268\n",
      "5e-05 0.9255678717671109\n",
      "5e-05 0.9254942972760363\n",
      "5e-05 0.9254206893668225\n",
      "5e-05 0.925347048045251\n",
      "5e-05 0.9252733733171055\n",
      "5e-05 0.925199665188172\n",
      "5e-05 0.92512592366424\n",
      "5e-05 0.9250521487511008\n",
      "5e-05 0.9249783404545487\n",
      "5e-05 0.9249044987803807\n",
      "5e-05 0.9248306237343962\n",
      "5e-05 0.9247567153223973\n",
      "5e-05 0.9246827735501888\n",
      "5e-05 0.924608798423578\n",
      "5e-05 0.9245347899483749\n",
      "5e-05 0.9244607481303921\n",
      "5e-05 0.9243866729754449\n",
      "5e-05 0.924312564489351\n",
      "5e-05 0.9242384226779308\n",
      "5e-05 0.9241642475470074\n",
      "5e-05 0.9240900391024066\n",
      "5e-05 0.9240157973499566\n",
      "5e-05 0.9239415222954884\n",
      "5e-05 0.9238672139448354\n",
      "5e-05 0.923792872303834\n",
      "5e-05 0.9237184973783226\n",
      "5e-05 0.9236440891741429\n",
      "5e-05 0.9235696476971386\n",
      "5e-05 0.9234951729531564\n",
      "5e-05 0.9234206649480456\n",
      "5e-05 0.9233461236876581\n",
      "5e-05 0.9232715491778483\n",
      "5e-05 0.923196941424473\n",
      "5e-05 0.923122300433392\n",
      "Epoch: 22 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 2.148 | Train Acc @1:  45.17% | Train Acc @5:  76.69%\n",
      "\tValid Loss: 3.080 | Valid Acc @1:  27.08% | Valid Acc @5:  56.26%\n",
      "5e-05 0.9230476262104677\n",
      "5e-05 0.922972918761565\n",
      "5e-05 0.9228981780925511\n",
      "5e-05 0.9228234042092963\n",
      "5e-05 0.9227485971176733\n",
      "5e-05 0.9226737568235575\n",
      "5e-05 0.9225988833328267\n",
      "5e-05 0.9225239766513613\n",
      "5e-05 0.9224490367850449\n",
      "5e-05 0.9223740637397626\n",
      "5e-05 0.9222990575214033\n",
      "5e-05 0.9222240181358577\n",
      "5e-05 0.9221489455890195\n",
      "5e-05 0.9220738398867847\n",
      "5e-05 0.9219987010350521\n",
      "5e-05 0.9219235290397232\n",
      "5e-05 0.9218483239067019\n",
      "5e-05 0.9217730856418946\n",
      "5e-05 0.9216978142512109\n",
      "5e-05 0.9216225097405623\n",
      "5e-05 0.9215471721158631\n",
      "5e-05 0.9214718013830305\n",
      "5e-05 0.921396397547984\n",
      "5e-05 0.9213209606166457\n",
      "5e-05 0.9212454905949405\n",
      "5e-05 0.9211699874887957\n",
      "5e-05 0.9210944513041415\n",
      "5e-05 0.9210188820469102\n",
      "5e-05 0.920943279723037\n",
      "5e-05 0.9208676443384598\n",
      "5e-05 0.920791975899119\n",
      "5e-05 0.9207162744109575\n",
      "5e-05 0.9206405398799208\n",
      "5e-05 0.920564772311957\n",
      "5e-05 0.9204889717130171\n",
      "5e-05 0.9204131380890543\n",
      "5e-05 0.9203372714460246\n",
      "5e-05 0.9202613717898864\n",
      "5e-05 0.920185439126601\n",
      "5e-05 0.920109473462132\n",
      "5e-05 0.9200334748024457\n",
      "5e-05 0.9199574431535111\n",
      "5e-05 0.9198813785212996\n",
      "5e-05 0.9198052809117853\n",
      "5e-05 0.9197291503309448\n",
      "5e-05 0.9196529867847576\n",
      "5e-05 0.9195767902792054\n",
      "5e-05 0.9195005608202726\n",
      "5e-05 0.9194242984139465\n",
      "5e-05 0.9193480030662162\n",
      "5e-05 0.9192716747830743\n",
      "5e-05 0.9191953135705155\n",
      "5e-05 0.919118919434537\n",
      "5e-05 0.9190424923811391\n",
      "5e-05 0.9189660324163242\n",
      "5e-05 0.9188895395460974\n",
      "5e-05 0.9188130137764664\n",
      "5e-05 0.9187364551134416\n",
      "5e-05 0.9186598635630356\n",
      "5e-05 0.9185832391312643\n",
      "5e-05 0.9185065818241454\n",
      "5e-05 0.9184298916476997\n",
      "5e-05 0.9183531686079505\n",
      "5e-05 0.9182764127109233\n",
      "5e-05 0.9181996239626466\n",
      "5e-05 0.9181228023691516\n",
      "5e-05 0.9180459479364715\n",
      "5e-05 0.9179690606706425\n",
      "5e-05 0.9178921405777034\n",
      "5e-05 0.9178151876636955\n",
      "5e-05 0.9177382019346625\n",
      "5e-05 0.9176611833966508\n",
      "5e-05 0.9175841320557097\n",
      "5e-05 0.9175070479178904\n",
      "5e-05 0.9174299309892473\n",
      "5e-05 0.9173527812758369\n",
      "5e-05 0.9172755987837188\n",
      "5e-05 0.9171983835189548\n",
      "5e-05 0.9171211354876092\n",
      "5e-05 0.917043854695749\n",
      "5e-05 0.9169665411494441\n",
      "5e-05 0.9168891948547664\n",
      "5e-05 0.9168118158177908\n",
      "5e-05 0.9167344040445945\n",
      "5e-05 0.9166569595412575\n",
      "5e-05 0.9165794823138622\n",
      "5e-05 0.9165019723684935\n",
      "5e-05 0.9164244297112393\n",
      "5e-05 0.9163468543481895\n",
      "5e-05 0.9162692462854369\n",
      "5e-05 0.9161916055290769\n",
      "5e-05 0.9161139320852073\n",
      "5e-05 0.9160362259599285\n",
      "5e-05 0.9159584871593436\n",
      "5e-05 0.9158807156895581\n",
      "5e-05 0.9158029115566801\n",
      "5e-05 0.9157250747668204\n",
      "5e-05 0.9156472053260922\n",
      "5e-05 0.9155693032406114\n",
      "5e-05 0.9154913685164964\n",
      "5e-05 0.915413401159868\n",
      "5e-05 0.91533540117685\n",
      "5e-05 0.9152573685735681\n",
      "5e-05 0.9151793033561513\n",
      "5e-05 0.9151012055307308\n",
      "5e-05 0.91502307510344\n",
      "5e-05 0.9149449120804156\n",
      "5e-05 0.9148667164677965\n",
      "5e-05 0.9147884882717239\n",
      "5e-05 0.9147102274983419\n",
      "5e-05 0.9146319341537972\n",
      "5e-05 0.9145536082442387\n",
      "5e-05 0.9144752497758182\n",
      "5e-05 0.91439685875469\n",
      "5e-05 0.9143184351870108\n",
      "5e-05 0.9142399790789402\n",
      "5e-05 0.9141614904366396\n",
      "5e-05 0.914082969266274\n",
      "Epoch: 23 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 2.061 | Train Acc @1:  46.71% | Train Acc @5:  78.36%\n",
      "\tValid Loss: 3.113 | Valid Acc @1:  26.61% | Valid Acc @5:  55.52%\n",
      "5e-05 0.91400441557401\n",
      "5e-05 0.9139258293660175\n",
      "5e-05 0.9138472106484684\n",
      "5e-05 0.9137685594275375\n",
      "5e-05 0.9136898757094021\n",
      "5e-05 0.9136111595002417\n",
      "5e-05 0.913532410806239\n",
      "5e-05 0.9134536296335787\n",
      "5e-05 0.913374815988448\n",
      "5e-05 0.9132959698770374\n",
      "5e-05 0.9132170913055391\n",
      "5e-05 0.9131381802801484\n",
      "5e-05 0.9130592368070627\n",
      "5e-05 0.9129802608924822\n",
      "5e-05 0.9129012525426098\n",
      "5e-05 0.9128222117636507\n",
      "5e-05 0.9127431385618128\n",
      "5e-05 0.9126640329433064\n",
      "5e-05 0.9125848949143444\n",
      "5e-05 0.9125057244811423\n",
      "5e-05 0.9124265216499181\n",
      "5e-05 0.9123472864268924\n",
      "5e-05 0.9122680188182883\n",
      "5e-05 0.9121887188303314\n",
      "5e-05 0.9121093864692499\n",
      "5e-05 0.9120300217412745\n",
      "5e-05 0.9119506246526385\n",
      "5e-05 0.9118711952095777\n",
      "5e-05 0.9117917334183305\n",
      "5e-05 0.9117122392851378\n",
      "5e-05 0.9116327128162429\n",
      "5e-05 0.911553154017892\n",
      "5e-05 0.9114735628963335\n",
      "5e-05 0.9113939394578183\n",
      "5e-05 0.9113142837086002\n",
      "5e-05 0.9112345956549354\n",
      "5e-05 0.9111548753030823\n",
      "5e-05 0.9110751226593021\n",
      "5e-05 0.9109953377298589\n",
      "5e-05 0.9109155205210187\n",
      "5e-05 0.9108356710390502\n",
      "5e-05 0.9107557892902249\n",
      "5e-05 0.9106758752808168\n",
      "5e-05 0.9105959290171022\n",
      "5e-05 0.9105159505053598\n",
      "5e-05 0.9104359397518715\n",
      "5e-05 0.9103558967629211\n",
      "5e-05 0.9102758215447951\n",
      "5e-05 0.9101957141037826\n",
      "5e-05 0.9101155744461753\n",
      "5e-05 0.9100354025782673\n",
      "5e-05 0.9099551985063552\n",
      "5e-05 0.9098749622367384\n",
      "5e-05 0.9097946937757182\n",
      "5e-05 0.9097143931295991\n",
      "5e-05 0.909634060304688\n",
      "5e-05 0.909553695307294\n",
      "5e-05 0.909473298143729\n",
      "5e-05 0.9093928688203075\n",
      "5e-05 0.9093124073433463\n",
      "5e-05 0.9092319137191646\n",
      "5e-05 0.9091513879540845\n",
      "5e-05 0.9090708300544306\n",
      "5e-05 0.9089902400265296\n",
      "5e-05 0.9089096178767113\n",
      "5e-05 0.9088289636113074\n",
      "5e-05 0.9087482772366527\n",
      "5e-05 0.9086675587590842\n",
      "5e-05 0.9085868081849416\n",
      "5e-05 0.9085060255205668\n",
      "5e-05 0.9084252107723046\n",
      "5e-05 0.9083443639465021\n",
      "5e-05 0.908263485049509\n",
      "5e-05 0.9081825740876774\n",
      "5e-05 0.9081016310673622\n",
      "5e-05 0.9080206559949204\n",
      "5e-05 0.907939648876712\n",
      "5e-05 0.907858609719099\n",
      "5e-05 0.9077775385284463\n",
      "5e-05 0.9076964353111214\n",
      "5e-05 0.9076153000734937\n",
      "5e-05 0.9075341328219357\n",
      "5e-05 0.9074529335628225\n",
      "5e-05 0.9073717023025312\n",
      "5e-05 0.9072904390474416\n",
      "5e-05 0.9072091438039362\n",
      "5e-05 0.9071278165784\n",
      "5e-05 0.9070464573772201\n",
      "5e-05 0.9069650662067867\n",
      "5e-05 0.9068836430734921\n",
      "5e-05 0.9068021879837314\n",
      "5e-05 0.9067207009439018\n",
      "5e-05 0.9066391819604034\n",
      "5e-05 0.9065576310396386\n",
      "5e-05 0.9064760481880125\n",
      "5e-05 0.9063944334119325\n",
      "5e-05 0.9063127867178085\n",
      "5e-05 0.9062311081120531\n",
      "5e-05 0.9061493976010813\n",
      "5e-05 0.9060676551913105\n",
      "5e-05 0.905985880889161\n",
      "5e-05 0.9059040747010549\n",
      "5e-05 0.9058222366334177\n",
      "5e-05 0.9057403666926764\n",
      "5e-05 0.9056584648852615\n",
      "5e-05 0.9055765312176053\n",
      "5e-05 0.9054945656961428\n",
      "5e-05 0.9054125683273117\n",
      "5e-05 0.9053305391175519\n",
      "5e-05 0.905248478073306\n",
      "5e-05 0.905166385201019\n",
      "5e-05 0.9050842605071385\n",
      "5e-05 0.9050021039981144\n",
      "5e-05 0.9049199156803994\n",
      "5e-05 0.9048376955604485\n",
      "5e-05 0.9047554436447192\n",
      "5e-05 0.9046731599396716\n",
      "5e-05 0.9045908444517681\n",
      "Epoch: 24 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 1.944 | Train Acc @1:  49.20% | Train Acc @5:  80.90%\n",
      "\tValid Loss: 2.962 | Valid Acc @1:  30.17% | Valid Acc @5:  60.19%\n",
      "5e-05 0.9045084971874737\n",
      "5e-05 0.904426118153256\n",
      "5e-05 0.9043437073555852\n",
      "5e-05 0.9042612648009336\n",
      "5e-05 0.9041787904957761\n",
      "5e-05 0.9040962844465903\n",
      "5e-05 0.9040137466598563\n",
      "5e-05 0.9039311771420566\n",
      "5e-05 0.9038485758996759\n",
      "5e-05 0.903765942939202\n",
      "5e-05 0.9036832782671246\n",
      "5e-05 0.9036005818899362\n",
      "5e-05 0.9035178538141317\n",
      "5e-05 0.9034350940462088\n",
      "5e-05 0.9033523025926673\n",
      "5e-05 0.9032694794600094\n",
      "5e-05 0.90318662465474\n",
      "5e-05 0.9031037381833669\n",
      "5e-05 0.9030208200523994\n",
      "5e-05 0.9029378702683502\n",
      "5e-05 0.9028548888377341\n",
      "5e-05 0.9027718757670684\n",
      "5e-05 0.9026888310628729\n",
      "5e-05 0.9026057547316698\n",
      "5e-05 0.9025226467799841\n",
      "5e-05 0.902439507214343\n",
      "5e-05 0.902356336041276\n",
      "5e-05 0.9022731332673155\n",
      "5e-05 0.9021898988989965\n",
      "5e-05 0.9021066329428556\n",
      "5e-05 0.902023335405433\n",
      "5e-05 0.9019400062932705\n",
      "5e-05 0.901856645612913\n",
      "5e-05 0.9017732533709075\n",
      "5e-05 0.9016898295738035\n",
      "5e-05 0.901606374228153\n",
      "5e-05 0.901522887340511\n",
      "5e-05 0.901439368917434\n",
      "5e-05 0.9013558189654818\n",
      "5e-05 0.9012722374912163\n",
      "5e-05 0.901188624501202\n",
      "5e-05 0.9011049800020057\n",
      "5e-05 0.9010213040001969\n",
      "5e-05 0.9009375965023474\n",
      "5e-05 0.9008538575150317\n",
      "5e-05 0.9007700870448264\n",
      "5e-05 0.9006862850983111\n",
      "5e-05 0.9006024516820672\n",
      "5e-05 0.9005185868026793\n",
      "5e-05 0.900434690466734\n",
      "5e-05 0.9003507626808203\n",
      "5e-05 0.90026680345153\n",
      "5e-05 0.9001828127854572\n",
      "5e-05 0.9000987906891984\n",
      "5e-05 0.900014737169353\n",
      "5e-05 0.8999306522325221\n",
      "5e-05 0.8998465358853098\n",
      "5e-05 0.8997623881343229\n",
      "5e-05 0.8996782089861699\n",
      "5e-05 0.8995939984474624\n",
      "5e-05 0.8995097565248142\n",
      "5e-05 0.8994254832248416\n",
      "5e-05 0.8993411785541636\n",
      "5e-05 0.8992568425194012\n",
      "5e-05 0.8991724751271781\n",
      "5e-05 0.8990880763841207\n",
      "5e-05 0.8990036462968575\n",
      "5e-05 0.8989191848720196\n",
      "5e-05 0.8988346921162407\n",
      "5e-05 0.8987501680361565\n",
      "5e-05 0.8986656126384058\n",
      "5e-05 0.8985810259296294\n",
      "5e-05 0.8984964079164708\n",
      "5e-05 0.8984117586055759\n",
      "5e-05 0.8983270780035928\n",
      "5e-05 0.8982423661171725\n",
      "5e-05 0.898157622952968\n",
      "5e-05 0.8980728485176352\n",
      "5e-05 0.8979880428178322\n",
      "5e-05 0.8979032058602197\n",
      "5e-05 0.8978183376514606\n",
      "5e-05 0.8977334381982203\n",
      "5e-05 0.897648507507167\n",
      "5e-05 0.8975635455849711\n",
      "5e-05 0.8974785524383053\n",
      "5e-05 0.8973935280738451\n",
      "5e-05 0.8973084724982683\n",
      "5e-05 0.8972233857182549\n",
      "5e-05 0.8971382677404878\n",
      "5e-05 0.897053118571652\n",
      "5e-05 0.8969679382184352\n",
      "5e-05 0.8968827266875273\n",
      "5e-05 0.8967974839856209\n",
      "5e-05 0.8967122101194108\n",
      "5e-05 0.8966269050955945\n",
      "5e-05 0.8965415689208718\n",
      "5e-05 0.8964562016019448\n",
      "5e-05 0.8963708031455184\n",
      "5e-05 0.8962853735582996\n",
      "5e-05 0.8961999128469982\n",
      "5e-05 0.8961144210183262\n",
      "5e-05 0.8960288980789979\n",
      "5e-05 0.8959433440357305\n",
      "5e-05 0.8958577588952431\n",
      "5e-05 0.8957721426642578\n",
      "5e-05 0.8956864953494986\n",
      "5e-05 0.8956008169576924\n",
      "5e-05 0.8955151074955683\n",
      "5e-05 0.8954293669698579\n",
      "5e-05 0.895343595387295\n",
      "5e-05 0.8952577927546164\n",
      "5e-05 0.8951719590785608\n",
      "5e-05 0.8950860943658696\n",
      "5e-05 0.8950001986232867\n",
      "5e-05 0.894914271857558\n",
      "5e-05 0.8948283140754323\n",
      "5e-05 0.8947423252836608\n",
      "5e-05 0.8946563054889971\n",
      "Epoch: 25 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 1.839 | Train Acc @1:  52.18% | Train Acc @5:  82.95%\n",
      "\tValid Loss: 3.050 | Valid Acc @1:  28.92% | Valid Acc @5:  58.97%\n",
      "5e-05 0.8945702546981968\n",
      "5e-05 0.8944841729180186\n",
      "5e-05 0.894398060155223\n",
      "5e-05 0.8943119164165738\n",
      "5e-05 0.8942257417088362\n",
      "5e-05 0.8941395360387785\n",
      "5e-05 0.8940532994131712\n",
      "5e-05 0.8939670318387875\n",
      "5e-05 0.8938807333224026\n",
      "5e-05 0.8937944038707943\n",
      "5e-05 0.893708043490743\n",
      "5e-05 0.8936216521890314\n",
      "5e-05 0.8935352299724447\n",
      "5e-05 0.8934487768477704\n",
      "5e-05 0.8933622928217984\n",
      "5e-05 0.8932757779013213\n",
      "5e-05 0.8931892320931337\n",
      "5e-05 0.8931026554040331\n",
      "5e-05 0.8930160478408191\n",
      "5e-05 0.8929294094102939\n",
      "5e-05 0.8928427401192618\n",
      "5e-05 0.8927560399745301\n",
      "5e-05 0.892669308982908\n",
      "5e-05 0.8925825471512073\n",
      "5e-05 0.8924957544862424\n",
      "5e-05 0.8924089309948298\n",
      "5e-05 0.8923220766837885\n",
      "5e-05 0.8922351915599402\n",
      "5e-05 0.8921482756301088\n",
      "5e-05 0.8920613289011206\n",
      "5e-05 0.8919743513798043\n",
      "5e-05 0.8918873430729911\n",
      "5e-05 0.8918003039875146\n",
      "5e-05 0.891713234130211\n",
      "5e-05 0.8916261335079183\n",
      "5e-05 0.8915390021274778\n",
      "5e-05 0.8914518399957325\n",
      "5e-05 0.8913646471195281\n",
      "5e-05 0.8912774235057128\n",
      "5e-05 0.891190169161137\n",
      "5e-05 0.8911028840926537\n",
      "5e-05 0.8910155683071181\n",
      "5e-05 0.8909282218113882\n",
      "5e-05 0.8908408446123238\n",
      "5e-05 0.8907534367167877\n",
      "5e-05 0.8906659981316449\n",
      "5e-05 0.8905785288637628\n",
      "5e-05 0.890491028920011\n",
      "5e-05 0.8904034983072617\n",
      "5e-05 0.8903159370323899\n",
      "5e-05 0.8902283451022723\n",
      "5e-05 0.8901407225237883\n",
      "5e-05 0.89005306930382\n",
      "5e-05 0.8899653854492513\n",
      "5e-05 0.8898776709669691\n",
      "5e-05 0.8897899258638625\n",
      "5e-05 0.8897021501468229\n",
      "5e-05 0.889614343822744\n",
      "5e-05 0.8895265068985222\n",
      "5e-05 0.8894386393810563\n",
      "5e-05 0.889350741277247\n",
      "5e-05 0.8892628125939983\n",
      "5e-05 0.8891748533382157\n",
      "5e-05 0.8890868635168077\n",
      "5e-05 0.8889988431366846\n",
      "5e-05 0.8889107922047601\n",
      "5e-05 0.888822710727949\n",
      "5e-05 0.8887345987131698\n",
      "5e-05 0.8886464561673424\n",
      "5e-05 0.8885582830973896\n",
      "5e-05 0.8884700795102364\n",
      "5e-05 0.8883818454128104\n",
      "5e-05 0.8882935808120414\n",
      "5e-05 0.8882052857148616\n",
      "5e-05 0.8881169601282057\n",
      "5e-05 0.8880286040590109\n",
      "5e-05 0.8879402175142164\n",
      "5e-05 0.8878518005007641\n",
      "5e-05 0.8877633530255984\n",
      "5e-05 0.8876748750956658\n",
      "5e-05 0.8875863667179154\n",
      "5e-05 0.8874978278992984\n",
      "5e-05 0.8874092586467689\n",
      "5e-05 0.8873206589672828\n",
      "5e-05 0.8872320288677991\n",
      "5e-05 0.8871433683552782\n",
      "5e-05 0.8870546774366839\n",
      "5e-05 0.8869659561189818\n",
      "5e-05 0.8868772044091399\n",
      "5e-05 0.8867884223141289\n",
      "5e-05 0.8866996098409217\n",
      "5e-05 0.8866107669964935\n",
      "5e-05 0.8865218937878221\n",
      "5e-05 0.8864329902218875\n",
      "5e-05 0.886344056305672\n",
      "5e-05 0.8862550920461607\n",
      "5e-05 0.8861660974503407\n",
      "5e-05 0.8860770725252016\n",
      "5e-05 0.8859880172777352\n",
      "5e-05 0.8858989317149363\n",
      "5e-05 0.8858098158438013\n",
      "5e-05 0.8857206696713291\n",
      "5e-05 0.8856314932045217\n",
      "5e-05 0.8855422864503828\n",
      "5e-05 0.8854530494159187\n",
      "5e-05 0.8853637821081379\n",
      "5e-05 0.8852744845340514\n",
      "5e-05 0.8851851567006728\n",
      "5e-05 0.8850957986150176\n",
      "5e-05 0.8850064102841043\n",
      "5e-05 0.8849169917149531\n",
      "5e-05 0.8848275429145871\n",
      "5e-05 0.8847380638900313\n",
      "5e-05 0.8846485546483137\n",
      "5e-05 0.8845590151964642\n",
      "5e-05 0.884469445541515\n",
      "5e-05 0.884379845690501\n",
      "5e-05 0.8842902156504593\n",
      "Epoch: 26 | Epoch Time: 1m 28s\n",
      "\tTrain Loss: 1.727 | Train Acc @1:  55.54% | Train Acc @5:  84.60%\n",
      "\tValid Loss: 2.961 | Valid Acc @1:  30.88% | Valid Acc @5:  59.38%\n",
      "5e-05 0.8842005554284296\n",
      "5e-05 0.8841108650314533\n",
      "5e-05 0.8840211444665753\n",
      "5e-05 0.8839313937408417\n",
      "5e-05 0.8838416128613017\n",
      "5e-05 0.8837518018350066\n",
      "5e-05 0.8836619606690101\n",
      "5e-05 0.8835720893703682\n",
      "5e-05 0.8834821879461396\n",
      "5e-05 0.8833922564033851\n",
      "5e-05 0.8833022947491675\n",
      "5e-05 0.8832123029905529\n",
      "5e-05 0.8831222811346088\n",
      "5e-05 0.8830322291884056\n",
      "5e-05 0.882942147159016\n",
      "5e-05 0.8828520350535148\n",
      "5e-05 0.8827618928789798\n",
      "5e-05 0.8826717206424901\n",
      "5e-05 0.8825815183511283\n",
      "5e-05 0.8824912860119788\n",
      "5e-05 0.8824010236321282\n",
      "5e-05 0.8823107312186658\n",
      "5e-05 0.882220408778683\n",
      "5e-05 0.8821300563192738\n",
      "5e-05 0.8820396738475345\n",
      "5e-05 0.8819492613705635\n",
      "5e-05 0.881858818895462\n",
      "5e-05 0.8817683464293331\n",
      "5e-05 0.8816778439792826\n",
      "5e-05 0.8815873115524185\n",
      "5e-05 0.8814967491558512\n",
      "5e-05 0.8814061567966933\n",
      "5e-05 0.88131553448206\n",
      "5e-05 0.8812248822190687\n",
      "5e-05 0.8811342000148392\n",
      "5e-05 0.8810434878764937\n",
      "5e-05 0.8809527458111567\n",
      "5e-05 0.8808619738259549\n",
      "5e-05 0.8807711719280176\n",
      "5e-05 0.8806803401244763\n",
      "5e-05 0.8805894784224648\n",
      "5e-05 0.8804985868291195\n",
      "5e-05 0.8804076653515791\n",
      "5e-05 0.8803167139969842\n",
      "5e-05 0.8802257327724783\n",
      "5e-05 0.8801347216852069\n",
      "5e-05 0.8800436807423181\n",
      "5e-05 0.8799526099509621\n",
      "5e-05 0.8798615093182918\n",
      "5e-05 0.8797703788514618\n",
      "5e-05 0.8796792185576299\n",
      "5e-05 0.8795880284439552\n",
      "5e-05 0.8794968085176005\n",
      "5e-05 0.8794055587857296\n",
      "5e-05 0.8793142792555093\n",
      "5e-05 0.8792229699341089\n",
      "5e-05 0.8791316308286996\n",
      "5e-05 0.879040261946455\n",
      "5e-05 0.8789488632945515\n",
      "5e-05 0.8788574348801674\n",
      "5e-05 0.8787659767104833\n",
      "5e-05 0.8786744887926824\n",
      "5e-05 0.8785829711339501\n",
      "5e-05 0.8784914237414742\n",
      "5e-05 0.8783998466224447\n",
      "5e-05 0.8783082397840541\n",
      "5e-05 0.8782166032334973\n",
      "5e-05 0.8781249369779709\n",
      "5e-05 0.878033241024675\n",
      "5e-05 0.8779415153808109\n",
      "5e-05 0.8778497600535828\n",
      "5e-05 0.8777579750501971\n",
      "5e-05 0.8776661603778628\n",
      "5e-05 0.8775743160437905\n",
      "5e-05 0.8774824420551941\n",
      "5e-05 0.8773905384192893\n",
      "5e-05 0.8772986051432937\n",
      "5e-05 0.8772066422344281\n",
      "5e-05 0.8771146496999151\n",
      "5e-05 0.87702262754698\n",
      "5e-05 0.8769305757828498\n",
      "5e-05 0.8768384944147545\n",
      "5e-05 0.876746383449926\n",
      "5e-05 0.8766542428955986\n",
      "5e-05 0.8765620727590091\n",
      "5e-05 0.8764698730473964\n",
      "5e-05 0.876377643768002\n",
      "5e-05 0.8762853849280692\n",
      "5e-05 0.8761930965348443\n",
      "5e-05 0.8761007785955757\n",
      "5e-05 0.8760084311175136\n",
      "5e-05 0.8759160541079111\n",
      "5e-05 0.8758236475740235\n",
      "5e-05 0.8757312115231084\n",
      "5e-05 0.8756387459624255\n",
      "5e-05 0.8755462508992373\n",
      "5e-05 0.8754537263408082\n",
      "5e-05 0.8753611722944048\n",
      "5e-05 0.8752685887672966\n",
      "5e-05 0.875175975766755\n",
      "5e-05 0.8750833333000536\n",
      "5e-05 0.8749906613744687\n",
      "5e-05 0.8748979599972786\n",
      "5e-05 0.874805229175764\n",
      "5e-05 0.8747124689172079\n",
      "5e-05 0.8746196792288958\n",
      "5e-05 0.8745268601181155\n",
      "5e-05 0.8744340115921566\n",
      "5e-05 0.8743411336583116\n",
      "5e-05 0.8742482263238751\n",
      "5e-05 0.8741552895961439\n",
      "5e-05 0.8740623234824172\n",
      "5e-05 0.8739693279899967\n",
      "5e-05 0.873876303126186\n",
      "5e-05 0.8737832488982915\n",
      "5e-05 0.8736901653136213\n",
      "5e-05 0.8735970523794865\n",
      "5e-05 0.8735039101031998\n",
      "Epoch: 27 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 1.627 | Train Acc @1:  57.17% | Train Acc @5:  86.05%\n",
      "\tValid Loss: 2.787 | Valid Acc @1:  33.02% | Valid Acc @5:  63.54%\n",
      "5e-05 0.873410738492077\n",
      "5e-05 0.8733175375534352\n",
      "5e-05 0.8732243072945949\n",
      "5e-05 0.873131047722878\n",
      "5e-05 0.8730377588456091\n",
      "5e-05 0.8729444406701152\n",
      "5e-05 0.8728510932037254\n",
      "5e-05 0.8727577164537713\n",
      "5e-05 0.8726643104275865\n",
      "5e-05 0.8725708751325072\n",
      "5e-05 0.8724774105758716\n",
      "5e-05 0.8723839167650205\n",
      "5e-05 0.8722903937072968\n",
      "5e-05 0.8721968414100458\n",
      "5e-05 0.872103259880615\n",
      "5e-05 0.8720096491263544\n",
      "5e-05 0.8719160091546159\n",
      "5e-05 0.8718223399727543\n",
      "5e-05 0.8717286415881259\n",
      "5e-05 0.8716349140080901\n",
      "5e-05 0.871541157240008\n",
      "5e-05 0.8714473712912434\n",
      "5e-05 0.871353556169162\n",
      "5e-05 0.8712597118811322\n",
      "5e-05 0.8711658384345243\n",
      "5e-05 0.8710719358367112\n",
      "5e-05 0.870978004095068\n",
      "5e-05 0.870884043216972\n",
      "5e-05 0.8707900532098027\n",
      "5e-05 0.8706960340809423\n",
      "5e-05 0.8706019858377749\n",
      "5e-05 0.8705079084876871\n",
      "5e-05 0.8704138020380675\n",
      "5e-05 0.8703196664963073\n",
      "5e-05 0.8702255018698\n",
      "5e-05 0.8701313081659409\n",
      "5e-05 0.8700370853921282\n",
      "5e-05 0.8699428335557621\n",
      "5e-05 0.869848552664245\n",
      "5e-05 0.8697542427249817\n",
      "5e-05 0.8696599037453794\n",
      "5e-05 0.8695655357328472\n",
      "5e-05 0.869471138694797\n",
      "5e-05 0.8693767126386425\n",
      "5e-05 0.8692822575718\n",
      "5e-05 0.8691877735016877\n",
      "5e-05 0.8690932604357268\n",
      "5e-05 0.8689987183813399\n",
      "5e-05 0.8689041473459524\n",
      "5e-05 0.8688095473369921\n",
      "5e-05 0.8687149183618887\n",
      "5e-05 0.8686202604280742\n",
      "5e-05 0.8685255735429829\n",
      "5e-05 0.8684308577140518\n",
      "5e-05 0.8683361129487197\n",
      "5e-05 0.8682413392544278\n",
      "5e-05 0.8681465366386196\n",
      "5e-05 0.8680517051087407\n",
      "5e-05 0.8679568446722394\n",
      "5e-05 0.8678619553365658\n",
      "5e-05 0.8677670371091726\n",
      "5e-05 0.8676720899975146\n",
      "5e-05 0.8675771140090487\n",
      "5e-05 0.8674821091512346\n",
      "5e-05 0.8673870754315336\n",
      "5e-05 0.86729201285741\n",
      "5e-05 0.8671969214363296\n",
      "5e-05 0.8671018011757612\n",
      "5e-05 0.8670066520831752\n",
      "5e-05 0.8669114741660446\n",
      "5e-05 0.8668162674318449\n",
      "5e-05 0.8667210318880532\n",
      "5e-05 0.8666257675421496\n",
      "5e-05 0.866530474401616\n",
      "5e-05 0.8664351524739367\n",
      "5e-05 0.8663398017665981\n",
      "5e-05 0.8662444222870892\n",
      "5e-05 0.8661490140429009\n",
      "5e-05 0.8660535770415267\n",
      "5e-05 0.865958111290462\n",
      "5e-05 0.8658626167972048\n",
      "5e-05 0.8657670935692551\n",
      "5e-05 0.8656715416141152\n",
      "5e-05 0.8655759609392899\n",
      "5e-05 0.8654803515522859\n",
      "5e-05 0.8653847134606123\n",
      "5e-05 0.8652890466717806\n",
      "5e-05 0.8651933511933043\n",
      "5e-05 0.8650976270326995\n",
      "5e-05 0.8650018741974841\n",
      "5e-05 0.8649060926951786\n",
      "5e-05 0.8648102825333055\n",
      "5e-05 0.8647144437193899\n",
      "5e-05 0.8646185762609588\n",
      "5e-05 0.8645226801655417\n",
      "5e-05 0.8644267554406702\n",
      "5e-05 0.864330802093878\n",
      "5e-05 0.8642348201327015\n",
      "5e-05 0.8641388095646789\n",
      "5e-05 0.864042770397351\n",
      "5e-05 0.8639467026382605\n",
      "5e-05 0.8638506062949525\n",
      "5e-05 0.8637544813749746\n",
      "5e-05 0.8636583278858763\n",
      "5e-05 0.8635621458352093\n",
      "5e-05 0.8634659352305278\n",
      "5e-05 0.8633696960793882\n",
      "5e-05 0.8632734283893491\n",
      "5e-05 0.8631771321679713\n",
      "5e-05 0.8630808074228178\n",
      "5e-05 0.8629844541614538\n",
      "5e-05 0.862888072391447\n",
      "5e-05 0.8627916621203673\n",
      "5e-05 0.8626952233557865\n",
      "5e-05 0.8625987561052788\n",
      "5e-05 0.8625022603764211\n",
      "5e-05 0.8624057361767917\n",
      "5e-05 0.8623091835139718\n",
      "Epoch: 28 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 1.536 | Train Acc @1:  59.73% | Train Acc @5:  87.80%\n",
      "\tValid Loss: 2.879 | Valid Acc @1:  32.93% | Valid Acc @5:  61.47%\n",
      "5e-05 0.8622126023955445\n",
      "5e-05 0.8621159928290953\n",
      "5e-05 0.8620193548222118\n",
      "5e-05 0.861922688382484\n",
      "5e-05 0.861825993517504\n",
      "5e-05 0.8617292702348662\n",
      "5e-05 0.8616325185421672\n",
      "5e-05 0.8615357384470057\n",
      "5e-05 0.861438929956983\n",
      "5e-05 0.8613420930797022\n",
      "5e-05 0.861245227822769\n",
      "5e-05 0.8611483341937911\n",
      "5e-05 0.8610514122003783\n",
      "5e-05 0.860954461850143\n",
      "5e-05 0.8608574831506997\n",
      "5e-05 0.8607604761096648\n",
      "5e-05 0.8606634407346574\n",
      "5e-05 0.8605663770332986\n",
      "5e-05 0.8604692850132117\n",
      "5e-05 0.8603721646820224\n",
      "5e-05 0.8602750160473582\n",
      "5e-05 0.8601778391168493\n",
      "5e-05 0.8600806338981279\n",
      "5e-05 0.8599834003988286\n",
      "5e-05 0.8598861386265879\n",
      "5e-05 0.8597888485890447\n",
      "5e-05 0.8596915302938402\n",
      "5e-05 0.8595941837486176\n",
      "5e-05 0.8594968089610227\n",
      "5e-05 0.859399405938703\n",
      "5e-05 0.8593019746893087\n",
      "5e-05 0.8592045152204919\n",
      "5e-05 0.8591070275399071\n",
      "5e-05 0.8590095116552108\n",
      "5e-05 0.858911967574062\n",
      "5e-05 0.8588143953041216\n",
      "5e-05 0.8587167948530532\n",
      "5e-05 0.858619166228522\n",
      "5e-05 0.8585215094381957\n",
      "5e-05 0.8584238244897445\n",
      "5e-05 0.8583261113908404\n",
      "5e-05 0.8582283701491575\n",
      "5e-05 0.8581306007723728\n",
      "5e-05 0.8580328032681648\n",
      "5e-05 0.8579349776442143\n",
      "5e-05 0.8578371239082048\n",
      "5e-05 0.8577392420678216\n",
      "5e-05 0.8576413321307523\n",
      "5e-05 0.8575433941046867\n",
      "5e-05 0.8574454279973167\n",
      "5e-05 0.8573474338163367\n",
      "5e-05 0.8572494115694429\n",
      "5e-05 0.8571513612643342\n",
      "5e-05 0.8570532829087112\n",
      "5e-05 0.856955176510277\n",
      "5e-05 0.856857042076737\n",
      "5e-05 0.8567588796157982\n",
      "5e-05 0.8566606891351707\n",
      "5e-05 0.8565624706425661\n",
      "5e-05 0.8564642241456986\n",
      "5e-05 0.8563659496522842\n",
      "5e-05 0.8562676471700416\n",
      "5e-05 0.8561693167066912\n",
      "5e-05 0.8560709582699559\n",
      "5e-05 0.8559725718675608\n",
      "5e-05 0.8558741575072333\n",
      "5e-05 0.8557757151967024\n",
      "5e-05 0.8556772449437\n",
      "5e-05 0.8555787467559597\n",
      "5e-05 0.8554802206412178\n",
      "5e-05 0.8553816666072123\n",
      "5e-05 0.8552830846616837\n",
      "5e-05 0.8551844748123745\n",
      "5e-05 0.8550858370670293\n",
      "5e-05 0.8549871714333956\n",
      "5e-05 0.8548884779192221\n",
      "5e-05 0.8547897565322601\n",
      "5e-05 0.8546910072802634\n",
      "5e-05 0.8545922301709876\n",
      "5e-05 0.8544934252121907\n",
      "5e-05 0.8543945924116327\n",
      "5e-05 0.854295731777076\n",
      "5e-05 0.854196843316285\n",
      "5e-05 0.8540979270370261\n",
      "5e-05 0.8539989829470687\n",
      "5e-05 0.8539000110541832\n",
      "5e-05 0.8538010113661434\n",
      "5e-05 0.8537019838907243\n",
      "5e-05 0.8536029286357036\n",
      "5e-05 0.8535038456088611\n",
      "5e-05 0.8534047348179786\n",
      "5e-05 0.8533055962708405\n",
      "5e-05 0.8532064299752327\n",
      "5e-05 0.853107235938944\n",
      "5e-05 0.8530080141697649\n",
      "5e-05 0.8529087646754883\n",
      "5e-05 0.8528094874639092\n",
      "5e-05 0.8527101825428247\n",
      "5e-05 0.8526108499200343\n",
      "5e-05 0.8525114896033394\n",
      "5e-05 0.8524121016005439\n",
      "5e-05 0.8523126859194536\n",
      "5e-05 0.8522132425678766\n",
      "5e-05 0.8521137715536231\n",
      "5e-05 0.8520142728845055\n",
      "5e-05 0.8519147465683383\n",
      "5e-05 0.8518151926129384\n",
      "5e-05 0.8517156110261246\n",
      "5e-05 0.8516160018157182\n",
      "5e-05 0.8515163649895422\n",
      "5e-05 0.8514167005554223\n",
      "5e-05 0.8513170085211859\n",
      "5e-05 0.8512172888946627\n",
      "5e-05 0.8511175416836849\n",
      "5e-05 0.8510177668960865\n",
      "5e-05 0.8509179645397037\n",
      "5e-05 0.8508181346223749\n",
      "5e-05 0.8507182771519409\n",
      "Epoch: 29 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 1.429 | Train Acc @1:  62.86% | Train Acc @5:  89.29%\n",
      "\tValid Loss: 2.845 | Valid Acc @1:  33.96% | Valid Acc @5:  63.30%\n",
      "5e-05 0.8506183921362442\n",
      "5e-05 0.8505184795831301\n",
      "5e-05 0.8504185395004453\n",
      "5e-05 0.8503185718960393\n",
      "5e-05 0.8502185767777632\n",
      "5e-05 0.850118554153471\n",
      "5e-05 0.8500185040310182\n",
      "5e-05 0.8499184264182627\n",
      "5e-05 0.8498183213230645\n",
      "5e-05 0.8497181887532859\n",
      "5e-05 0.8496180287167913\n",
      "5e-05 0.8495178412214471\n",
      "5e-05 0.8494176262751221\n",
      "5e-05 0.8493173838856871\n",
      "5e-05 0.8492171140610152\n",
      "5e-05 0.8491168168089813\n",
      "5e-05 0.8490164921374629\n",
      "5e-05 0.8489161400543394\n",
      "5e-05 0.8488157605674924\n",
      "5e-05 0.8487153536848057\n",
      "5e-05 0.8486149194141651\n",
      "5e-05 0.8485144577634587\n",
      "5e-05 0.848413968740577\n",
      "5e-05 0.8483134523534119\n",
      "5e-05 0.8482129086098583\n",
      "5e-05 0.8481123375178127\n",
      "5e-05 0.8480117390851738\n",
      "5e-05 0.8479111133198428\n",
      "5e-05 0.8478104602297226\n",
      "5e-05 0.8477097798227186\n",
      "5e-05 0.847609072106738\n",
      "5e-05 0.8475083370896905\n",
      "5e-05 0.8474075747794878\n",
      "5e-05 0.8473067851840437\n",
      "5e-05 0.8472059683112741\n",
      "5e-05 0.8471051241690972\n",
      "5e-05 0.8470042527654331\n",
      "5e-05 0.8469033541082045\n",
      "5e-05 0.8468024282053357\n",
      "5e-05 0.8467014750647534\n",
      "5e-05 0.8466004946943864\n",
      "5e-05 0.8464994871021657\n",
      "5e-05 0.8463984522960244\n",
      "5e-05 0.8462973902838979\n",
      "5e-05 0.8461963010737231\n",
      "5e-05 0.84609518467344\n",
      "5e-05 0.84599404109099\n",
      "5e-05 0.8458928703343169\n",
      "5e-05 0.8457916724113665\n",
      "5e-05 0.8456904473300871\n",
      "5e-05 0.8455891950984287\n",
      "5e-05 0.8454879157243436\n",
      "5e-05 0.8453866092157862\n",
      "5e-05 0.8452852755807132\n",
      "5e-05 0.8451839148270833\n",
      "5e-05 0.8450825269628573\n",
      "5e-05 0.8449811119959981\n",
      "5e-05 0.8448796699344708\n",
      "5e-05 0.8447782007862427\n",
      "5e-05 0.8446767045592829\n",
      "5e-05 0.8445751812615632\n",
      "5e-05 0.844473630901057\n",
      "5e-05 0.8443720534857402\n",
      "5e-05 0.8442704490235904\n",
      "5e-05 0.8441688175225877\n",
      "5e-05 0.844067158990714\n",
      "5e-05 0.8439654734359539\n",
      "5e-05 0.8438637608662934\n",
      "5e-05 0.8437620212897212\n",
      "5e-05 0.8436602547142278\n",
      "5e-05 0.843558461147806\n",
      "5e-05 0.8434566405984503\n",
      "5e-05 0.8433547930741578\n",
      "5e-05 0.8432529185829278\n",
      "5e-05 0.8431510171327612\n",
      "5e-05 0.8430490887316613\n",
      "5e-05 0.8429471333876337\n",
      "5e-05 0.8428451511086859\n",
      "5e-05 0.8427431419028273\n",
      "5e-05 0.84264110577807\n",
      "5e-05 0.8425390427424275\n",
      "5e-05 0.8424369528039162\n",
      "5e-05 0.8423348359705538\n",
      "5e-05 0.8422326922503608\n",
      "5e-05 0.8421305216513595\n",
      "5e-05 0.8420283241815741\n",
      "5e-05 0.8419260998490314\n",
      "5e-05 0.84182384866176\n",
      "5e-05 0.8417215706277905\n",
      "5e-05 0.841619265755156\n",
      "5e-05 0.8415169340518913\n",
      "5e-05 0.8414145755260336\n",
      "5e-05 0.8413121901856221\n",
      "5e-05 0.841209778038698\n",
      "5e-05 0.8411073390933048\n",
      "5e-05 0.841004873357488\n",
      "5e-05 0.8409023808392952\n",
      "5e-05 0.840799861546776\n",
      "5e-05 0.8406973154879824\n",
      "5e-05 0.8405947426709683\n",
      "5e-05 0.8404921431037896\n",
      "5e-05 0.8403895167945046\n",
      "5e-05 0.8402868637511733\n",
      "5e-05 0.8401841839818583\n",
      "5e-05 0.8400814774946239\n",
      "5e-05 0.8399787442975364\n",
      "5e-05 0.8398759843986647\n",
      "5e-05 0.8397731978060796\n",
      "5e-05 0.8396703845278537\n",
      "5e-05 0.8395675445720618\n",
      "5e-05 0.8394646779467814\n",
      "5e-05 0.8393617846600909\n",
      "5e-05 0.8392588647200722\n",
      "5e-05 0.839155918134808\n",
      "5e-05 0.839052944912384\n",
      "5e-05 0.8389499450608877\n",
      "5e-05 0.8388469185884087\n",
      "5e-05 0.8387438655030384\n",
      "Epoch: 30 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 1.360 | Train Acc @1:  65.19% | Train Acc @5:  90.39%\n",
      "\tValid Loss: 2.828 | Valid Acc @1:  34.39% | Valid Acc @5:  64.39%\n",
      "5e-05 0.8386407858128706\n",
      "5e-05 0.8385376795260012\n",
      "5e-05 0.8384345466505282\n",
      "5e-05 0.8383313871945515\n",
      "5e-05 0.8382282011661734\n",
      "5e-05 0.8381249885734978\n",
      "5e-05 0.8380217494246311\n",
      "5e-05 0.8379184837276816\n",
      "5e-05 0.83781519149076\n",
      "5e-05 0.8377118727219786\n",
      "5e-05 0.8376085274294518\n",
      "5e-05 0.8375051556212967\n",
      "5e-05 0.837401757305632\n",
      "5e-05 0.8372983324905784\n",
      "5e-05 0.8371948811842589\n",
      "5e-05 0.8370914033947986\n",
      "5e-05 0.8369878991303246\n",
      "5e-05 0.8368843683989658\n",
      "5e-05 0.8367808112088537\n",
      "5e-05 0.8366772275681218\n",
      "5e-05 0.8365736174849052\n",
      "5e-05 0.8364699809673416\n",
      "5e-05 0.8363663180235705\n",
      "5e-05 0.8362626286617334\n",
      "5e-05 0.8361589128899743\n",
      "5e-05 0.8360551707164388\n",
      "5e-05 0.8359514021492748\n",
      "5e-05 0.8358476071966322\n",
      "5e-05 0.8357437858666631\n",
      "5e-05 0.8356399381675215\n",
      "5e-05 0.8355360641073637\n",
      "5e-05 0.8354321636943477\n",
      "5e-05 0.8353282369366339\n",
      "5e-05 0.8352242838423847\n",
      "5e-05 0.8351203044197646\n",
      "5e-05 0.8350162986769398\n",
      "5e-05 0.8349122666220793\n",
      "5e-05 0.8348082082633534\n",
      "5e-05 0.834704123608935\n",
      "5e-05 0.8346000126669986\n",
      "5e-05 0.8344958754457213\n",
      "5e-05 0.8343917119532818\n",
      "5e-05 0.8342875221978612\n",
      "5e-05 0.8341833061876425\n",
      "5e-05 0.8340790639308108\n",
      "5e-05 0.833974795435553\n",
      "5e-05 0.8338705007100586\n",
      "5e-05 0.8337661797625189\n",
      "5e-05 0.8336618326011267\n",
      "5e-05 0.833557459234078\n",
      "5e-05 0.83345305966957\n",
      "5e-05 0.833348633915802\n",
      "5e-05 0.8332441819809759\n",
      "5e-05 0.8331397038732953\n",
      "5e-05 0.8330351996009655\n",
      "5e-05 0.8329306691721945\n",
      "5e-05 0.8328261125951919\n",
      "5e-05 0.8327215298781698\n",
      "5e-05 0.8326169210293419\n",
      "5e-05 0.8325122860569241\n",
      "5e-05 0.8324076249691346\n",
      "5e-05 0.8323029377741931\n",
      "5e-05 0.8321982244803219\n",
      "5e-05 0.8320934850957451\n",
      "5e-05 0.8319887196286889\n",
      "5e-05 0.8318839280873815\n",
      "5e-05 0.8317791104800534\n",
      "5e-05 0.8316742668149366\n",
      "5e-05 0.8315693971002656\n",
      "5e-05 0.8314645013442769\n",
      "5e-05 0.8313595795552089\n",
      "5e-05 0.8312546317413019\n",
      "5e-05 0.8311496579107989\n",
      "5e-05 0.8310446580719442\n",
      "5e-05 0.8309396322329845\n",
      "5e-05 0.8308345804021686\n",
      "5e-05 0.830729502587747\n",
      "5e-05 0.8306243987979727\n",
      "5e-05 0.8305192690411004\n",
      "5e-05 0.8304141133253868\n",
      "5e-05 0.830308931659091\n",
      "5e-05 0.8302037240504739\n",
      "5e-05 0.8300984905077984\n",
      "5e-05 0.8299932310393295\n",
      "5e-05 0.8298879456533342\n",
      "5e-05 0.8297826343580816\n",
      "5e-05 0.8296772971618429\n",
      "5e-05 0.8295719340728911\n",
      "5e-05 0.8294665450995014\n",
      "5e-05 0.8293611302499511\n",
      "5e-05 0.8292556895325194\n",
      "5e-05 0.8291502229554875\n",
      "5e-05 0.8290447305271386\n",
      "5e-05 0.8289392122557583\n",
      "5e-05 0.8288336681496337\n",
      "5e-05 0.8287280982170544\n",
      "5e-05 0.8286225024663116\n",
      "5e-05 0.8285168809056991\n",
      "5e-05 0.8284112335435121\n",
      "5e-05 0.828305560388048\n",
      "5e-05 0.8281998614476066\n",
      "5e-05 0.8280941367304893\n",
      "5e-05 0.8279883862449996\n",
      "5e-05 0.8278826099994432\n",
      "5e-05 0.8277768080021277\n",
      "5e-05 0.8276709802613629\n",
      "5e-05 0.8275651267854602\n",
      "5e-05 0.8274592475827335\n",
      "5e-05 0.8273533426614983\n",
      "5e-05 0.8272474120300726\n",
      "5e-05 0.8271414556967758\n",
      "5e-05 0.8270354736699299\n",
      "5e-05 0.8269294659578585\n",
      "5e-05 0.8268234325688878\n",
      "5e-05 0.8267173735113452\n",
      "5e-05 0.8266112887935607\n",
      "5e-05 0.8265051784238662\n",
      "5e-05 0.8263990424105954\n",
      "Epoch: 31 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 1.263 | Train Acc @1:  66.82% | Train Acc @5:  92.07%\n",
      "\tValid Loss: 2.812 | Valid Acc @1:  34.18% | Valid Acc @5:  63.83%\n",
      "5e-05 0.8262928807620843\n",
      "5e-05 0.8261866934866708\n",
      "5e-05 0.8260804805926947\n",
      "5e-05 0.825974242088498\n",
      "5e-05 0.8258679779824246\n",
      "5e-05 0.8257616882828205\n",
      "5e-05 0.8256553729980336\n",
      "5e-05 0.8255490321364136\n",
      "5e-05 0.825442665706313\n",
      "5e-05 0.8253362737160853\n",
      "5e-05 0.8252298561740867\n",
      "5e-05 0.8251234130886753\n",
      "5e-05 0.8250169444682108\n",
      "5e-05 0.8249104503210554\n",
      "5e-05 0.824803930655573\n",
      "5e-05 0.8246973854801298\n",
      "5e-05 0.8245908148030936\n",
      "5e-05 0.8244842186328344\n",
      "5e-05 0.8243775969777244\n",
      "5e-05 0.8242709498461375\n",
      "5e-05 0.8241642772464497\n",
      "5e-05 0.8240575791870391\n",
      "5e-05 0.8239508556762857\n",
      "5e-05 0.8238441067225715\n",
      "5e-05 0.8237373323342805\n",
      "5e-05 0.8236305325197988\n",
      "5e-05 0.8235237072875142\n",
      "5e-05 0.8234168566458169\n",
      "5e-05 0.823309980603099\n",
      "5e-05 0.8232030791677543\n",
      "5e-05 0.8230961523481786\n",
      "5e-05 0.8229892001527704\n",
      "5e-05 0.8228822225899294\n",
      "5e-05 0.8227752196680576\n",
      "5e-05 0.8226681913955587\n",
      "5e-05 0.8225611377808392\n",
      "5e-05 0.8224540588323066\n",
      "5e-05 0.822346954558371\n",
      "5e-05 0.8222398249674443\n",
      "5e-05 0.8221326700679403\n",
      "5e-05 0.8220254898682753\n",
      "5e-05 0.8219182843768668\n",
      "5e-05 0.8218110536021347\n",
      "5e-05 0.821703797552501\n",
      "5e-05 0.8215965162363894\n",
      "5e-05 0.8214892096622257\n",
      "5e-05 0.8213818778384381\n",
      "5e-05 0.821274520773456\n",
      "5e-05 0.8211671384757113\n",
      "5e-05 0.8210597309536377\n",
      "5e-05 0.8209522982156711\n",
      "5e-05 0.8208448402702491\n",
      "5e-05 0.8207373571258113\n",
      "5e-05 0.8206298487907995\n",
      "5e-05 0.8205223152736574\n",
      "5e-05 0.8204147565828306\n",
      "5e-05 0.8203071727267668\n",
      "5e-05 0.8201995637139153\n",
      "5e-05 0.820091929552728\n",
      "5e-05 0.8199842702516583\n",
      "5e-05 0.8198765858191617\n",
      "5e-05 0.8197688762636957\n",
      "5e-05 0.8196611415937196\n",
      "5e-05 0.8195533818176952\n",
      "5e-05 0.8194455969440857\n",
      "5e-05 0.8193377869813564\n",
      "5e-05 0.8192299519379748\n",
      "5e-05 0.81912209182241\n",
      "5e-05 0.8190142066431336\n",
      "5e-05 0.8189062964086187\n",
      "5e-05 0.8187983611273404\n",
      "5e-05 0.8186904008077761\n",
      "5e-05 0.8185824154584048\n",
      "5e-05 0.8184744050877077\n",
      "5e-05 0.8183663697041679\n",
      "5e-05 0.8182583093162705\n",
      "5e-05 0.8181502239325023\n",
      "5e-05 0.8180421135613525\n",
      "5e-05 0.817933978211312\n",
      "5e-05 0.8178258178908735\n",
      "5e-05 0.8177176326085323\n",
      "5e-05 0.8176094223727848\n",
      "5e-05 0.8175011871921299\n",
      "5e-05 0.8173929270750684\n",
      "5e-05 0.8172846420301031\n",
      "5e-05 0.8171763320657385\n",
      "5e-05 0.8170679971904813\n",
      "5e-05 0.8169596374128401\n",
      "5e-05 0.8168512527413252\n",
      "5e-05 0.8167428431844493\n",
      "5e-05 0.8166344087507269\n",
      "5e-05 0.8165259494486742\n",
      "5e-05 0.8164174652868097\n",
      "5e-05 0.8163089562736536\n",
      "5e-05 0.8162004224177282\n",
      "5e-05 0.8160918637275578\n",
      "5e-05 0.8159832802116683\n",
      "5e-05 0.8158746718785881\n",
      "5e-05 0.815766038736847\n",
      "5e-05 0.815657380794977\n",
      "5e-05 0.8155486980615123\n",
      "5e-05 0.8154399905449887\n",
      "5e-05 0.8153312582539438\n",
      "5e-05 0.8152225011969177\n",
      "5e-05 0.815113719382452\n",
      "5e-05 0.8150049128190904\n",
      "5e-05 0.8148960815153784\n",
      "5e-05 0.8147872254798638\n",
      "5e-05 0.8146783447210959\n",
      "5e-05 0.8145694392476263\n",
      "5e-05 0.8144605090680082\n",
      "5e-05 0.8143515541907971\n",
      "5e-05 0.8142425746245503\n",
      "5e-05 0.8141335703778267\n",
      "5e-05 0.8140245414591878\n",
      "5e-05 0.8139154878771965\n",
      "5e-05 0.8138064096404178\n",
      "5e-05 0.8136973067574189\n",
      "Epoch: 32 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 1.185 | Train Acc @1:  69.10% | Train Acc @5:  92.84%\n",
      "\tValid Loss: 2.841 | Valid Acc @1:  35.31% | Valid Acc @5:  63.56%\n",
      "5e-05 0.8135881792367685\n",
      "5e-05 0.8134790270870373\n",
      "5e-05 0.8133698503167984\n",
      "5e-05 0.8132606489346264\n",
      "5e-05 0.8131514229490975\n",
      "5e-05 0.8130421723687908\n",
      "5e-05 0.8129328972022866\n",
      "5e-05 0.8128235974581672\n",
      "5e-05 0.8127142731450172\n",
      "5e-05 0.8126049242714227\n",
      "5e-05 0.812495550845972\n",
      "5e-05 0.8123861528772551\n",
      "5e-05 0.8122767303738643\n",
      "5e-05 0.8121672833443936\n",
      "5e-05 0.8120578117974386\n",
      "5e-05 0.8119483157415974\n",
      "5e-05 0.8118387951854698\n",
      "5e-05 0.8117292501376574\n",
      "5e-05 0.8116196806067637\n",
      "5e-05 0.8115100866013945\n",
      "5e-05 0.8114004681301571\n",
      "5e-05 0.811290825201661\n",
      "5e-05 0.8111811578245174\n",
      "5e-05 0.8110714660073397\n",
      "5e-05 0.8109617497587428\n",
      "5e-05 0.8108520090873439\n",
      "5e-05 0.810742244001762\n",
      "5e-05 0.8106324545106178\n",
      "5e-05 0.8105226406225345\n",
      "5e-05 0.8104128023461368\n",
      "5e-05 0.810302939690051\n",
      "5e-05 0.8101930526629058\n",
      "5e-05 0.8100831412733317\n",
      "5e-05 0.8099732055299613\n",
      "5e-05 0.8098632454414285\n",
      "5e-05 0.8097532610163699\n",
      "5e-05 0.8096432522634234\n",
      "5e-05 0.8095332191912292\n",
      "5e-05 0.8094231618084291\n",
      "5e-05 0.8093130801236672\n",
      "5e-05 0.8092029741455888\n",
      "5e-05 0.8090928438828422\n",
      "5e-05 0.8089826893440764\n",
      "5e-05 0.8088725105379432\n",
      "5e-05 0.808762307473096\n",
      "5e-05 0.80865208015819\n",
      "5e-05 0.8085418286018824\n",
      "5e-05 0.8084315528128325\n",
      "5e-05 0.808321252799701\n",
      "5e-05 0.8082109285711512\n",
      "5e-05 0.8081005801358474\n",
      "5e-05 0.8079902075024568\n",
      "5e-05 0.8078798106796479\n",
      "5e-05 0.8077693896760911\n",
      "5e-05 0.8076589445004589\n",
      "5e-05 0.8075484751614255\n",
      "5e-05 0.8074379816676673\n",
      "5e-05 0.8073274640278623\n",
      "5e-05 0.8072169222506906\n",
      "5e-05 0.807106356344834\n",
      "5e-05 0.8069957663189762\n",
      "5e-05 0.8068851521818031\n",
      "5e-05 0.8067745139420023\n",
      "5e-05 0.8066638516082631\n",
      "5e-05 0.806553165189277\n",
      "5e-05 0.8064424546937372\n",
      "5e-05 0.8063317201303388\n",
      "5e-05 0.8062209615077791\n",
      "5e-05 0.8061101788347567\n",
      "5e-05 0.8059993721199727\n",
      "5e-05 0.8058885413721297\n",
      "5e-05 0.8057776865999322\n",
      "5e-05 0.8056668078120868\n",
      "5e-05 0.8055559050173019\n",
      "5e-05 0.8054449782242876\n",
      "5e-05 0.8053340274417564\n",
      "5e-05 0.8052230526784219\n",
      "5e-05 0.8051120539430001\n",
      "5e-05 0.8050010312442091\n",
      "5e-05 0.8048899845907682\n",
      "5e-05 0.8047789139913992\n"
     ]
    }
   ],
   "source": [
    "# Model training.\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_epoch = 0\n",
    "_lr_check_list =[]      # !!!\n",
    "\n",
    "print('[*] Start Training !', end='\\n\\n')\n",
    "for epoch in range(args.epochs):\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc_1, train_acc_5, lr_const = train_cosLRdecay(model, train_iterator, optimizer, criterion, device, args.epochs, args.cosLRdecay_lin_end, epoch, args.lr, scheduler)\n",
    "    _lr_check_list.append(lr_const)     # !!!\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    # writer.add_scalar(\"loss/train\", train_loss, epoch)  # tensorboard\n",
    "    # writer.add_scalar(\"loss/val\", valid_loss, epoch)    # tensorboard\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_epoch = epoch\n",
    "        torch.save(model.state_dict(), f'./saved/{args.model}_bs{args.batch_size}_lr{args.lr}_epochs{args.epochs}_pretrained-{args.pretrained}.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
    "        f'Train Acc @5: {train_acc_5*100:6.2f}%')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
    "        f'Valid Acc @5: {valid_acc_5*100:6.2f}%')\n",
    "\n",
    "print()\n",
    "print(f\"Best valid epoch : {best_valid_epoch}/{args.epochs} epochs\")\n",
    "\n",
    "# writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr_const 잘 작동하는지 확인요망(아래 실행)  \n",
    "다른 batch 등등에 대해서도 작동하는지 봐야겠는걸?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(_lr_check_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine LR Decay 만들기\n",
    "\n",
    "- 깃허브에 올려서 사람들 쓸 수 있게 API 만들어볼 수 없나?  \n",
    "- 어떻게 contribute 그런거 해보지?  \n",
    "\n",
    "---\n",
    "TODO  \n",
    "- pytorch API -> optimizer 상속받아서 만든다면??  \n",
    "- optimizer wrapper로 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDecayWithLinearWarmup(MAX_EPOCH, lin_end, epoch, train_loader, step):\n",
    "    import math\n",
    "    '''\n",
    "    input   :   max_epoch  \n",
    "                lin_end  \n",
    "                epoch(current step's / must starts from 0)  \n",
    "                train_loader (for len(train_loader)...)  \n",
    "                current step_num (might should use enumerate)  \n",
    "    output  :   lr_계수 that will be multiplied with lr for current step before optimizer.step().  \n",
    "    '''\n",
    "    \n",
    "    # 'lin_end' is a end epoch of linear warmup stage.\n",
    "    lin_end_steps = lin_end*len(train_loader) # lin_warmup이 끝나는 지점\n",
    "    iter_per_epoch = len(train_loader)\n",
    "    whole_steps = iter_per_epoch*MAX_EPOCH - lin_end_steps  # 'whole_steps' is whole iteration steps.\n",
    "    whole_steps_cos = whole_steps - lin_end_steps   # pure cosine #steps.\n",
    "    lili.append(whole_steps_cos)\n",
    "    # returning lr_c is 계수 that will be multiplied for current step lr.\n",
    "    if epoch < lin_end:\n",
    "        lr_const = (step + epoch*iter_per_epoch)/lin_end_steps  # 선형 증가 비율계산\n",
    "        return lr_const\n",
    "    else:\n",
    "        T = (MAX_EPOCH-lin_end)*iter_per_epoch\n",
    "        t = (epoch - lin_end)*iter_per_epoch + step\n",
    "        lr_const = 0.5*(1+math.cos(t/T*math.pi))\n",
    "        return lr_const\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f72dd083ac0>]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulation\n",
    "MAX_EPOCH = 120\n",
    "lin_end = 10\n",
    "lr=[]\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    for i in range(len(train_loader)):  # 실제론 enumerate 해야겠네 for step in iteration\n",
    "        lr_c= cosineDecayWithLinearWarmup(MAX_EPOCH, lin_end, epoch, train_loader, i)\n",
    "        lr.append(lr_c)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine LR Decay 실 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 돌리기 코드\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_epoch = 0\n",
    "\n",
    "print('[*] Start Training !', end='\\n\\n')\n",
    "for epoch in range(args.epochs):\n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, device, scheduler)\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_epoch = epoch\n",
    "        torch.save(model.state_dict(), f'./saved/{args.model}_bs{args.batch_size}_lr{args.lr}_epochs{args.epochs}_pretrained-{args.pretrained}.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
    "        f'Train Acc @5: {train_acc_5*100:6.2f}%')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
    "        f'Valid Acc @5: {valid_acc_5*100:6.2f}%')\n",
    "\n",
    "print()\n",
    "print(f\"Best valid epoch : {best_valid_epoch}/{args.epochs} epochs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# low-precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([64])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([128])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([256])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([1024])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048, 1024, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([512])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([200, 2048])\n",
      "torch.float16\n",
      "True\n",
      "===\n",
      "name\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([200])\n",
      "torch.float16\n",
      "True\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "model.half()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print('name')\n",
    "    print(type(param))\n",
    "    print(param.shape)\n",
    "    print(param.dtype)\n",
    "    print(param.requires_grad)\n",
    "    print('===')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
