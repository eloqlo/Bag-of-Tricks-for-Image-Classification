{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_enable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/test_jh/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_archive.ResNet import ResNet, Config\n",
    "from loss_archive.knowledge_distillation_loss import KD_loss\n",
    "\n",
    "import argparse\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    model='resnet50',\n",
    "    batch_size=16,\n",
    "    lr=1.25e-4,\n",
    "    epochs=100,\n",
    "    root_path='/root/datasets/archive/CUB_200_2011/',\n",
    "    scheduler='no',\n",
    "    pretrained='no',\n",
    "    teacher_path='/root/workspace/CNN_work/teacher_model/teacher_model.pt'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions for training / model\n",
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device, scheduler=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for step, (x, y) in enumerate(iterator):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler=='yes':\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "train_transforms = transforms.Compose([\n",
    "                        transforms.Resize(pretrained_size),\n",
    "                        transforms.RandomRotation(5),\n",
    "                        transforms.RandomHorizontalFlip(0.5),\n",
    "                        transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                    ])\n",
    "test_transforms = transforms.Compose([\n",
    "                        transforms.Resize(pretrained_size),\n",
    "                        transforms.CenterCrop(pretrained_size),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                    ])\n",
    "\n",
    "ROOT = args.root_path\n",
    "data_dir = os.path.join(ROOT, 'CUB_200_2011')\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "train_data = datasets.ImageFolder(root = train_dir,\n",
    "                                transform = train_transforms)\n",
    "test_data = datasets.ImageFolder(root = test_dir,\n",
    "                                transform = test_transforms)\n",
    "\n",
    "VALID_RATIO = 0.8\n",
    "n_train_examples = int(len(train_data)*VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data,\n",
    "                                        [n_train_examples, n_valid_examples])\n",
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms\n",
    "\n",
    "BATCH_SIZE = args.batch_size\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                shuffle = True, \n",
    "                                batch_size = BATCH_SIZE)\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                batch_size = BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KD_loss(nn.Module):\n",
    "    def __init__(self, Temperature):\n",
    "        super(KD_loss,self).__init__()\n",
    "        self.T = Temperature\n",
    "    \n",
    "    def forward(self, outputs, labels):\n",
    "        \"\"\"\n",
    "            input : \n",
    "                y : (gt)\n",
    "                y_stu : (student output)\n",
    "                y_tea : (teacher output)\n",
    "            output : \n",
    "                loss (Variable) : 논문's distillation loss\n",
    "        \"\"\"\n",
    "        default_loss = nn.CrossEntropyLoss()(y_stu,y)               # TODO How this could work? --> \"default_loss\"  be an insatnce carrying some needed values.\n",
    "        term1 = F.softmax(torch.mul(y_tea,1/T))         # nn.functional 이 softmax의 computational graph를 지원하나?\n",
    "        term2 = F.softmax(torch.mul(y_stu,1/T))\n",
    "        distill_loss = T**2 * nn.CrossEntropyLoss()(term1, term2)\n",
    "\n",
    "        loss = default_loss + distill_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student_model, Optimizer, Criterion, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<< Configurations >>\n",
      "[*] Model       - resnet50\n",
      "[*] Batch_size  - 16\n",
      "[*] LR          - 0.000125\n",
      "[*] Epochs      - 100\n",
      "[*] train newly initialized model!\n",
      "[*] Parameters  - 23,917,832\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--model\", type=str, default='resnet34')     # resnet18, 34, 50, 101, 152.\n",
    "    # parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    # parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    # parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "    # parser.add_argument(\"--root_path\", type=str, default='/home/jh/Desktop/VSC/CNN_work/archive/CUB_200_2011/')\n",
    "    # parser.add_argument(\"--scheduler\", type=str, default='no')      # yes / no\n",
    "    # parser.add_argument(\"--pretrained\", type=str, default='no')     # yes / no\n",
    "    # parser.add_argument(\"--teacher_path\", type=str, default='/home/jh/Desktop/VSC/CNN_work/teacher_model/teacher_model.pt')\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    print()\n",
    "    print('<< Configurations >>')\n",
    "    print(f'[*] Model       - {args.model}')\n",
    "    print(f'[*] Batch_size  - {args.batch_size}')\n",
    "    print(f'[*] LR          - {args.lr}')\n",
    "    print(f'[*] Epochs      - {args.epochs}')\n",
    "\n",
    "    # * Dasetset (Above)\n",
    "\n",
    "    # get pretrained model.\n",
    "    if args.model=='resnet18':\n",
    "        if args.pretrained=='yes':\n",
    "            model = models.resnet18(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "    elif args.model=='resnet34':\n",
    "        if args.pretrained=='yes':\n",
    "            model = models.resnet34(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "    elif args.model=='resnet50':\n",
    "        if args.pretrained=='yes':\n",
    "            model = models.resnet50(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "    elif args.model=='resnet101':\n",
    "        if args.pretrained=='yes':\n",
    "            model = models.resnet101(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "    elif args.model=='resnet152':\n",
    "        if args.pretrained=='yes':\n",
    "            model = models.resnet152(pretrained = True)\n",
    "            print('[*] pre-trained model being used!')\n",
    "\n",
    "    if args.pretrained!='yes':\n",
    "        # make new model.\n",
    "        print('[*] train newly initialized model!')\n",
    "        config = Config()\n",
    "        resnet_config = config.get_resnet_config(model_name = args.model)\n",
    "        OUTPUT_DIM = len(test_data.classes)\n",
    "        model = ResNet(resnet_config, OUTPUT_DIM)  # get resnetXXX\n",
    "\n",
    "        print(f'[*] Parameters  - {count_parameters(model):,}')\n",
    "    else:\n",
    "        # Change FC layer in downloaded model for Transfer Learning.\n",
    "        IN_FEATURES = model.fc.in_features \n",
    "        OUTPUT_DIM = len(test_data.classes)\n",
    "        model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "        print(f'[*] Parameters  - {count_parameters(model):,}')\n",
    "    \n",
    "    # if args.half=='yes':\n",
    "    #     model = model.half()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # ! Knowledge Distillation Loss here\n",
    "    criterion = KD_loss(Temperature=20)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if args.scheduler == 'yes':\n",
    "        # cosine scheduler\n",
    "        '''\n",
    "        - 기존 lr overfitting지점인, 30-40 에 다다르기 전에 decay주는게 적합해보여.\n",
    "        - 한번 그렇게 ``lr==0`` 까지 탐색하는것보단, hard_reset하면서 그 optima에서 빠져나와서 \n",
    "          주변 다른 optima 들어가보는것도 좋지 않을까?\n",
    "        - 지금 실험상황은 best 모델 찾는거고, epoch 100 가면서 어차피 튀는 경향성 보이니, 좋은 시도같은데?\n",
    "        '''\n",
    "        ITERATIONS = args.epochs * len(train_iterator)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=ITERATIONS, eta_min=1e-8)\n",
    "    else:\n",
    "        scheduler=None\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    if tensorboard_enable:\n",
    "        writer = SummaryWriter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Test] Knowledge Distillation\n",
    "\n",
    "- teacher model 마련\n",
    "- loss 구현\n",
    "- train code 손보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Teacher Model\n",
    "\n",
    "[TODO] Get Teacher Model\n",
    "\n",
    "- Train \"ResNet152\" for \"CUB200-2011\" Dataset   ->   Get good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tUnexpected key(s) in state_dict: \"layer2.4.conv1.weight\", \"layer2.4.bn1.weight\", \"layer2.4.bn1.bias\", \"layer2.4.bn1.running_mean\", \"layer2.4.bn1.running_var\", \"layer2.4.bn1.num_batches_tracked\", \"layer2.4.conv2.weight\", \"layer2.4.bn2.weight\", \"layer2.4.bn2.bias\", \"layer2.4.bn2.running_mean\", \"layer2.4.bn2.running_var\", \"layer2.4.bn2.num_batches_tracked\", \"layer2.4.conv3.weight\", \"layer2.4.bn3.weight\", \"layer2.4.bn3.bias\", \"layer2.4.bn3.running_mean\", \"layer2.4.bn3.running_var\", \"layer2.4.bn3.num_batches_tracked\", \"layer2.5.conv1.weight\", \"layer2.5.bn1.weight\", \"layer2.5.bn1.bias\", \"layer2.5.bn1.running_mean\", \"layer2.5.bn1.running_var\", \"layer2.5.bn1.num_batches_tracked\", \"layer2.5.conv2.weight\", \"layer2.5.bn2.weight\", \"layer2.5.bn2.bias\", \"layer2.5.bn2.running_mean\", \"layer2.5.bn2.running_var\", \"layer2.5.bn2.num_batches_tracked\", \"layer2.5.conv3.weight\", \"layer2.5.bn3.weight\", \"layer2.5.bn3.bias\", \"layer2.5.bn3.running_mean\", \"layer2.5.bn3.running_var\", \"layer2.5.bn3.num_batches_tracked\", \"layer2.6.conv1.weight\", \"layer2.6.bn1.weight\", \"layer2.6.bn1.bias\", \"layer2.6.bn1.running_mean\", \"layer2.6.bn1.running_var\", \"layer2.6.bn1.num_batches_tracked\", \"layer2.6.conv2.weight\", \"layer2.6.bn2.weight\", \"layer2.6.bn2.bias\", \"layer2.6.bn2.running_mean\", \"layer2.6.bn2.running_var\", \"layer2.6.bn2.num_batches_tracked\", \"layer2.6.conv3.weight\", \"layer2.6.bn3.weight\", \"layer2.6.bn3.bias\", \"layer2.6.bn3.running_mean\", \"layer2.6.bn3.running_var\", \"layer2.6.bn3.num_batches_tracked\", \"layer2.7.conv1.weight\", \"layer2.7.bn1.weight\", \"layer2.7.bn1.bias\", \"layer2.7.bn1.running_mean\", \"layer2.7.bn1.running_var\", \"layer2.7.bn1.num_batches_tracked\", \"layer2.7.conv2.weight\", \"layer2.7.bn2.weight\", \"layer2.7.bn2.bias\", \"layer2.7.bn2.running_mean\", \"layer2.7.bn2.running_var\", \"layer2.7.bn2.num_batches_tracked\", \"layer2.7.conv3.weight\", \"layer2.7.bn3.weight\", \"layer2.7.bn3.bias\", \"layer2.7.bn3.running_mean\", \"layer2.7.bn3.running_var\", \"layer2.7.bn3.num_batches_tracked\", \"layer3.6.conv1.weight\", \"layer3.6.bn1.weight\", \"layer3.6.bn1.bias\", \"layer3.6.bn1.running_mean\", \"layer3.6.bn1.running_var\", \"layer3.6.bn1.num_batches_tracked\", \"layer3.6.conv2.weight\", \"layer3.6.bn2.weight\", \"layer3.6.bn2.bias\", \"layer3.6.bn2.running_mean\", \"layer3.6.bn2.running_var\", \"layer3.6.bn2.num_batches_tracked\", \"layer3.6.conv3.weight\", \"layer3.6.bn3.weight\", \"layer3.6.bn3.bias\", \"layer3.6.bn3.running_mean\", \"layer3.6.bn3.running_var\", \"layer3.6.bn3.num_batches_tracked\", \"layer3.7.conv1.weight\", \"layer3.7.bn1.weight\", \"layer3.7.bn1.bias\", \"layer3.7.bn1.running_mean\", \"layer3.7.bn1.running_var\", \"layer3.7.bn1.num_batches_tracked\", \"layer3.7.conv2.weight\", \"layer3.7.bn2.weight\", \"layer3.7.bn2.bias\", \"layer3.7.bn2.running_mean\", \"layer3.7.bn2.running_var\", \"layer3.7.bn2.num_batches_tracked\", \"layer3.7.conv3.weight\", \"layer3.7.bn3.weight\", \"layer3.7.bn3.bias\", \"layer3.7.bn3.running_mean\", \"layer3.7.bn3.running_var\", \"layer3.7.bn3.num_batches_tracked\", \"layer3.8.conv1.weight\", \"layer3.8.bn1.weight\", \"layer3.8.bn1.bias\", \"layer3.8.bn1.running_mean\", \"layer3.8.bn1.running_var\", \"layer3.8.bn1.num_batches_tracked\", \"layer3.8.conv2.weight\", \"layer3.8.bn2.weight\", \"layer3.8.bn2.bias\", \"layer3.8.bn2.running_mean\", \"layer3.8.bn2.running_var\", \"layer3.8.bn2.num_batches_tracked\", \"layer3.8.conv3.weight\", \"layer3.8.bn3.weight\", \"layer3.8.bn3.bias\", \"layer3.8.bn3.running_mean\", \"layer3.8.bn3.running_var\", \"layer3.8.bn3.num_batches_tracked\", \"layer3.9.conv1.weight\", \"layer3.9.bn1.weight\", \"layer3.9.bn1.bias\", \"layer3.9.bn1.running_mean\", \"layer3.9.bn1.running_var\", \"layer3.9.bn1.num_batches_tracked\", \"layer3.9.conv2.weight\", \"layer3.9.bn2.weight\", \"layer3.9.bn2.bias\", \"layer3.9.bn2.running_mean\", \"layer3.9.bn2.running_var\", \"layer3.9.bn2.num_batches_tracked\", \"layer3.9.conv3.weight\", \"layer3.9.bn3.weight\", \"layer3.9.bn3.bias\", \"layer3.9.bn3.running_mean\", \"layer3.9.bn3.running_var\", \"layer3.9.bn3.num_batches_tracked\", \"layer3.10.conv1.weight\", \"layer3.10.bn1.weight\", \"layer3.10.bn1.bias\", \"layer3.10.bn1.running_mean\", \"layer3.10.bn1.running_var\", \"layer3.10.bn1.num_batches_tracked\", \"layer3.10.conv2.weight\", \"layer3.10.bn2.weight\", \"layer3.10.bn2.bias\", \"layer3.10.bn2.running_mean\", \"layer3.10.bn2.running_var\", \"layer3.10.bn2.num_batches_tracked\", \"layer3.10.conv3.weight\", \"layer3.10.bn3.weight\", \"layer3.10.bn3.bias\", \"layer3.10.bn3.running_mean\", \"layer3.10.bn3.running_var\", \"layer3.10.bn3.num_batches_tracked\", \"layer3.11.conv1.weight\", \"layer3.11.bn1.weight\", \"layer3.11.bn1.bias\", \"layer3.11.bn1.running_mean\", \"layer3.11.bn1.running_var\", \"layer3.11.bn1.num_batches_tracked\", \"layer3.11.conv2.weight\", \"layer3.11.bn2.weight\", \"layer3.11.bn2.bias\", \"layer3.11.bn2.running_mean\", \"layer3.11.bn2.running_var\", \"layer3.11.bn2.num_batches_tracked\", \"layer3.11.conv3.weight\", \"layer3.11.bn3.weight\", \"layer3.11.bn3.bias\", \"layer3.11.bn3.running_mean\", \"layer3.11.bn3.running_var\", \"layer3.11.bn3.num_batches_tracked\", \"layer3.12.conv1.weight\", \"layer3.12.bn1.weight\", \"layer3.12.bn1.bias\", \"layer3.12.bn1.running_mean\", \"layer3.12.bn1.running_var\", \"layer3.12.bn1.num_batches_tracked\", \"layer3.12.conv2.weight\", \"layer3.12.bn2.weight\", \"layer3.12.bn2.bias\", \"layer3.12.bn2.running_mean\", \"layer3.12.bn2.running_var\", \"layer3.12.bn2.num_batches_tracked\", \"layer3.12.conv3.weight\", \"layer3.12.bn3.weight\", \"layer3.12.bn3.bias\", \"layer3.12.bn3.running_mean\", \"layer3.12.bn3.running_var\", \"layer3.12.bn3.num_batches_tracked\", \"layer3.13.conv1.weight\", \"layer3.13.bn1.weight\", \"layer3.13.bn1.bias\", \"layer3.13.bn1.running_mean\", \"layer3.13.bn1.running_var\", \"layer3.13.bn1.num_batches_tracked\", \"layer3.13.conv2.weight\", \"layer3.13.bn2.weight\", \"layer3.13.bn2.bias\", \"layer3.13.bn2.running_mean\", \"layer3.13.bn2.running_var\", \"layer3.13.bn2.num_batches_tracked\", \"layer3.13.conv3.weight\", \"layer3.13.bn3.weight\", \"layer3.13.bn3.bias\", \"layer3.13.bn3.running_mean\", \"layer3.13.bn3.running_var\", \"layer3.13.bn3.num_batches_tracked\", \"layer3.14.conv1.weight\", \"layer3.14.bn1.weight\", \"layer3.14.bn1.bias\", \"layer3.14.bn1.running_mean\", \"layer3.14.bn1.running_var\", \"layer3.14.bn1.num_batches_tracked\", \"layer3.14.conv2.weight\", \"layer3.14.bn2.weight\", \"layer3.14.bn2.bias\", \"layer3.14.bn2.running_mean\", \"layer3.14.bn2.running_var\", \"layer3.14.bn2.num_batches_tracked\", \"layer3.14.conv3.weight\", \"layer3.14.bn3.weight\", \"layer3.14.bn3.bias\", \"layer3.14.bn3.running_mean\", \"layer3.14.bn3.running_var\", \"layer3.14.bn3.num_batches_tracked\", \"layer3.15.conv1.weight\", \"layer3.15.bn1.weight\", \"layer3.15.bn1.bias\", \"layer3.15.bn1.running_mean\", \"layer3.15.bn1.running_var\", \"layer3.15.bn1.num_batches_tracked\", \"layer3.15.conv2.weight\", \"layer3.15.bn2.weight\", \"layer3.15.bn2.bias\", \"layer3.15.bn2.running_mean\", \"layer3.15.bn2.running_var\", \"layer3.15.bn2.num_batches_tracked\", \"layer3.15.conv3.weight\", \"layer3.15.bn3.weight\", \"layer3.15.bn3.bias\", \"layer3.15.bn3.running_mean\", \"layer3.15.bn3.running_var\", \"layer3.15.bn3.num_batches_tracked\", \"layer3.16.conv1.weight\", \"layer3.16.bn1.weight\", \"layer3.16.bn1.bias\", \"layer3.16.bn1.running_mean\", \"layer3.16.bn1.running_var\", \"layer3.16.bn1.num_batches_tracked\", \"layer3.16.conv2.weight\", \"layer3.16.bn2.weight\", \"layer3.16.bn2.bias\", \"layer3.16.bn2.running_mean\", \"layer3.16.bn2.running_var\", \"layer3.16.bn2.num_batches_tracked\", \"layer3.16.conv3.weight\", \"layer3.16.bn3.weight\", \"layer3.16.bn3.bias\", \"layer3.16.bn3.running_mean\", \"layer3.16.bn3.running_var\", \"layer3.16.bn3.num_batches_tracked\", \"layer3.17.conv1.weight\", \"layer3.17.bn1.weight\", \"layer3.17.bn1.bias\", \"layer3.17.bn1.running_mean\", \"layer3.17.bn1.running_var\", \"layer3.17.bn1.num_batches_tracked\", \"layer3.17.conv2.weight\", \"layer3.17.bn2.weight\", \"layer3.17.bn2.bias\", \"layer3.17.bn2.running_mean\", \"layer3.17.bn2.running_var\", \"layer3.17.bn2.num_batches_tracked\", \"layer3.17.conv3.weight\", \"layer3.17.bn3.weight\", \"layer3.17.bn3.bias\", \"layer3.17.bn3.running_mean\", \"layer3.17.bn3.running_var\", \"layer3.17.bn3.num_batches_tracked\", \"layer3.18.conv1.weight\", \"layer3.18.bn1.weight\", \"layer3.18.bn1.bias\", \"layer3.18.bn1.running_mean\", \"layer3.18.bn1.running_var\", \"layer3.18.bn1.num_batches_tracked\", \"layer3.18.conv2.weight\", \"layer3.18.bn2.weight\", \"layer3.18.bn2.bias\", \"layer3.18.bn2.running_mean\", \"layer3.18.bn2.running_var\", \"layer3.18.bn2.num_batches_tracked\", \"layer3.18.conv3.weight\", \"layer3.18.bn3.weight\", \"layer3.18.bn3.bias\", \"layer3.18.bn3.running_mean\", \"layer3.18.bn3.running_var\", \"layer3.18.bn3.num_batches_tracked\", \"layer3.19.conv1.weight\", \"layer3.19.bn1.weight\", \"layer3.19.bn1.bias\", \"layer3.19.bn1.running_mean\", \"layer3.19.bn1.running_var\", \"layer3.19.bn1.num_batches_tracked\", \"layer3.19.conv2.weight\", \"layer3.19.bn2.weight\", \"layer3.19.bn2.bias\", \"layer3.19.bn2.running_mean\", \"layer3.19.bn2.running_var\", \"layer3.19.bn2.num_batches_tracked\", \"layer3.19.conv3.weight\", \"layer3.19.bn3.weight\", \"layer3.19.bn3.bias\", \"layer3.19.bn3.running_mean\", \"layer3.19.bn3.running_var\", \"layer3.19.bn3.num_batches_tracked\", \"layer3.20.conv1.weight\", \"layer3.20.bn1.weight\", \"layer3.20.bn1.bias\", \"layer3.20.bn1.running_mean\", \"layer3.20.bn1.running_var\", \"layer3.20.bn1.num_batches_tracked\", \"layer3.20.conv2.weight\", \"layer3.20.bn2.weight\", \"layer3.20.bn2.bias\", \"layer3.20.bn2.running_mean\", \"layer3.20.bn2.running_var\", \"layer3.20.bn2.num_batches_tracked\", \"layer3.20.conv3.weight\", \"layer3.20.bn3.weight\", \"layer3.20.bn3.bias\", \"layer3.20.bn3.running_mean\", \"layer3.20.bn3.running_var\", \"layer3.20.bn3.num_batches_tracked\", \"layer3.21.conv1.weight\", \"layer3.21.bn1.weight\", \"layer3.21.bn1.bias\", \"layer3.21.bn1.running_mean\", \"layer3.21.bn1.running_var\", \"layer3.21.bn1.num_batches_tracked\", \"layer3.21.conv2.weight\", \"layer3.21.bn2.weight\", \"layer3.21.bn2.bias\", \"layer3.21.bn2.running_mean\", \"layer3.21.bn2.running_var\", \"layer3.21.bn2.num_batches_tracked\", \"layer3.21.conv3.weight\", \"layer3.21.bn3.weight\", \"layer3.21.bn3.bias\", \"layer3.21.bn3.running_mean\", \"layer3.21.bn3.running_var\", \"layer3.21.bn3.num_batches_tracked\", \"layer3.22.conv1.weight\", \"layer3.22.bn1.weight\", \"layer3.22.bn1.bias\", \"layer3.22.bn1.running_mean\", \"layer3.22.bn1.running_var\", \"layer3.22.bn1.num_batches_tracked\", \"layer3.22.conv2.weight\", \"layer3.22.bn2.weight\", \"layer3.22.bn2.bias\", \"layer3.22.bn2.running_mean\", \"layer3.22.bn2.running_var\", \"layer3.22.bn2.num_batches_tracked\", \"layer3.22.conv3.weight\", \"layer3.22.bn3.weight\", \"layer3.22.bn3.bias\", \"layer3.22.bn3.running_mean\", \"layer3.22.bn3.running_var\", \"layer3.22.bn3.num_batches_tracked\", \"layer3.23.conv1.weight\", \"layer3.23.bn1.weight\", \"layer3.23.bn1.bias\", \"layer3.23.bn1.running_mean\", \"layer3.23.bn1.running_var\", \"layer3.23.bn1.num_batches_tracked\", \"layer3.23.conv2.weight\", \"layer3.23.bn2.weight\", \"layer3.23.bn2.bias\", \"layer3.23.bn2.running_mean\", \"layer3.23.bn2.running_var\", \"layer3.23.bn2.num_batches_tracked\", \"layer3.23.conv3.weight\", \"layer3.23.bn3.weight\", \"layer3.23.bn3.bias\", \"layer3.23.bn3.running_mean\", \"layer3.23.bn3.running_var\", \"layer3.23.bn3.num_batches_tracked\", \"layer3.24.conv1.weight\", \"layer3.24.bn1.weight\", \"layer3.24.bn1.bias\", \"layer3.24.bn1.running_mean\", \"layer3.24.bn1.running_var\", \"layer3.24.bn1.num_batches_tracked\", \"layer3.24.conv2.weight\", \"layer3.24.bn2.weight\", \"layer3.24.bn2.bias\", \"layer3.24.bn2.running_mean\", \"layer3.24.bn2.running_var\", \"layer3.24.bn2.num_batches_tracked\", \"layer3.24.conv3.weight\", \"layer3.24.bn3.weight\", \"layer3.24.bn3.bias\", \"layer3.24.bn3.running_mean\", \"layer3.24.bn3.running_var\", \"layer3.24.bn3.num_batches_tracked\", \"layer3.25.conv1.weight\", \"layer3.25.bn1.weight\", \"layer3.25.bn1.bias\", \"layer3.25.bn1.running_mean\", \"layer3.25.bn1.running_var\", \"layer3.25.bn1.num_batches_tracked\", \"layer3.25.conv2.weight\", \"layer3.25.bn2.weight\", \"layer3.25.bn2.bias\", \"layer3.25.bn2.running_mean\", \"layer3.25.bn2.running_var\", \"layer3.25.bn2.num_batches_tracked\", \"layer3.25.conv3.weight\", \"layer3.25.bn3.weight\", \"layer3.25.bn3.bias\", \"layer3.25.bn3.running_mean\", \"layer3.25.bn3.running_var\", \"layer3.25.bn3.num_batches_tracked\", \"layer3.26.conv1.weight\", \"layer3.26.bn1.weight\", \"layer3.26.bn1.bias\", \"layer3.26.bn1.running_mean\", \"layer3.26.bn1.running_var\", \"layer3.26.bn1.num_batches_tracked\", \"layer3.26.conv2.weight\", \"layer3.26.bn2.weight\", \"layer3.26.bn2.bias\", \"layer3.26.bn2.running_mean\", \"layer3.26.bn2.running_var\", \"layer3.26.bn2.num_batches_tracked\", \"layer3.26.conv3.weight\", \"layer3.26.bn3.weight\", \"layer3.26.bn3.bias\", \"layer3.26.bn3.running_mean\", \"layer3.26.bn3.running_var\", \"layer3.26.bn3.num_batches_tracked\", \"layer3.27.conv1.weight\", \"layer3.27.bn1.weight\", \"layer3.27.bn1.bias\", \"layer3.27.bn1.running_mean\", \"layer3.27.bn1.running_var\", \"layer3.27.bn1.num_batches_tracked\", \"layer3.27.conv2.weight\", \"layer3.27.bn2.weight\", \"layer3.27.bn2.bias\", \"layer3.27.bn2.running_mean\", \"layer3.27.bn2.running_var\", \"layer3.27.bn2.num_batches_tracked\", \"layer3.27.conv3.weight\", \"layer3.27.bn3.weight\", \"layer3.27.bn3.bias\", \"layer3.27.bn3.running_mean\", \"layer3.27.bn3.running_var\", \"layer3.27.bn3.num_batches_tracked\", \"layer3.28.conv1.weight\", \"layer3.28.bn1.weight\", \"layer3.28.bn1.bias\", \"layer3.28.bn1.running_mean\", \"layer3.28.bn1.running_var\", \"layer3.28.bn1.num_batches_tracked\", \"layer3.28.conv2.weight\", \"layer3.28.bn2.weight\", \"layer3.28.bn2.bias\", \"layer3.28.bn2.running_mean\", \"layer3.28.bn2.running_var\", \"layer3.28.bn2.num_batches_tracked\", \"layer3.28.conv3.weight\", \"layer3.28.bn3.weight\", \"layer3.28.bn3.bias\", \"layer3.28.bn3.running_mean\", \"layer3.28.bn3.running_var\", \"layer3.28.bn3.num_batches_tracked\", \"layer3.29.conv1.weight\", \"layer3.29.bn1.weight\", \"layer3.29.bn1.bias\", \"layer3.29.bn1.running_mean\", \"layer3.29.bn1.running_var\", \"layer3.29.bn1.num_batches_tracked\", \"layer3.29.conv2.weight\", \"layer3.29.bn2.weight\", \"layer3.29.bn2.bias\", \"layer3.29.bn2.running_mean\", \"layer3.29.bn2.running_var\", \"layer3.29.bn2.num_batches_tracked\", \"layer3.29.conv3.weight\", \"layer3.29.bn3.weight\", \"layer3.29.bn3.bias\", \"layer3.29.bn3.running_mean\", \"layer3.29.bn3.running_var\", \"layer3.29.bn3.num_batches_tracked\", \"layer3.30.conv1.weight\", \"layer3.30.bn1.weight\", \"layer3.30.bn1.bias\", \"layer3.30.bn1.running_mean\", \"layer3.30.bn1.running_var\", \"layer3.30.bn1.num_batches_tracked\", \"layer3.30.conv2.weight\", \"layer3.30.bn2.weight\", \"layer3.30.bn2.bias\", \"layer3.30.bn2.running_mean\", \"layer3.30.bn2.running_var\", \"layer3.30.bn2.num_batches_tracked\", \"layer3.30.conv3.weight\", \"layer3.30.bn3.weight\", \"layer3.30.bn3.bias\", \"layer3.30.bn3.running_mean\", \"layer3.30.bn3.running_var\", \"layer3.30.bn3.num_batches_tracked\", \"layer3.31.conv1.weight\", \"layer3.31.bn1.weight\", \"layer3.31.bn1.bias\", \"layer3.31.bn1.running_mean\", \"layer3.31.bn1.running_var\", \"layer3.31.bn1.num_batches_tracked\", \"layer3.31.conv2.weight\", \"layer3.31.bn2.weight\", \"layer3.31.bn2.bias\", \"layer3.31.bn2.running_mean\", \"layer3.31.bn2.running_var\", \"layer3.31.bn2.num_batches_tracked\", \"layer3.31.conv3.weight\", \"layer3.31.bn3.weight\", \"layer3.31.bn3.bias\", \"layer3.31.bn3.running_mean\", \"layer3.31.bn3.running_var\", \"layer3.31.bn3.num_batches_tracked\", \"layer3.32.conv1.weight\", \"layer3.32.bn1.weight\", \"layer3.32.bn1.bias\", \"layer3.32.bn1.running_mean\", \"layer3.32.bn1.running_var\", \"layer3.32.bn1.num_batches_tracked\", \"layer3.32.conv2.weight\", \"layer3.32.bn2.weight\", \"layer3.32.bn2.bias\", \"layer3.32.bn2.running_mean\", \"layer3.32.bn2.running_var\", \"layer3.32.bn2.num_batches_tracked\", \"layer3.32.conv3.weight\", \"layer3.32.bn3.weight\", \"layer3.32.bn3.bias\", \"layer3.32.bn3.running_mean\", \"layer3.32.bn3.running_var\", \"layer3.32.bn3.num_batches_tracked\", \"layer3.33.conv1.weight\", \"layer3.33.bn1.weight\", \"layer3.33.bn1.bias\", \"layer3.33.bn1.running_mean\", \"layer3.33.bn1.running_var\", \"layer3.33.bn1.num_batches_tracked\", \"layer3.33.conv2.weight\", \"layer3.33.bn2.weight\", \"layer3.33.bn2.bias\", \"layer3.33.bn2.running_mean\", \"layer3.33.bn2.running_var\", \"layer3.33.bn2.num_batches_tracked\", \"layer3.33.conv3.weight\", \"layer3.33.bn3.weight\", \"layer3.33.bn3.bias\", \"layer3.33.bn3.running_mean\", \"layer3.33.bn3.running_var\", \"layer3.33.bn3.num_batches_tracked\", \"layer3.34.conv1.weight\", \"layer3.34.bn1.weight\", \"layer3.34.bn1.bias\", \"layer3.34.bn1.running_mean\", \"layer3.34.bn1.running_var\", \"layer3.34.bn1.num_batches_tracked\", \"layer3.34.conv2.weight\", \"layer3.34.bn2.weight\", \"layer3.34.bn2.bias\", \"layer3.34.bn2.running_mean\", \"layer3.34.bn2.running_var\", \"layer3.34.bn2.num_batches_tracked\", \"layer3.34.conv3.weight\", \"layer3.34.bn3.weight\", \"layer3.34.bn3.bias\", \"layer3.34.bn3.running_mean\", \"layer3.34.bn3.running_var\", \"layer3.34.bn3.num_batches_tracked\", \"layer3.35.conv1.weight\", \"layer3.35.bn1.weight\", \"layer3.35.bn1.bias\", \"layer3.35.bn1.running_mean\", \"layer3.35.bn1.running_var\", \"layer3.35.bn1.num_batches_tracked\", \"layer3.35.conv2.weight\", \"layer3.35.bn2.weight\", \"layer3.35.bn2.bias\", \"layer3.35.bn2.running_mean\", \"layer3.35.bn2.running_var\", \"layer3.35.bn2.num_batches_tracked\", \"layer3.35.conv3.weight\", \"layer3.35.bn3.weight\", \"layer3.35.bn3.bias\", \"layer3.35.bn3.running_mean\", \"layer3.35.bn3.running_var\", \"layer3.35.bn3.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m OUTPUT_DIM \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m    \u001b[39m#! delete after 통합 to whole code.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m teacher_model \u001b[39m=\u001b[39m ResNet(resnet_config, OUTPUT_DIM)\n\u001b[0;32m----> 5\u001b[0m teacher_model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(PATH))\n\u001b[1;32m      6\u001b[0m teacher_model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_jh/lib/python3.8/site-packages/torch/nn/modules/module.py:1406\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1402\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1403\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1406\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1407\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1408\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tUnexpected key(s) in state_dict: \"layer2.4.conv1.weight\", \"layer2.4.bn1.weight\", \"layer2.4.bn1.bias\", \"layer2.4.bn1.running_mean\", \"layer2.4.bn1.running_var\", \"layer2.4.bn1.num_batches_tracked\", \"layer2.4.conv2.weight\", \"layer2.4.bn2.weight\", \"layer2.4.bn2.bias\", \"layer2.4.bn2.running_mean\", \"layer2.4.bn2.running_var\", \"layer2.4.bn2.num_batches_tracked\", \"layer2.4.conv3.weight\", \"layer2.4.bn3.weight\", \"layer2.4.bn3.bias\", \"layer2.4.bn3.running_mean\", \"layer2.4.bn3.running_var\", \"layer2.4.bn3.num_batches_tracked\", \"layer2.5.conv1.weight\", \"layer2.5.bn1.weight\", \"layer2.5.bn1.bias\", \"layer2.5.bn1.running_mean\", \"layer2.5.bn1.running_var\", \"layer2.5.bn1.num_batches_tracked\", \"layer2.5.conv2.weight\", \"layer2.5.bn2.weight\", \"layer2.5.bn2.bias\", \"layer2.5.bn2.running_mean\", \"layer2.5.bn2.running_var\", \"layer2.5.bn2.num_batches_tracked\", \"layer2.5.conv3.weight\", \"layer2.5.bn3.weight\", \"layer2.5.bn3.bias\", \"layer2.5.bn3.running_mean\", \"layer2.5.bn3.running_var\", \"layer2.5.bn3.num_batches_tracked\", \"layer2.6.conv1.weight\", \"layer2.6.bn1.weight\", \"layer2.6.bn1.bias\", \"layer2.6.bn1.running_mean\", \"layer2.6.bn1.running_var\", \"layer2.6.bn1.num_batches_tracked\", \"layer2.6.conv2.weight\", \"layer2.6.bn2.weight\", \"layer2.6.bn2.bias\", \"layer2.6.bn2.running_mean\", \"layer2.6.bn2.running_var\", \"layer2.6.bn2.num_batches_tracked\", \"layer2.6.conv3.weight\", \"layer2.6.bn3.weight\", \"layer2.6.bn3.bias\", \"layer2.6.bn3.running_mean\", \"layer2.6.bn3.running_var\", \"layer2.6.bn3.num_batches_tracked\", \"layer2.7.conv1.weight\", \"layer2.7.bn1.weight\", \"layer2.7.bn1.bias\", \"layer2.7.bn1.running_mean\", \"layer2.7.bn1.running_var\", \"layer2.7.bn1.num_batches_tracked\", \"layer2.7.conv2.weight\", \"layer2.7.bn2.weight\", \"layer2.7.bn2.bias\", \"layer2.7.bn2.running_mean\", \"layer2.7.bn2.running_var\", \"layer2.7.bn2.num_batches_tracked\", \"layer2.7.conv3.weight\", \"layer2.7.bn3.weight\", \"layer2.7.bn3.bias\", \"layer2.7.bn3.running_mean\", \"layer2.7.bn3.running_var\", \"layer2.7.bn3.num_batches_tracked\", \"layer3.6.conv1.weight\", \"layer3.6.bn1.weight\", \"layer3.6.bn1.bias\", \"layer3.6.bn1.running_mean\", \"layer3.6.bn1.running_var\", \"layer3.6.bn1.num_batches_tracked\", \"layer3.6.conv2.weight\", \"layer3.6.bn2.weight\", \"layer3.6.bn2.bias\", \"layer3.6.bn2.running_mean\", \"layer3.6.bn2.running_var\", \"layer3.6.bn2.num_batches_tracked\", \"layer3.6.conv3.weight\", \"layer3.6.bn3.weight\", \"layer3.6.bn3.bias\", \"layer3.6.bn3.running_mean\", \"layer3.6.bn3.running_var\", \"layer3.6.bn3.num_batches_tracked\", \"layer3.7.conv1.weight\", \"layer3.7.bn1.weight\", \"layer3.7.bn1.bias\", \"layer3.7.bn1.running_mean\", \"layer3.7.bn1.running_var\", \"layer3.7.bn1.num_batches_tracked\", \"layer3.7.conv2.weight\", \"layer3.7.bn2.weight\", \"layer3.7.bn2.bias\", \"layer3.7.bn2.running_mean\", \"layer3.7.bn2.running_var\", \"layer3.7.bn2.num_batches_tracked\", \"layer3.7.conv3.weight\", \"layer3.7.bn3.weight\", \"layer3.7.bn3.bias\", \"layer3.7.bn3.running_mean\", \"layer3.7.bn3.running_var\", \"layer3.7.bn3.num_batches_tracked\", \"layer3.8.conv1.weight\", \"layer3.8.bn1.weight\", \"layer3.8.bn1.bias\", \"layer3.8.bn1.running_mean\", \"layer3.8.bn1.running_var\", \"layer3.8.bn1.num_batches_tracked\", \"layer3.8.conv2.weight\", \"layer3.8.bn2.weight\", \"layer3.8.bn2.bias\", \"layer3.8.bn2.running_mean\", \"layer3.8.bn2.running_var\", \"layer3.8.bn2.num_batches_tracked\", \"layer3.8.conv3.weight\", \"layer3.8.bn3.weight\", \"layer3.8.bn3.bias\", \"layer3.8.bn3.running_mean\", \"layer3.8.bn3.running_var\", \"layer3.8.bn3.num_batches_tracked\", \"layer3.9.conv1.weight\", \"layer3.9.bn1.weight\", \"layer3.9.bn1.bias\", \"layer3.9.bn1.running_mean\", \"layer3.9.bn1.running_var\", \"layer3.9.bn1.num_batches_tracked\", \"layer3.9.conv2.weight\", \"layer3.9.bn2.weight\", \"layer3.9.bn2.bias\", \"layer3.9.bn2.running_mean\", \"layer3.9.bn2.running_var\", \"layer3.9.bn2.num_batches_tracked\", \"layer3.9.conv3.weight\", \"layer3.9.bn3.weight\", \"layer3.9.bn3.bias\", \"layer3.9.bn3.running_mean\", \"layer3.9.bn3.running_var\", \"layer3.9.bn3.num_batches_tracked\", \"layer3.10.conv1.weight\", \"layer3.10.bn1.weight\", \"layer3.10.bn1.bias\", \"layer3.10.bn1.running_mean\", \"layer3.10.bn1.running_var\", \"layer3.10.bn1.num_batches_tracked\", \"layer3.10.conv2.weight\", \"layer3.10.bn2.weight\", \"layer3.10.bn2.bias\", \"layer3.10.bn2.running_mean\", \"layer3.10.bn2.running_var\", \"layer3.10.bn2.num_batches_tracked\", \"layer3.10.conv3.weight\", \"layer3.10.bn3.weight\", \"layer3.10.bn3.bias\", \"layer3.10.bn3.running_mean\", \"layer3.10.bn3.running_var\", \"layer3.10.bn3.num_batches_tracked\", \"layer3.11.conv1.weight\", \"layer3.11.bn1.weight\", \"layer3.11.bn1.bias\", \"layer3.11.bn1.running_mean\", \"layer3.11.bn1.running_var\", \"layer3.11.bn1.num_batches_tracked\", \"layer3.11.conv2.weight\", \"layer3.11.bn2.weight\", \"layer3.11.bn2.bias\", \"layer3.11.bn2.running_mean\", \"layer3.11.bn2.running_var\", \"layer3.11.bn2.num_batches_tracked\", \"layer3.11.conv3.weight\", \"layer3.11.bn3.weight\", \"layer3.11.bn3.bias\", \"layer3.11.bn3.running_mean\", \"layer3.11.bn3.running_var\", \"layer3.11.bn3.num_batches_tracked\", \"layer3.12.conv1.weight\", \"layer3.12.bn1.weight\", \"layer3.12.bn1.bias\", \"layer3.12.bn1.running_mean\", \"layer3.12.bn1.running_var\", \"layer3.12.bn1.num_batches_tracked\", \"layer3.12.conv2.weight\", \"layer3.12.bn2.weight\", \"layer3.12.bn2.bias\", \"layer3.12.bn2.running_mean\", \"layer3.12.bn2.running_var\", \"layer3.12.bn2.num_batches_tracked\", \"layer3.12.conv3.weight\", \"layer3.12.bn3.weight\", \"layer3.12.bn3.bias\", \"layer3.12.bn3.running_mean\", \"layer3.12.bn3.running_var\", \"layer3.12.bn3.num_batches_tracked\", \"layer3.13.conv1.weight\", \"layer3.13.bn1.weight\", \"layer3.13.bn1.bias\", \"layer3.13.bn1.running_mean\", \"layer3.13.bn1.running_var\", \"layer3.13.bn1.num_batches_tracked\", \"layer3.13.conv2.weight\", \"layer3.13.bn2.weight\", \"layer3.13.bn2.bias\", \"layer3.13.bn2.running_mean\", \"layer3.13.bn2.running_var\", \"layer3.13.bn2.num_batches_tracked\", \"layer3.13.conv3.weight\", \"layer3.13.bn3.weight\", \"layer3.13.bn3.bias\", \"layer3.13.bn3.running_mean\", \"layer3.13.bn3.running_var\", \"layer3.13.bn3.num_batches_tracked\", \"layer3.14.conv1.weight\", \"layer3.14.bn1.weight\", \"layer3.14.bn1.bias\", \"layer3.14.bn1.running_mean\", \"layer3.14.bn1.running_var\", \"layer3.14.bn1.num_batches_tracked\", \"layer3.14.conv2.weight\", \"layer3.14.bn2.weight\", \"layer3.14.bn2.bias\", \"layer3.14.bn2.running_mean\", \"layer3.14.bn2.running_var\", \"layer3.14.bn2.num_batches_tracked\", \"layer3.14.conv3.weight\", \"layer3.14.bn3.weight\", \"layer3.14.bn3.bias\", \"layer3.14.bn3.running_mean\", \"layer3.14.bn3.running_var\", \"layer3.14.bn3.num_batches_tracked\", \"layer3.15.conv1.weight\", \"layer3.15.bn1.weight\", \"layer3.15.bn1.bias\", \"layer3.15.bn1.running_mean\", \"layer3.15.bn1.running_var\", \"layer3.15.bn1.num_batches_tracked\", \"layer3.15.conv2.weight\", \"layer3.15.bn2.weight\", \"layer3.15.bn2.bias\", \"layer3.15.bn2.running_mean\", \"layer3.15.bn2.running_var\", \"layer3.15.bn2.num_batches_tracked\", \"layer3.15.conv3.weight\", \"layer3.15.bn3.weight\", \"layer3.15.bn3.bias\", \"layer3.15.bn3.running_mean\", \"layer3.15.bn3.running_var\", \"layer3.15.bn3.num_batches_tracked\", \"layer3.16.conv1.weight\", \"layer3.16.bn1.weight\", \"layer3.16.bn1.bias\", \"layer3.16.bn1.running_mean\", \"layer3.16.bn1.running_var\", \"layer3.16.bn1.num_batches_tracked\", \"layer3.16.conv2.weight\", \"layer3.16.bn2.weight\", \"layer3.16.bn2.bias\", \"layer3.16.bn2.running_mean\", \"layer3.16.bn2.running_var\", \"layer3.16.bn2.num_batches_tracked\", \"layer3.16.conv3.weight\", \"layer3.16.bn3.weight\", \"layer3.16.bn3.bias\", \"layer3.16.bn3.running_mean\", \"layer3.16.bn3.running_var\", \"layer3.16.bn3.num_batches_tracked\", \"layer3.17.conv1.weight\", \"layer3.17.bn1.weight\", \"layer3.17.bn1.bias\", \"layer3.17.bn1.running_mean\", \"layer3.17.bn1.running_var\", \"layer3.17.bn1.num_batches_tracked\", \"layer3.17.conv2.weight\", \"layer3.17.bn2.weight\", \"layer3.17.bn2.bias\", \"layer3.17.bn2.running_mean\", \"layer3.17.bn2.running_var\", \"layer3.17.bn2.num_batches_tracked\", \"layer3.17.conv3.weight\", \"layer3.17.bn3.weight\", \"layer3.17.bn3.bias\", \"layer3.17.bn3.running_mean\", \"layer3.17.bn3.running_var\", \"layer3.17.bn3.num_batches_tracked\", \"layer3.18.conv1.weight\", \"layer3.18.bn1.weight\", \"layer3.18.bn1.bias\", \"layer3.18.bn1.running_mean\", \"layer3.18.bn1.running_var\", \"layer3.18.bn1.num_batches_tracked\", \"layer3.18.conv2.weight\", \"layer3.18.bn2.weight\", \"layer3.18.bn2.bias\", \"layer3.18.bn2.running_mean\", \"layer3.18.bn2.running_var\", \"layer3.18.bn2.num_batches_tracked\", \"layer3.18.conv3.weight\", \"layer3.18.bn3.weight\", \"layer3.18.bn3.bias\", \"layer3.18.bn3.running_mean\", \"layer3.18.bn3.running_var\", \"layer3.18.bn3.num_batches_tracked\", \"layer3.19.conv1.weight\", \"layer3.19.bn1.weight\", \"layer3.19.bn1.bias\", \"layer3.19.bn1.running_mean\", \"layer3.19.bn1.running_var\", \"layer3.19.bn1.num_batches_tracked\", \"layer3.19.conv2.weight\", \"layer3.19.bn2.weight\", \"layer3.19.bn2.bias\", \"layer3.19.bn2.running_mean\", \"layer3.19.bn2.running_var\", \"layer3.19.bn2.num_batches_tracked\", \"layer3.19.conv3.weight\", \"layer3.19.bn3.weight\", \"layer3.19.bn3.bias\", \"layer3.19.bn3.running_mean\", \"layer3.19.bn3.running_var\", \"layer3.19.bn3.num_batches_tracked\", \"layer3.20.conv1.weight\", \"layer3.20.bn1.weight\", \"layer3.20.bn1.bias\", \"layer3.20.bn1.running_mean\", \"layer3.20.bn1.running_var\", \"layer3.20.bn1.num_batches_tracked\", \"layer3.20.conv2.weight\", \"layer3.20.bn2.weight\", \"layer3.20.bn2.bias\", \"layer3.20.bn2.running_mean\", \"layer3.20.bn2.running_var\", \"layer3.20.bn2.num_batches_tracked\", \"layer3.20.conv3.weight\", \"layer3.20.bn3.weight\", \"layer3.20.bn3.bias\", \"layer3.20.bn3.running_mean\", \"layer3.20.bn3.running_var\", \"layer3.20.bn3.num_batches_tracked\", \"layer3.21.conv1.weight\", \"layer3.21.bn1.weight\", \"layer3.21.bn1.bias\", \"layer3.21.bn1.running_mean\", \"layer3.21.bn1.running_var\", \"layer3.21.bn1.num_batches_tracked\", \"layer3.21.conv2.weight\", \"layer3.21.bn2.weight\", \"layer3.21.bn2.bias\", \"layer3.21.bn2.running_mean\", \"layer3.21.bn2.running_var\", \"layer3.21.bn2.num_batches_tracked\", \"layer3.21.conv3.weight\", \"layer3.21.bn3.weight\", \"layer3.21.bn3.bias\", \"layer3.21.bn3.running_mean\", \"layer3.21.bn3.running_var\", \"layer3.21.bn3.num_batches_tracked\", \"layer3.22.conv1.weight\", \"layer3.22.bn1.weight\", \"layer3.22.bn1.bias\", \"layer3.22.bn1.running_mean\", \"layer3.22.bn1.running_var\", \"layer3.22.bn1.num_batches_tracked\", \"layer3.22.conv2.weight\", \"layer3.22.bn2.weight\", \"layer3.22.bn2.bias\", \"layer3.22.bn2.running_mean\", \"layer3.22.bn2.running_var\", \"layer3.22.bn2.num_batches_tracked\", \"layer3.22.conv3.weight\", \"layer3.22.bn3.weight\", \"layer3.22.bn3.bias\", \"layer3.22.bn3.running_mean\", \"layer3.22.bn3.running_var\", \"layer3.22.bn3.num_batches_tracked\", \"layer3.23.conv1.weight\", \"layer3.23.bn1.weight\", \"layer3.23.bn1.bias\", \"layer3.23.bn1.running_mean\", \"layer3.23.bn1.running_var\", \"layer3.23.bn1.num_batches_tracked\", \"layer3.23.conv2.weight\", \"layer3.23.bn2.weight\", \"layer3.23.bn2.bias\", \"layer3.23.bn2.running_mean\", \"layer3.23.bn2.running_var\", \"layer3.23.bn2.num_batches_tracked\", \"layer3.23.conv3.weight\", \"layer3.23.bn3.weight\", \"layer3.23.bn3.bias\", \"layer3.23.bn3.running_mean\", \"layer3.23.bn3.running_var\", \"layer3.23.bn3.num_batches_tracked\", \"layer3.24.conv1.weight\", \"layer3.24.bn1.weight\", \"layer3.24.bn1.bias\", \"layer3.24.bn1.running_mean\", \"layer3.24.bn1.running_var\", \"layer3.24.bn1.num_batches_tracked\", \"layer3.24.conv2.weight\", \"layer3.24.bn2.weight\", \"layer3.24.bn2.bias\", \"layer3.24.bn2.running_mean\", \"layer3.24.bn2.running_var\", \"layer3.24.bn2.num_batches_tracked\", \"layer3.24.conv3.weight\", \"layer3.24.bn3.weight\", \"layer3.24.bn3.bias\", \"layer3.24.bn3.running_mean\", \"layer3.24.bn3.running_var\", \"layer3.24.bn3.num_batches_tracked\", \"layer3.25.conv1.weight\", \"layer3.25.bn1.weight\", \"layer3.25.bn1.bias\", \"layer3.25.bn1.running_mean\", \"layer3.25.bn1.running_var\", \"layer3.25.bn1.num_batches_tracked\", \"layer3.25.conv2.weight\", \"layer3.25.bn2.weight\", \"layer3.25.bn2.bias\", \"layer3.25.bn2.running_mean\", \"layer3.25.bn2.running_var\", \"layer3.25.bn2.num_batches_tracked\", \"layer3.25.conv3.weight\", \"layer3.25.bn3.weight\", \"layer3.25.bn3.bias\", \"layer3.25.bn3.running_mean\", \"layer3.25.bn3.running_var\", \"layer3.25.bn3.num_batches_tracked\", \"layer3.26.conv1.weight\", \"layer3.26.bn1.weight\", \"layer3.26.bn1.bias\", \"layer3.26.bn1.running_mean\", \"layer3.26.bn1.running_var\", \"layer3.26.bn1.num_batches_tracked\", \"layer3.26.conv2.weight\", \"layer3.26.bn2.weight\", \"layer3.26.bn2.bias\", \"layer3.26.bn2.running_mean\", \"layer3.26.bn2.running_var\", \"layer3.26.bn2.num_batches_tracked\", \"layer3.26.conv3.weight\", \"layer3.26.bn3.weight\", \"layer3.26.bn3.bias\", \"layer3.26.bn3.running_mean\", \"layer3.26.bn3.running_var\", \"layer3.26.bn3.num_batches_tracked\", \"layer3.27.conv1.weight\", \"layer3.27.bn1.weight\", \"layer3.27.bn1.bias\", \"layer3.27.bn1.running_mean\", \"layer3.27.bn1.running_var\", \"layer3.27.bn1.num_batches_tracked\", \"layer3.27.conv2.weight\", \"layer3.27.bn2.weight\", \"layer3.27.bn2.bias\", \"layer3.27.bn2.running_mean\", \"layer3.27.bn2.running_var\", \"layer3.27.bn2.num_batches_tracked\", \"layer3.27.conv3.weight\", \"layer3.27.bn3.weight\", \"layer3.27.bn3.bias\", \"layer3.27.bn3.running_mean\", \"layer3.27.bn3.running_var\", \"layer3.27.bn3.num_batches_tracked\", \"layer3.28.conv1.weight\", \"layer3.28.bn1.weight\", \"layer3.28.bn1.bias\", \"layer3.28.bn1.running_mean\", \"layer3.28.bn1.running_var\", \"layer3.28.bn1.num_batches_tracked\", \"layer3.28.conv2.weight\", \"layer3.28.bn2.weight\", \"layer3.28.bn2.bias\", \"layer3.28.bn2.running_mean\", \"layer3.28.bn2.running_var\", \"layer3.28.bn2.num_batches_tracked\", \"layer3.28.conv3.weight\", \"layer3.28.bn3.weight\", \"layer3.28.bn3.bias\", \"layer3.28.bn3.running_mean\", \"layer3.28.bn3.running_var\", \"layer3.28.bn3.num_batches_tracked\", \"layer3.29.conv1.weight\", \"layer3.29.bn1.weight\", \"layer3.29.bn1.bias\", \"layer3.29.bn1.running_mean\", \"layer3.29.bn1.running_var\", \"layer3.29.bn1.num_batches_tracked\", \"layer3.29.conv2.weight\", \"layer3.29.bn2.weight\", \"layer3.29.bn2.bias\", \"layer3.29.bn2.running_mean\", \"layer3.29.bn2.running_var\", \"layer3.29.bn2.num_batches_tracked\", \"layer3.29.conv3.weight\", \"layer3.29.bn3.weight\", \"layer3.29.bn3.bias\", \"layer3.29.bn3.running_mean\", \"layer3.29.bn3.running_var\", \"layer3.29.bn3.num_batches_tracked\", \"layer3.30.conv1.weight\", \"layer3.30.bn1.weight\", \"layer3.30.bn1.bias\", \"layer3.30.bn1.running_mean\", \"layer3.30.bn1.running_var\", \"layer3.30.bn1.num_batches_tracked\", \"layer3.30.conv2.weight\", \"layer3.30.bn2.weight\", \"layer3.30.bn2.bias\", \"layer3.30.bn2.running_mean\", \"layer3.30.bn2.running_var\", \"layer3.30.bn2.num_batches_tracked\", \"layer3.30.conv3.weight\", \"layer3.30.bn3.weight\", \"layer3.30.bn3.bias\", \"layer3.30.bn3.running_mean\", \"layer3.30.bn3.running_var\", \"layer3.30.bn3.num_batches_tracked\", \"layer3.31.conv1.weight\", \"layer3.31.bn1.weight\", \"layer3.31.bn1.bias\", \"layer3.31.bn1.running_mean\", \"layer3.31.bn1.running_var\", \"layer3.31.bn1.num_batches_tracked\", \"layer3.31.conv2.weight\", \"layer3.31.bn2.weight\", \"layer3.31.bn2.bias\", \"layer3.31.bn2.running_mean\", \"layer3.31.bn2.running_var\", \"layer3.31.bn2.num_batches_tracked\", \"layer3.31.conv3.weight\", \"layer3.31.bn3.weight\", \"layer3.31.bn3.bias\", \"layer3.31.bn3.running_mean\", \"layer3.31.bn3.running_var\", \"layer3.31.bn3.num_batches_tracked\", \"layer3.32.conv1.weight\", \"layer3.32.bn1.weight\", \"layer3.32.bn1.bias\", \"layer3.32.bn1.running_mean\", \"layer3.32.bn1.running_var\", \"layer3.32.bn1.num_batches_tracked\", \"layer3.32.conv2.weight\", \"layer3.32.bn2.weight\", \"layer3.32.bn2.bias\", \"layer3.32.bn2.running_mean\", \"layer3.32.bn2.running_var\", \"layer3.32.bn2.num_batches_tracked\", \"layer3.32.conv3.weight\", \"layer3.32.bn3.weight\", \"layer3.32.bn3.bias\", \"layer3.32.bn3.running_mean\", \"layer3.32.bn3.running_var\", \"layer3.32.bn3.num_batches_tracked\", \"layer3.33.conv1.weight\", \"layer3.33.bn1.weight\", \"layer3.33.bn1.bias\", \"layer3.33.bn1.running_mean\", \"layer3.33.bn1.running_var\", \"layer3.33.bn1.num_batches_tracked\", \"layer3.33.conv2.weight\", \"layer3.33.bn2.weight\", \"layer3.33.bn2.bias\", \"layer3.33.bn2.running_mean\", \"layer3.33.bn2.running_var\", \"layer3.33.bn2.num_batches_tracked\", \"layer3.33.conv3.weight\", \"layer3.33.bn3.weight\", \"layer3.33.bn3.bias\", \"layer3.33.bn3.running_mean\", \"layer3.33.bn3.running_var\", \"layer3.33.bn3.num_batches_tracked\", \"layer3.34.conv1.weight\", \"layer3.34.bn1.weight\", \"layer3.34.bn1.bias\", \"layer3.34.bn1.running_mean\", \"layer3.34.bn1.running_var\", \"layer3.34.bn1.num_batches_tracked\", \"layer3.34.conv2.weight\", \"layer3.34.bn2.weight\", \"layer3.34.bn2.bias\", \"layer3.34.bn2.running_mean\", \"layer3.34.bn2.running_var\", \"layer3.34.bn2.num_batches_tracked\", \"layer3.34.conv3.weight\", \"layer3.34.bn3.weight\", \"layer3.34.bn3.bias\", \"layer3.34.bn3.running_mean\", \"layer3.34.bn3.running_var\", \"layer3.34.bn3.num_batches_tracked\", \"layer3.35.conv1.weight\", \"layer3.35.bn1.weight\", \"layer3.35.bn1.bias\", \"layer3.35.bn1.running_mean\", \"layer3.35.bn1.running_var\", \"layer3.35.bn1.num_batches_tracked\", \"layer3.35.conv2.weight\", \"layer3.35.bn2.weight\", \"layer3.35.bn2.bias\", \"layer3.35.bn2.running_mean\", \"layer3.35.bn2.running_var\", \"layer3.35.bn2.num_batches_tracked\", \"layer3.35.conv3.weight\", \"layer3.35.bn3.weight\", \"layer3.35.bn3.bias\", \"layer3.35.bn3.running_mean\", \"layer3.35.bn3.running_var\", \"layer3.35.bn3.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "# run trainer_teacher_model.py\n",
    "PATH = './teacher_model/ResNet152_bs128_lr0.001_epochs150_pretrained-yes.pt'\n",
    "OUTPUT_DIM = 200    #! delete after 통합 to whole code.\n",
    "teacher_model = ResNet(resnet_config, OUTPUT_DIM)\n",
    "teacher_model.load_state_dict(torch.load(PATH))\n",
    "teacher_model.eval()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load my teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model architecture\n",
    "teacher_model = models.resnet152(pretrained = False)\n",
    "\n",
    "IN_FEATURES = downloaded_model.fc.in_features \n",
    "OUTPUT_DIM = len(test_data.classes)\n",
    "teacher_model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "print(f'[*] Teacher Model Parameters  - {count_parameters(teacher_model):,}')\n",
    "\n",
    "# load trained model from ./teacher_model/teacher_model.pt\n",
    "teacher_model.load_state_dict(torch.load(args.teacher_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Solving]  \n",
    "I am not sure that this function properly do an backpropagation or grad storing stuffs. I need to check it before real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_archive.knowledge_distillation_loss import KD_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class KD_loss(nn.Module):\n",
    "    def __init__(self, Temperature):\n",
    "        super(KD_loss,self).__init__()\n",
    "        self.T = Temperature\n",
    "    \n",
    "    def forward(self, outputs, labels):\n",
    "        \"\"\"\n",
    "            input : \n",
    "                y : (gt)\n",
    "                y_stu : (student output)\n",
    "                y_tea : (teacher output)\n",
    "            output : \n",
    "                loss (Variable) : 논문's distillation loss\n",
    "        \"\"\"\n",
    "        default_loss = nn.CrossEntropyLoss()(y_stu,y)               # TODO How this could work? --> \"default_loss\"  be an insatnce carrying some needed values.\n",
    "        term1 = F.softmax(torch.mul(y_tea,1/T))         # nn.functional 이 softmax의 computational graph를 지원하나?\n",
    "        term2 = F.softmax(torch.mul(y_stu,1/T))\n",
    "        distill_loss = T**2 * nn.CrossEntropyLoss()(term1, term2)\n",
    "\n",
    "        loss = default_loss + distill_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = KD_loss(Temperature=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional loss testing.  \n",
    "\n",
    "but don't know why it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def kd_loss_functional(y, y_stu, y_tea, T):\n",
    "    default_loss = nn.CrossEntropyLoss()(y_stu,y)               # TODO How this could work? --> \"default_loss\"  be an insatnce carrying some needed values.\n",
    "    term1 = F.softmax(torch.mul(y_tea,1/T))         # nn.functional 이 softmax의 computational graph를 지원하나?\n",
    "    term2 = F.softmax(torch.mul(y_stu,1/T))\n",
    "    distill_loss = T**2 * nn.CrossEntropyLoss()(term1, term2)\n",
    "\n",
    "    loss = default_loss + distill_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_loss_functional()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. The difference btw nn.functional.crossentropy() and nn.CrossEntropyLoss()  \n",
    "A. nn.functional.crossentropy() doesn't exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m a\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mTensor([[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]])\n\u001b[1;32m      2\u001b[0m b\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mTensor([[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]])\n\u001b[0;32m----> 4\u001b[0m torch\u001b[39m.\u001b[39;49msum(a,b)\n",
      "\u001b[0;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor([[0,0,0],[1,1,1]])\n",
    "b=torch.Tensor([[1,1,1],[0,0,0]])\n",
    "\n",
    "torch.sum(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Code 손보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training.\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_epoch = 0\n",
    "\n",
    "print('[*] Start Training !', end='\\n\\n')\n",
    "for epoch in range(args.epochs):\n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, device, scheduler)\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if tensorboard_enable:\n",
    "        writer.add_scalar(\"loss/train\", train_loss, epoch)  # tensorboard\n",
    "        writer.add_scalar(\"loss/val\", valid_loss, epoch)    # tensorboard\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_epoch = epoch\n",
    "        torch.save(model.state_dict(), f'./saved/{args.model}_bs{args.batch_size}_lr{args.lr}_epochs{args.epochs}_pretrained-{args.pretrained}.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
    "        f'Train Acc @5: {train_acc_5*100:6.2f}%')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
    "        f'Valid Acc @5: {valid_acc_5*100:6.2f}%')\n",
    "\n",
    "print()\n",
    "print(f\"Best valid epoch : {best_valid_epoch}/{args.epochs} epochs\")\n",
    "\n",
    "if tensorboard_enbale:\n",
    "    writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
