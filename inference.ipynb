{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as self tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros([\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m])\n\u001b[1;32m      6\u001b[0m b \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mfill_(\u001b[39m0.1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m b\u001b[39m.\u001b[39;49mscatter_(\u001b[39m1\u001b[39;49m, r\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m), \u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m b\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as self tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "r = torch.randint(0,1,[3,4])\n",
    "a = torch.zeros([3,4])\n",
    "b = a.fill_(0.1)\n",
    "\n",
    "b.scatter_(1, r.data.unsqueeze(1), 0.1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/test_jh/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model_archive.ResNet import ResNet, Config\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image    \n",
    "\n",
    "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device, scheduler=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler=='yes':\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<< Configurations >>\n",
      "[*] Model       - resnet50\n",
      "[*] (어떻게 훈련된 모델인지 정보)\n"
     ]
    }
   ],
   "source": [
    "# Not yet for transfer learning\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--model\", type=str, default=\"resnet50\")\n",
    "# parser.add_argument(\"--model_path\", type=str, required=True)\n",
    "# # model config 는 뭐고, 왜 저장하는거지?\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "# parser.add_argument(\"--root_path\", type=str, default='/home/jh/Desktop/VSC/CNN_work/archive/CUB_200_2011/')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "print()\n",
    "print('<< Configurations >>')\n",
    "print(f'[*] Model       - {args.model}')\n",
    "print(f'[*] (어떻게 훈련된 모델인지 정보)')\n",
    "\n",
    "\n",
    "# Dataset\n",
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#                         transforms.Resize(pretrained_size),\n",
    "#                         transforms.RandomRotation(5),\n",
    "#                         transforms.RandomHorizontalFlip(0.5),\n",
    "#                         transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "#                         transforms.ToTensor(),\n",
    "#                         transforms.Normalize(mean = pretrained_means, \n",
    "#                                                 std = pretrained_stds)\n",
    "#                     ])\n",
    "test_transforms = transforms.Compose([\n",
    "                        transforms.Resize(pretrained_size),\n",
    "                        transforms.CenterCrop(pretrained_size),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                    ])\n",
    "ROOT = args.root_path\n",
    "data_dir = os.path.join(ROOT, 'CUB_200_2011')\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "\n",
    "BATCH_SIZE = args.batch_size\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_data = datasets.ImageFolder(root = test_dir,\n",
    "                                transform = test_transforms)\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    model = 'resnet50',\n",
    "    model_path = '/home/jh/Desktop/VSC/CNN_work/saved/resnet50_bs16_lr0.000125_epochs100_pretrained-no.pt',\n",
    "    batch_size = 16,\n",
    "    root_path = '/home/jh/Desktop/VSC/CNN_work/archive/CUB_200_2011/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained = False)     # model 달라지면, 바꾸기\n",
    "IN_FEATURES = model.fc.in_features \n",
    "OUTPUT_DIM = len(test_data.classes)\n",
    "model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "\n",
    "model.load_state_dict(torch.load(args.model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Parameters  - 23,917,832\n",
      "[*] Inference Start !\n",
      "\n",
      "\tTest Loss: 2.124 | Test Acc @1:  51.92% | Test Acc @5:  78.34%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Inference, 일단 score만 구해봄. 작동 잘하는듯!\n",
    "'''\n",
    "\n",
    "print(f'[*] Model - {args.model}')\n",
    "print(f'[*] Parameters  - {count_parameters(model):,}')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Model training.\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_epoch = 0\n",
    "\n",
    "print('[*] Inference Start !', end='\\n\\n')\n",
    "\n",
    "test_loss, test_acc_1, test_acc_5 = evaluate(model, test_iterator, criterion, device)\n",
    "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | ' \\\n",
    "        f'Test Acc @5: {test_acc_5*100:6.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 200개 class, 어떤 순서로 배치된거지?\n",
    "- 각 image 에 대해서 어떤 확률로 inference 한건지 볼 수 있나?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
